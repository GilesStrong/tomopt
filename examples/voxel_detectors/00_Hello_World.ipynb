{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World\n",
    "This tutorial/example aims to give an simplistic overview of setting up a passive volume (scattering material to be imaged), detector (active material to record hits), and optimisation loop (to refine the detector to image the passive volume better or more cheaply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Volume setup\n",
    "The volume consists of both passive material to be imaged, and active detectors to record muons hits. We aim to adjust the resolution and efficiency of the detectors to minimise the cost of the detector whilst improving the precision of the imaging of the passive volume.\n",
    "\n",
    "<img src=\"imgs/volume_layout.png\" width=\"256\">\n",
    "\n",
    "The above image shows a typical layout, with two detection layers above and below the passive volume consisting of layers of material. Each layer consists of sub-cubes (voxels). In the detector layers, these are elements of the detector with properties to be optimised, and in the passive layers these can be different materials, whose X0 will affect the scattering of muons to deferring extents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the cost of the detector elements according to resolution and efficiency. These are currently arbitrary, and discussed further in the next tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_cost(x:Tensor) -> Tensor:\n",
    "    return torch.expm1(3*F.relu(x))  # free for negative efficiency, sharp rise as efficiency increases\n",
    "\n",
    "x = torch.linspace(0,1,10)\n",
    "plt.plot(x, eff_cost(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/100)**2  # free for negative resoltuion, gradual rise as resoltuion increases\n",
    "\n",
    "x = torch.logspace(1,4,100)\n",
    "plt.plot(x, res_cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a volume by sandwiching passive layers with pairs of detector layers above and below. Detector layers are initialised with a specified resolution and efficiency for each element. Passive layers will contain voxels of different materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from tomopt.volume import PassiveLayer, VoxelDetectorLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    pos = 'above'\n",
    "    for z,d in zip(np.arange(lwh[2],0,-size), [1,1,0,0,0,0,0,0,1,1]):\n",
    "        if d:\n",
    "            layers.append(VoxelDetectorLayer(pos=pos, init_eff=init_eff, init_res=init_res,\n",
    "                                        lw=lwh[:2], z=z, size=size, eff_cost_func=eff_cost, res_cost_func=res_cost))\n",
    "        else:\n",
    "            pos = 'below'\n",
    "            layers.append(PassiveLayer(lw=lwh[:2], z=z, size=size))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll feed these stacked layers into a single object for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume import Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())\n",
    "volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "\n",
    "Having built our detector and defined where the passive volumes will be, we now want to define the material composition of the passive volume(s) to be imaged, and to optimise our detector.\n",
    "As its name suggests, `VoxelVolumeWrapper` wraps the `Volume` and provides methods to optimise the detector, predict passive volumes, loading and saving of detector configurations, etc.\n",
    "\n",
    "When building the wrapper, we need to supply it with optimiser definitions for both resolution and efficiency, and a loss function to optimise. Optimisers are the classes in PyTorch which implement gradient descent on specified parameters. For the optimisers, use partial definitions, since the `VoxelVolumeWrapper` takes care of instantiating the optimisers to relate to the relevant detector parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tomopt.optimisation import VoxelVolumeWrapper, DetectorLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = VoxelVolumeWrapper(volume,\n",
    "                             res_opt=partial(torch.optim.SGD, lr=2e9),  # Scale of resolution is large, so use high LR\n",
    "                             eff_opt=partial(torch.optim.SGD, lr=2e4),  # Scale of efficiency is [0,1] so use smaller LR\n",
    "                             loss_func=DetectorLoss(target_budget=0.8, cost_coef=None))  # Loss is precision + budget_coef*cost_coef*detector cost, balance coef as required or leave as None to automatically balance on first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define the composition of the passive volume. This is done via a function which is called per passive layer (we have six) and returns the x0 (radiation length [m]) of the material in the voxels in that layer. Below we'll define the passive material to be mostly beryllium but with a single block of lead in the corner of one of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.core import X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we may want to optimise the detector for multiple different passive volumes (or randomly generated volumes), different functions can be passed to the `VoxelVolumeWrapper` during optimisation by loading the functions into `PassiveYielder` objects, which loop through the passive volumes. In this tutorial, though, we only have one passive volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation import PassiveYielder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're in a position to optimise our detector using the `VolumeWrapper.fit` method. The general layout for the optimisation loop is as follows, where `mu_bs` is the number of muons passed through the volume simultaneously and `passive_bs` is the number of passive volumes used per detector update:\n",
    "1. for epoch in `n_epochs`:\n",
    "    1. `loss` = 0\n",
    "    1. for `p`, `passive` in enumerate(`trn_passives`):\n",
    "        1. load `passive` into passive volume\n",
    "        1. for muon_batch in range(`n_mu_per_volume`//`mu_bs`):\n",
    "            1. Irradiate volume with `mu_bs` muons\n",
    "            1. Infer passive volume\n",
    "        1. Compute loss based on precision and cost, and add to `loss`\n",
    "        1. if `p`+1 % `passive_bs` == 0:\n",
    "            1. `loss` = `loss`/`passive_bs`\n",
    "            1. Backpropagate `loss` and update detector parameters\n",
    "            1. `loss` = 0\n",
    "        1. if len(`trn_passives`)-(`p`+1) < `passive_bs`:\n",
    "            1. Break\n",
    "            \n",
    "    1. `val_loss` = 0\n",
    "    1. for `p`, `passive` in enumerate(`val_passives`):\n",
    "        1. load `passive` into passive volume\n",
    "        1. for muon_batch in range(`n_mu_per_volume`//`mu_bs`):\n",
    "            1. Irradiate volume with `mu_bs` muons\n",
    "            1. Infer passive volume\n",
    "            1. Compute loss based on precision and cost, and add to `val_loss`\n",
    "        1. if len(`val_passives`)-(`p`+1) < `passive_bs`:\n",
    "            1. Break\n",
    "    1. `val_loss` = `val_loss`/`p`\n",
    "\n",
    "I.e. the loss for a single passive can be computed over several iterations of muon irradiation (for computational speed), and the total loss can be accumulated over multiple passives before updating the detector. In our case we only have one passive. We also have the option of evaluating the detector on unseen passives via validation data. For this example, we'll use the same passive for the both training and validation.\n",
    "\n",
    "Additionally, the optimisation loop has many interjection points for callback classes, which can affect most aspects of the optimisation. Currently in TomOpt, there is a problem which means that sometimes the gradients for some parameters are `NaN` after backpropagation. The `tomopt.optimisation.callbacks.grad_callbacks.NoMoreNaNs` will automatically go through each parameter after backpropagation and replace `NaN` gradients with zeros prior to the optimiser update step. Additionally, it is useful to have an indication of the progress the optimisation, and the current state of the detector. `tomopt.optimisation.callbacks.monitors.MetricLogger` provides real-time progress updates and telemetric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation import NoMoreNaNs, VoxelMetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = wrapper.fit(n_epochs=100,\n",
    "                passive_bs=1,\n",
    "                n_mu_per_volume=1000,\n",
    "                mu_bs=100,\n",
    "                trn_passives=passives,\n",
    "                val_passives=passives,\n",
    "                cbs=[NoMoreNaNs(),VoxelMetricLogger()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial resolution of each detector element was $1000 m^{-1}$ and the initial efficiencies were 0.5. From this we can see that the resolutions and efficiencies generally increase. Running for longer will produce a more prominent (and asymmetric) change in the four detector layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "`VolumeWrapper` also has a `.predict` method to provide predictions per passive volume. For convenience it also returns the true material composition for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = wrapper.predict(passives,\n",
    "                        n_mu_per_volume=10000,\n",
    "                        mu_bs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`preds` is a list of tuples of predicted x0 and true x0 per passive volume. We can plot these with `tomopt.plotting.predictions.plot_pred_true_x0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.plotting import plot_pred_true_x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_true_x0(*preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have the predicted and true x0 for ever voxel in the six passive layers. Currently the scale of predictions is very low, due to biases in the prediction method, however we can already see some indication of the lead block in the relative values of the predictions. Running 100k muons, will make the asymmetry more prominent, however that takes about 8 minutes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
