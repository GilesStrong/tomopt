{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tomopt.core import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.muon import *\n",
    "from tomopt.optimisation import *\n",
    "from tomopt.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5787166f89b9>:4: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  /pytorch/aten/src/ATen/native/RangeFactories.cpp:23.)\n",
      "  x = torch.linspace(-1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe315183ac0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def area_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x)\n",
    "\n",
    "x = torch.linspace(-1, 1)\n",
    "plt.plot(x, area_cost(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.2\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    n_panels = 4\n",
    "    layers.append(PanelDetectorLayer(pos='above', lw=lwh[:2], z=1, size=size,\n",
    "                                     panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,1-(i*(size)/n_panels)], init_xy_span=[1.0,1.0],\n",
    "                                                      area_cost_func=area_cost, device=DEVICE) for i in range(n_panels)]))\n",
    "    for z in [0.8,0.6,0.4]:\n",
    "        layers.append(PassiveLayer(lw=lwh[:2], z=z, size=size, device=DEVICE))\n",
    "    layers.append(PanelDetectorLayer(pos='below', lw=lwh[:2], z=0.2, size=size,\n",
    "                                     panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,0.2-(i*(size)/n_panels)], init_xy_span=[1.0,1.0],\n",
    "                                                      area_cost_func=area_cost, device=DEVICE) for i in range(n_panels)]))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): PanelDetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([1.]), and xy span tensor([1., 1.])\n",
       "        (1): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.9500]), and xy span tensor([1., 1.])\n",
       "        (2): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.9000]), and xy span tensor([1., 1.])\n",
       "        (3): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.8500]), and xy span tensor([1., 1.])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PanelDetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.2000]), and xy span tensor([1., 1.])\n",
       "        (1): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.1500]), and xy span tensor([1., 1.])\n",
       "        (2): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.1000]), and xy span tensor([1., 1.])\n",
       "        (3): <class 'tomopt.volume.panel.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=tensor([0.0500]), and xy span tensor([1., 1.])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = Volume(get_layers())\n",
    "volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation.data.passives import AbsPassiveGenerator\n",
    "\n",
    "from lumin.nn.data.fold_yielder import FoldYielder\n",
    "\n",
    "class ScatterYielder(FoldYielder):\n",
    "    def __init__(self, volume:Volume, passive_generator:AbsPassiveGenerator, mu_bs:int, n_volumes_per_fold:int, targ_as_class:bool):\n",
    "        self.cont_feats,self.cat_feats,self.input_pipe,self.output_pipe = [],[],None,None\n",
    "        self.yield_matrix,self.matrix_pipe = True,None\n",
    "        self.augmented,self.aug_mult,self.train_time_aug,self.test_time_aug = False,0,False,False\n",
    "        self.input_feats = self.cont_feats + self.cat_feats\n",
    "        self.orig_cont_feats,self.orig_cat_feat,self._ignore_feats = self.cont_feats,self.cat_feats,[]\n",
    "        \n",
    "        self.volume,self.passive_generator,self.mu_bs = volume,passive_generator,mu_bs\n",
    "        self.voxel_centres = self._build_centres()\n",
    "        self.targ_as_class = targ_as_class\n",
    "        if self.targ_as_class:\n",
    "            self.class2id = {m:i for i,m in enumerate(self.passive_generator.materials)}\n",
    "            self.id2class = {i:m for i,m in enumerate(self.passive_generator.materials)}\n",
    "            self.x02id = {X0[m]:i for i,m in enumerate(self.passive_generator.materials)}\n",
    "            self.id2x0 = {i:X0[m] for i,m in enumerate(self.passive_generator.materials)}\n",
    "                \n",
    "        self.n_volumes_per_fold = n_volumes_per_fold\n",
    "        self.n_voxels = int(len(self.volume.get_passives())*(self.volume.lw/self.volume.passive_size).prod().item())\n",
    "        self.n_folds = 10\n",
    "        self.has_matrix = True\n",
    "        self.fld_szs = {i:self.n_volumes_per_fold for i in range(self.n_folds)}\n",
    "        \n",
    "        self.targ_feats = [\"X0\"]\n",
    "        self.matrix_feats = {'present_feats': [\"dtheta_x\", \"dtheta_y\", \"dx\", \"dy\", \"pred_x0\", \"dpoca_x\", \"dpoca_y\", \"dpoca_z\", \"dpoca_r\"],\n",
    "                             'vecs': [f'mu_{i}' for i in range(self.mu_bs)], 'missing': [], 'row_wise': True}\n",
    "        self.matrix_feats['feats_per_vec'] = len(self.matrix_feats['present_feats']), \n",
    "        self.matrix_feats['shape'] = (self.mu_bs, self.matrix_feats['feats_per_vec'])\n",
    "        self.matrix_is_sparse = False\n",
    "        self.matrix_shape = self.matrix_feats['shape']\n",
    "        \n",
    "    def _build_centres(self) -> Tensor:\n",
    "        bounds = (\n",
    "            self.volume.passive_size\n",
    "            * np.mgrid[\n",
    "                round(self.volume.get_passive_z_range()[0].detach().cpu().numpy()[0] / self.volume.passive_size) : round(\n",
    "                      self.volume.get_passive_z_range()[1].detach().cpu().numpy()[0] / self.volume.passive_size\n",
    "                ) : 1,\n",
    "                0 : round(self.volume.lw.detach().cpu().numpy()[0] / self.volume.passive_size) : 1,\n",
    "                0 : round(self.volume.lw.detach().cpu().numpy()[1] / self.volume.passive_size) : 1,\n",
    "            ]\n",
    "        )\n",
    "#         bounds[0] = np.flip(bounds[0])  # z is reversed\n",
    "        return torch.tensor(bounds.reshape(3, -1).transpose(-1, -2), dtype=torch.float32) + (self.volume.passive_size/2)\n",
    "        \n",
    "    def generate_data(self) -> Dict[str, np.ndarray]:\n",
    "        inputs,targets = [],[]\n",
    "        for _ in range(self.n_volumes_per_fold):\n",
    "            #Scatter generation\n",
    "            muons = MuonBatch(generate_batch(self.mu_bs), self.volume.h, device=self.volume.device)\n",
    "            block = self.passive_generator.generate()\n",
    "            self.volume.load_rad_length(block)\n",
    "            self.volume(muons)\n",
    "            sb = GenScatterBatch(muons, self.volume)\n",
    "            \n",
    "            # x0 prediction\n",
    "            mom = muons.reco_mom\n",
    "            dtheta = sb.dtheta\n",
    "            theta_xy_in = sb.theta_in\n",
    "            theta_xy_out = sb.theta_out\n",
    "            theta2 = dtheta.pow(2).sum(1)\n",
    "            n_x0 = 0.5 * theta2 * ((mom / SCATTER_COEF_A) ** 2)\n",
    "            theta_in = theta_xy_in.pow(2).sum(1).sqrt()\n",
    "            theta_out = theta_xy_out.pow(2).sum(1).sqrt()\n",
    "            cos_theta_in = torch.cos(theta_in)\n",
    "            cos_theta_out = torch.cos(theta_out)\n",
    "            cos_mean = (cos_theta_in + cos_theta_out) / 2\n",
    "            pred = self.volume.passive_size / (n_x0 * cos_mean)\n",
    "            \n",
    "            #Data creation\n",
    "            data = torch.cat((sb.dtheta, sb.dxy, pred[:,None], sb.location), dim=-1).detach()\n",
    "            data = data[None,:].repeat_interleave(len(self.voxel_centres), dim=0)\n",
    "            data[:,:,-3:] -= self.voxel_centres[:,None].repeat_interleave(self.mu_bs, dim=1)\n",
    "            data = torch.cat((data,torch.norm(data[:,:,-3:], dim=-1, keepdim=True)), dim=-1)  # dR\n",
    "            \n",
    "            # Sort by dR\n",
    "            idxs = data[:,:,-1].argsort()\n",
    "            i = np.arange(data.shape[0])[:,None]\n",
    "            data = data[i,idxs]\n",
    "            \n",
    "            inputs.append(data[None,:])\n",
    "            targets.append(self.volume.get_rad_cube().flatten())\n",
    "        \n",
    "        inputs = torch.cat(inputs, dim=0).detach().cpu().numpy()\n",
    "        targets = torch.stack(targets, dim=0).detach().cpu().numpy()\n",
    "        print(targets.shape)\n",
    "        if self.targ_as_class:\n",
    "            for m in self.passive_generator.materials:\n",
    "                targets[targets == X0[m]] = self.class2id[m]\n",
    "            targets = targets.astype(int)\n",
    "        return {'inputs':(np.zeros((len(inputs),0)),inputs),'targets':targets}\n",
    "        \n",
    "    def get_fold(self, idx:int) -> Dict[str,np.ndarray]:\n",
    "        return self.generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy = ScatterYielder(volume=volume, passive_generator=VoxelPassiveGenerator(materials=[\"beryllium\",\"lead\"]), mu_bs=100, n_volumes_per_fold=160, targ_as_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sy.n_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((160, 75, 100, 9), (160, 75))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = sy[0]\n",
    "fold['inputs'][1].shape,fold['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30022803, 0.30817884, 0.35273668, 0.37139574, 0.39080364,\n",
       "       0.40336394, 0.43659258, 0.44007528, 0.44361407, 0.45162246,\n",
       "       0.4544852 , 0.4685242 , 0.4805765 , 0.4922181 , 0.4948578 ,\n",
       "       0.51994157, 0.53616446, 0.539029  , 0.53989685, 0.54660857,\n",
       "       0.54857314, 0.5566273 , 0.5792566 , 0.5869148 , 0.59182346,\n",
       "       0.59552914, 0.60428935, 0.6044844 , 0.6052807 , 0.60537314,\n",
       "       0.61932564, 0.63349247, 0.6345722 , 0.6351899 , 0.6450681 ,\n",
       "       0.6537459 , 0.6551525 , 0.65813047, 0.6591631 , 0.6621255 ,\n",
       "       0.6690187 , 0.67378956, 0.6850124 , 0.7042213 , 0.7067251 ,\n",
       "       0.7074449 , 0.71380067, 0.71438503, 0.71630144, 0.7165375 ,\n",
       "       0.7211572 , 0.7380758 , 0.73960626, 0.74826014, 0.7506312 ,\n",
       "       0.75394857, 0.756438  , 0.75702363, 0.75913334, 0.76060253,\n",
       "       0.7665566 , 0.77010226, 0.77126265, 0.7738953 , 0.7761524 ,\n",
       "       0.78891265, 0.79121834, 0.8389661 , 0.843919  , 0.84723014,\n",
       "       0.87044877, 0.88758767, 0.8880155 , 0.9016945 , 0.9071418 ,\n",
       "       0.90925467, 0.92066073, 0.9221797 , 0.92419595, 0.9260126 ,\n",
       "       0.9368668 , 0.94011563, 0.9403569 , 0.9482531 , 0.9620963 ,\n",
       "       0.9892478 , 0.98925686, 1.0010915 , 1.0220684 , 1.0394386 ,\n",
       "       1.0720179 , 1.0825291 , 1.0904889 , 1.1049814 , 1.1118436 ,\n",
       "       1.190491  , 1.3645157 , 1.4032575 , 1.4489836 , 1.6057202 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold['inputs'][1][0,0,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 1, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumin.nn.models.blocks.head import *\n",
    "from lumin.nn.models.blocks.head import AbsGraphFeatExtractor\n",
    "from lumin.nn.models.blocks.gnn_blocks import *\n",
    "from lumin.nn.models.initialisations import lookup_normal_init\n",
    "from lumin.nn.models.layers.activations import lookup_act\n",
    "from lumin.nn.models.layers.batchnorms import RunningBatchNorm1d, LCBatchNorm1d, RunningBatchNorm2d\n",
    "\n",
    "from torch._vmap_internals import _vmap as vmap\n",
    "\n",
    "class X0Net(AbsGraphFeatExtractor):\n",
    "    row_wise:Optional[bool] = True\n",
    "        \n",
    "    def __init__(self, n_v:int, n_fpv:int, vox_centres:Tensor,\n",
    "                 do:float=0, rep_bn:bool=False, act:str='relu',\n",
    "                 lookup_init:Callable[[str,Optional[int],Optional[int]],Callable[[Tensor],None]]=lookup_normal_init,\n",
    "                 lookup_act:Callable[[str],Any]=lookup_act, bn_class:Callable[[int],nn.Module]=nn.BatchNorm1d, rep_bn_class:Callable[[int],nn.Module]=nn.BatchNorm2d):\n",
    "        super().__init__(n_v=n_v, n_fpv=n_fpv, do=do, bn=False, act=act, lookup_init=lookup_init, lookup_act=lookup_act, bn_class=bn_class)\n",
    "        \n",
    "        self.n_voxels,self.rep_bn,self.rep_bn_class = len(vox_centres),rep_bn,rep_bn_class\n",
    "                \n",
    "        # GNNs\n",
    "        if self.rep_bn: self.init_bn = self.rep_bn_class(self.n_fpv)\n",
    "        \n",
    "        self.n_muon_rep, self.n_vox_rep = 40, 40\n",
    "        self.muon_rep_gnn = GravNet(n_v=self.n_v, n_fpv=self.n_fpv,\n",
    "                                    cat_means=True,\n",
    "                                    f_slr_depth=3,\n",
    "                                    n_s=4,\n",
    "                                    n_lr=22,\n",
    "                                    k=25,\n",
    "                                    f_out_depth=1,\n",
    "                                    n_out=[48],\n",
    "                                    act=self.act,\n",
    "                                    use_sa=False,\n",
    "                                    bn=False,\n",
    "                                   )\n",
    "        self.muon_rep_collapser = GraphCollapser(n_v=self.n_v, n_fpv=self.muon_rep_gnn.get_out_size()[1],\n",
    "                                                 flatten=False,\n",
    "                                                 f_final_outs=[self.n_muon_rep],\n",
    "                                                 n_sa_layers=0,\n",
    "                                                 global_feat_vec=False,\n",
    "                                                 act=self.act,\n",
    "                                                 bn=False,\n",
    "                                                )\n",
    "        \n",
    "        if self.rep_bn: self.muon_rep_bn = self.rep_bn_class(self.muon_rep_collapser.get_out_size()+4)\n",
    "        \n",
    "        self.vox_rep_gnn = GravNet(n_v=self.n_voxels, n_fpv=self.muon_rep_collapser.get_out_size()+4,\n",
    "                                   cat_means=True,\n",
    "                                   f_slr_depth=3,\n",
    "                                   n_s=4,\n",
    "                                   n_lr=22,\n",
    "                                   k=12,\n",
    "                                   f_out_depth=1,\n",
    "                                   n_out=[48],\n",
    "                                   act=self.act,\n",
    "                                   use_sa=False,\n",
    "                                   bn=False,\n",
    "                                  )\n",
    "        self.vox_rep_collapser = GraphCollapser(n_v=self.n_voxels, n_fpv=self.vox_rep_gnn.get_out_size()[1],\n",
    "                                                flatten=False,\n",
    "                                                f_final_outs=[self.n_vox_rep],\n",
    "                                                n_sa_layers=0,\n",
    "                                                global_feat_vec=False,\n",
    "                                                act=self.act,\n",
    "                                                bn=False,\n",
    "                                               )\n",
    "        \n",
    "        # Relative voxel positions\n",
    "        self.vox_centres = vox_centres  # (voxel,coords)\n",
    "        vox_dists = self.vox_centres[None]-self.vox_centres[:,None]  # (voxel,voxel,coords)\n",
    "        self.register_buffer('vox_dists', torch.cat((vox_dists,vox_dists.norm(dim=-1, keepdim=True)), dim=-1))\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        r'''x=(volume,voxel,muon,feature)'''\n",
    "        if self.rep_bn: x = self.init_bn(x.transpose(1,-1)).transpose(1,-1)\n",
    "        \n",
    "        def get_muon_rep(x:Tensor) -> Tensor:\n",
    "            r'''(voxel,muon,feature)'''\n",
    "            return self.muon_rep_collapser(self.muon_rep_gnn(x))\n",
    "        \n",
    "#         muon_rep = vmap(get_muon_rep)(x)  # (volume,voxel,muon_rep)\n",
    "        muon_rep = torch.stack([get_muon_rep(v) for v in x.unbind()], dim=0)  # (volume,voxel,muon_rep)\n",
    "        muon_rep = muon_rep[:,None].expand(-1,self.n_voxels, -1,-1)  # (volume,voxel,voxel,muon_rep)\n",
    "        muon_rep = torch.cat((muon_rep, self.vox_dists[None].expand(len(muon_rep), -1, -1, -1)), dim=-1)\n",
    "        if self.rep_bn: muon_rep = self.muon_rep_bn(muon_rep.transpose(1,-1)).transpose(1,-1)\n",
    "        \n",
    "        def get_vox_rep(x:Tensor) -> Tensor:\n",
    "            r'''(voxel,voxel,muon_rep)'''\n",
    "            return self.vox_rep_collapser(self.vox_rep_gnn(x))\n",
    "        \n",
    "#         vox_rep = vmap(get_vox_rep)(muon_rep)  # (volume,voxel,class)\n",
    "        vox_rep = torch.stack([get_vox_rep(v) for v in muon_rep.unbind()], dim=0)  # (volume,voxel,class)\n",
    "        return vox_rep\n",
    "    \n",
    "    def get_out_size(self) -> Tuple[int,int]: return self.n_voxels, self.n_vox_rep*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lumin.nn.models.blocks.body import FullyConnected\n",
    "from lumin.nn.models.blocks.tail import ClassRegMulti\n",
    "\n",
    "from lumin.nn.models.model_builder import ModelBuilder\n",
    "from lumin.nn.models.model import Model\n",
    "from lumin.optimisation.hyper_param import lr_find\n",
    "\n",
    "head = partial(GNNHead, vecs=sy.matrix_feats['vecs'], feats_per_vec=sy.matrix_feats['present_feats'],\n",
    "               extractor=partial(X0Net, vox_centres=sy.voxel_centres, rep_bn=True, rep_bn_class=RunningBatchNorm2d, act='swish'),\n",
    "               collapser=partial(GraphCollapser,\n",
    "                                 flatten=True,\n",
    "                                 f_final_outs=[len(sy.passive_generator.materials)],\n",
    "                                 bn=False,\n",
    "                                 act='swish',\n",
    "                                 bn_class=RunningBatchNorm1d\n",
    "                                ))\n",
    "\n",
    "body = partial(FullyConnected, depth=3, width=50, act='swish')\n",
    "opt_args = {'opt':'adam', 'eps':1e-08}\n",
    "model_builder = ModelBuilder('multiclass', cont_feats=sy.matrix_feats['present_feats'], n_out=len(sy.passive_generator.materials), \n",
    "                             opt_args=opt_args, body=body, head=head)\n",
    "print(Model(model_builder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.get_data_count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = lr_find(sy, model_builder, bs=16, lr_bounds=[1e-5,1e0], n_repeats=3, bulk_move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumin.nn.callbacks.cyclic_callbacks import OneCycle\n",
    "from lumin.nn.metrics.class_eval import RocAucScore\n",
    "from functools import partial\n",
    "\n",
    "cb_partials = [partial(OneCycle, lengths=[5, 10],lr_range=[1e-5, 1e-3], mom_range=[0.85, 0.95], interp='cosine')]\n",
    "metric_partials = (partial(RocAucScore, average='weighted', multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lumin.nn.training.train import train_models\n",
    "_ = train_models(sy, n_models=1,\n",
    "                 model_builder=model_builder,\n",
    "                 bs=16,\n",
    "                 cb_partials=cb_partials,\n",
    "                 metric_partials=metric_partials,\n",
    "                 n_epochs=15,\n",
    "                 bulk_move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.from_save('train_weights/model_id_0/best.h5', model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(data['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inputs'][1][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = pred.argmax(-1)\n",
    "# pred_class = pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = data['targets'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(targs, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_matrix(targs, pred_class), sy.passive_generator.materials, sy.passive_generator.materials)\n",
    "# plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.ylabel('Target')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=targs, y_score=pred, multi_class='ovr', average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
