{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.loss import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.core import *\n",
    "from tomopt.optimisation import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_cost(x:Tensor) -> Tensor:\n",
    "    return torch.expm1(3*F.relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/100)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    pos = 'above'\n",
    "    for z,d in zip(np.arange(lwh[2],0,-size), [1,1,0,0,0,0,0,0,1,1]):\n",
    "        if d:\n",
    "            layers.append(DetectorLayer(pos=pos, init_eff=init_eff, init_res=init_res,\n",
    "                                        lw=lwh[:2], z=z, size=size, eff_cost_func=eff_cost, res_cost_func=res_cost))\n",
    "        else:\n",
    "            pos = 'below'\n",
    "            layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VolumeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = VolumeWrapper(volume=volume, res_opt=partial(torch.optim.SGD, lr=2e1), eff_opt=partial(torch.optim.SGD, lr=2e-5), loss_func=DetectorLoss(0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function arb_rad_length at 0x7fe6af8210d0>\n"
     ]
    }
   ],
   "source": [
    "for p in trn_passives: print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i%5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation.callbacks.callback import Callback\n",
    "\n",
    "r'''\n",
    "This MetricLogger is a modified version of the MetricLogger in LUMIN (https://github.com/GilesStrong/lumin/blob/v0.7.2/lumin/nn/callbacks/monitors.py#L125), distributed under the following lincence:\n",
    "    Copyright 2018 onwards Giles Strong\n",
    "\n",
    "    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "    you may not use this file except in compliance with the License.\n",
    "    You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "    Unless required by applicable law or agreed to in writing, software\n",
    "    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "    See the License for the specific language governing permissions and\n",
    "    limitations under the License.\n",
    "\n",
    "Usage is compatible with the AGPL licence underwhich TomOpt is distributed.\n",
    "Stated changes: adaption to work with `VolumeWrapper` class, replacement of the telemtry plots with task specific information.\n",
    "'''\n",
    "                                                               \n",
    "class MetricLogger(Callback):\n",
    "    r'''\n",
    "    Provides live feedback during training showing a variety of metrics to help highlight problems or test hyper-parameters without completing a full training.\n",
    "    If `show_plots` is false, will instead print training and validation losses at the end of each epoch.\n",
    "    The full history is available as a dictionary by calling `MetricLogger.get_loss_history`.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, show_plots:bool=IN_NOTEBOOK, loss_is_meaned:bool=True):\n",
    "        self.show_plots,self.loss_is_meaned = show_plots,loss_is_meaned\n",
    "\n",
    "    def on_train_begin(self) -> None:\n",
    "        r'''\n",
    "        Prepare for new training\n",
    "        '''\n",
    "\n",
    "        super().on_train_begin()\n",
    "        self._reset()\n",
    "        for c in self.wrapper.fit_params.loss_cbs: self._add_loss_name(type(c).__name__)\n",
    "\n",
    "    def on_epoch_begin(self) -> None:\n",
    "        r'''\n",
    "        Prepare to track new loss\n",
    "        '''\n",
    "\n",
    "        self.loss,self.cnt = 0,0\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        r'''\n",
    "        If validation epoch finished, record validation losses, compute info and update plots\n",
    "        '''\n",
    "\n",
    "        if self.model.fit_params.state == 'train':\n",
    "            self.loss_vals[0].append(self.wrapper.loss_val)\n",
    "        elif self.model.fit_params.state == 'valid':\n",
    "            self.epochs.append(self.epochs[-1]+1)\n",
    "            self.loss_vals[1].append(self.wrapper.loss_val)\n",
    "            for i,c in enumerate(self.model.fit_params.loss_cbs): self.loss_vals[i+2].append(c.get_loss())\n",
    "            for i,c in enumerate(self.metric_cbs): self.metric_vals[i].append(c.get_metric())\n",
    "            if self.show_plots:\n",
    "                for i, v in enumerate(self.loss_vals[1:]):\n",
    "                    if len(self.loss_vals[1]) > 1 and self.extra_detail:\n",
    "                        self.vel_vals[i].append(v[-1]-v[-2])\n",
    "                        self.gen_vals[i].append(v[-1]/self.loss_vals[0][-1])\n",
    "                    if self.loss_vals[i+1][-1] <= self.best_loss: self.best_loss = self.loss_vals[i+1][-1]\n",
    "                self.update_plot()\n",
    "            else:\n",
    "                self.print_losses()\n",
    "\n",
    "            ls = np.array(self.loss_vals[1:])[:,-1]\n",
    "            m = None\n",
    "            if self.lock_to_metric:\n",
    "                m = self.metric_vals[self.main_metric_idx][-1]\n",
    "                if not self.metric_cbs[self.main_metric_idx].lower_metric_better: m *= -1\n",
    "            self.val_epoch_results = ls,m\n",
    "\n",
    "    def _add_loss_name(self, name:str) -> None:\n",
    "        self.loss_names.append(name)\n",
    "        self.loss_vals.append([0 for _ in self.loss_vals[1]])\n",
    "        self.vel_vals.append([0 for _ in self.vel_vals[0]])\n",
    "        self.gen_vals.append([0 for _ in self.gen_vals[0]])\n",
    "\n",
    "    def print_losses(self) -> None:\n",
    "        r'''\n",
    "        Print training and validation losses for the last epoch\n",
    "        '''\n",
    "\n",
    "        p = f'Epoch {len(self.loss_vals[1])}: Training = {np.mean(self.loss_vals[0][-self.n_trn_flds:]):.2E}'\n",
    "        for v,m in zip(self.loss_vals[1:],self.loss_names[1:]): p += f' {m} = {v[-1]:.2E}'\n",
    "        for m,v in zip(self.metric_cbs, self.metric_vals): p += f' {m.name} = {v[-1]:.2E}'\n",
    "        print(p)\n",
    "\n",
    "    def update_plot(self) -> None:\n",
    "        r'''\n",
    "        Updates the plot(s).\n",
    "\n",
    "        # TODO: make this faster\n",
    "        '''\n",
    "\n",
    "        # Loss\n",
    "        self.loss_ax.clear()\n",
    "        with sns.axes_style(**self.plot_settings.style), sns.color_palette(self.plot_settings.cat_palette):\n",
    "            self.loss_ax.plot(range(1,len(self.loss_vals[0])+1), self.loss_vals[0], label=self.loss_names[0])\n",
    "            x = range(self.n_trn_flds, self.n_trn_flds*len(self.loss_vals[1])+1, self.n_trn_flds)\n",
    "            for v,m in zip(self.loss_vals[1:],self.loss_names[1:]):\n",
    "                self.loss_ax.plot(x, v, label=m)\n",
    "            self.loss_ax.plot([1,x[-1]], [self.best_loss,self.best_loss], label=f'Best = {self.best_loss:.3E}', linestyle='--')\n",
    "            if self.log:\n",
    "                self.loss_ax.set_yscale('log', nonposy='clip')\n",
    "                self.loss_ax.tick_params(axis='y', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col, which='both')\n",
    "            self.loss_ax.grid(True, which=\"both\")\n",
    "            self.loss_ax.legend(loc='upper right', fontsize=0.8*self.plot_settings.leg_sz)\n",
    "            self.loss_ax.set_xlabel('Sub-Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "            self.loss_ax.set_ylabel('Loss', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "\n",
    "        if self.extra_detail and len(self.loss_vals[1]) > 1:\n",
    "            # Velocity\n",
    "            self.vel_ax.clear()\n",
    "            self.vel_ax.tick_params(axis='y', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col, which='both')\n",
    "            self.vel_ax.grid(True, which=\"both\")\n",
    "            with sns.axes_style(**self.plot_settings.style), sns.color_palette(self.plot_settings.cat_palette) as palette:\n",
    "                for i, (v,m) in enumerate(zip(self.vel_vals,self.loss_names[1:])):\n",
    "                    self.vel_ax.plot(self.epochs[2:], v, label=f'{m} {v[-1]:.2E}', color=palette[i+1])\n",
    "                self.vel_ax.legend(loc='lower right', fontsize=0.8*self.plot_settings.leg_sz)\n",
    "                self.vel_ax.set_ylabel(r'$\\Delta \\bar{L}\\ /$ Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "\n",
    "            # Generalisation\n",
    "            self.gen_ax.clear()\n",
    "            self.gen_ax.grid(True, which=\"both\")\n",
    "            with sns.axes_style(**self.plot_settings.style), sns.color_palette(self.plot_settings.cat_palette) as palette:\n",
    "                for i, (v,m) in enumerate(zip(self.gen_vals,self.loss_names[1:])):\n",
    "                    self.gen_ax.plot(self.epochs[2:], v, label=f'{m} {v[-1]:.2f}', color=palette[i+1])\n",
    "                self.gen_ax.legend(loc='upper left', fontsize=0.8*self.plot_settings.leg_sz)\n",
    "                self.gen_ax.set_xlabel('Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                self.gen_ax.set_ylabel('Validation / Train', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                if len(self.epochs) > 8:  # For some reason this needs to be 2+number epochs to display...\n",
    "                    self.epochs = self.epochs[1:]\n",
    "                    for i in range(len(self.vel_vals)): self.vel_vals[i],self.gen_vals[i] = self.vel_vals[i][1:],self.gen_vals[i][1:]\n",
    "\n",
    "            # Metrics\n",
    "            if self.main_metric_idx is not None:\n",
    "                self.metric_ax.clear()\n",
    "                with sns.axes_style(**self.plot_settings.style), sns.color_palette(self.plot_settings.cat_palette) as palette:\n",
    "                    x = range(self.n_trn_flds, self.n_trn_flds*len(self.loss_vals[1])+1, self.n_trn_flds)\n",
    "                    y = self.metric_vals[self.main_metric_idx]\n",
    "                    self.metric_ax.plot(x, y, color=palette[1])\n",
    "                    best = np.nanmin(y) if self.metric_cbs[self.main_metric_idx].lower_metric_better else np.nanmax(y)\n",
    "                    self.metric_ax.plot([1,x[-1]], [best,best], label=f'Best = {best:.3E}', linestyle='--', color=palette[2])\n",
    "                    self.metric_ax.legend(loc='upper left', fontsize=0.8*self.plot_settings.leg_sz)\n",
    "                    self.metric_ax.grid(True, which=\"both\")\n",
    "                    self.metric_ax.set_xlabel('Sub-Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.metric_ax.set_ylabel(self.metric_cbs[self.main_metric_idx].name, fontsize=0.8*self.plot_settings.lbl_sz,\n",
    "                                              color=self.plot_settings.lbl_col)\n",
    "            \n",
    "            self.display.update(self.fig)\n",
    "        else:\n",
    "            self.display.update(self.loss_ax.figure)\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        self.loss_names = ['Training', 'Validation']\n",
    "        self.loss_vals = [[] for _ in self.loss_names]\n",
    "        self.vel_vals, self.gen_vals = [[] for _ in range(len(self.loss_names)-1)], [[] for _ in range(len(self.loss_names)-1)]\n",
    "        self.n_trn_flds = len(self.model.fit_params.trn_idxs)\n",
    "        self.log = 'regress' in self.model.objective.lower()\n",
    "        self.best_loss,self.epochs = math.inf,[0]\n",
    "\n",
    "        self.metric_cbs = []\n",
    "        for c in self.model.fit_params.cbs:\n",
    "            if hasattr(c, 'get_metric'):\n",
    "                self.metric_cbs.append(c)\n",
    "        self.metric_vals = [[] for _ in self.metric_cbs]\n",
    "        self.main_metric_idx = None\n",
    "        self.lock_to_metric = False\n",
    "        if len(self.metric_cbs) > 0:\n",
    "            self.main_metric_idx = 0\n",
    "            for i,c in enumerate(self.metric_cbs):\n",
    "                if c.main_metric:\n",
    "                    self.main_metric_idx = i\n",
    "                    self.lock_to_metric = True\n",
    "                    break\n",
    "\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.plot_settings.style):\n",
    "                if self.extra_detail:\n",
    "                    self.fig = plt.figure(figsize=(self.plot_settings.w_mid, self.plot_settings.h_mid), constrained_layout=True)\n",
    "                    gs = self.fig.add_gridspec(2, 3)\n",
    "                    if self.main_metric_idx is None:\n",
    "                        self.loss_ax = self.fig.add_subplot(gs[:,:-1])\n",
    "                    else:\n",
    "                        self.loss_ax = self.fig.add_subplot(gs[:1,:-1])\n",
    "                        self.metric_ax = self.fig.add_subplot(gs[1:2,:-1])\n",
    "                    self.vel_ax  = self.fig.add_subplot(gs[:1,2:])\n",
    "                    self.gen_ax  = self.fig.add_subplot(gs[1:2,2:])\n",
    "                    for ax in [self.loss_ax, self.vel_ax, self.gen_ax]:\n",
    "                        ax.tick_params(axis='x', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                        ax.tick_params(axis='y', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                    self.loss_ax.set_xlabel('Sub-Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.loss_ax.set_ylabel('Loss', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    if self.main_metric_idx is not None:\n",
    "                        self.metric_ax.tick_params(axis='x', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                        self.metric_ax.tick_params(axis='y', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                        self.metric_ax.set_xlabel('Sub-Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                        self.metric_ax.set_ylabel(self.metric_cbs[self.main_metric_idx].name, fontsize=0.8*self.plot_settings.lbl_sz,\n",
    "                                                  color=self.plot_settings.lbl_col)\n",
    "                    self.vel_ax.set_ylabel(r'$\\Delta \\bar{L}\\ /$ Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.gen_ax.set_xlabel('Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.gen_ax.set_ylabel('Validation / Train', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.display = display(self.fig, display_id=True)\n",
    "                else:\n",
    "                    self.fig, self.loss_ax = plt.subplots(1, figsize=(self.plot_settings.w_mid, self.plot_settings.h_mid))\n",
    "                    self.loss_ax.tick_params(axis='x', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                    self.loss_ax.tick_params(axis='y', labelsize=0.8*self.plot_settings.tk_sz, labelcolor=self.plot_settings.tk_col)\n",
    "                    self.loss_ax.set_xlabel('Sub-Epoch', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.loss_ax.set_ylabel('Loss', fontsize=0.8*self.plot_settings.lbl_sz, color=self.plot_settings.lbl_col)\n",
    "                    self.display = display(self.loss_ax.figure, display_id=True)\n",
    "\n",
    "    def get_loss_history(self) -> Tuple[OrderedDict,OrderedDict]:\n",
    "        r'''\n",
    "        Get the current history of losses and metrics\n",
    "\n",
    "        Returns:\n",
    "            history: tuple of ordered dictionaries: first with losses, second with validation metrics\n",
    "        '''\n",
    "\n",
    "        history = (OrderedDict(),OrderedDict())\n",
    "        for v,m in zip(self.loss_vals,self.loss_names): history[0][m] = v\n",
    "        for v,c in zip(self.metric_vals,self.metric_cbs): history[1][c.name] = v\n",
    "        return history\n",
    "\n",
    "    def get_results(self, save_best:bool) -> Dict[str,float]:\n",
    "        r'''\n",
    "        Returns losses and metrics of the (loaded) model\n",
    "\n",
    "        #TODO: extend this to load at specified index\n",
    "\n",
    "        Arguments:\n",
    "            save_best: if the training used :class:`~lumin.nn.callbacks.monitors.SaveBest` return results at best point else return the latest values\n",
    "\n",
    "        Returns:\n",
    "            dictionary of validation loss and metrics\n",
    "        '''\n",
    "\n",
    "        losses = np.array(self.loss_vals[1:])\n",
    "        metrics = np.array(self.metric_vals)\n",
    "        results = {}\n",
    "        \n",
    "        if save_best:\n",
    "            if self.main_metric_idx is None or not self.lock_to_metric or len(losses) > 1:  # Tracking SWA only supported for loss\n",
    "                idx = np.unravel_index(np.nanargmin(losses), losses.shape)[-1]\n",
    "                results['loss'] = np.nanmin(losses)\n",
    "            else:\n",
    "                idx = np.nanargmin(self.metric_vals[self.main_metric_idx]) if self.metric_cbs[self.main_metric_idx].lower_metric_better else \\\n",
    "                    np.nanargmax(self.metric_vals[self.main_metric_idx])\n",
    "                results['loss'] = losses[0][idx]\n",
    "        else:\n",
    "            results['loss'] = np.nanmin(losses[:,-1:])\n",
    "            idx = -1\n",
    "        if len(self.metric_cbs) > 0:\n",
    "            for c,v in zip(self.metric_cbs,metrics[:,idx]): results[c.name] = v\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MetricLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.fit(10, n_mu_per_volume=1000, mu_bs=100, trn_passives=trn_passives, val_passives=None, cbs=[NoMoreNaNs(),ml])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
