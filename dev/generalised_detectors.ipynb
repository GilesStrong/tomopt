{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.core import *\n",
    "from tomopt.optimisation import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-edc514db5f58>:4: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:23.)\n",
      "  x = torch.linspace(-10, 100*100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc549c71a00>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def area_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/1000)**2\n",
    "\n",
    "x = torch.linspace(-10, 100*100)\n",
    "plt.plot(x, area_cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = torch.distributions.Normal(Tensor([0.5,0.5]), Tensor([0.5,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5353])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(torch.exp(gauss.log_prob(Tensor([[0.5,0.5], [1,1]])))/torch.exp(gauss.log_prob(Tensor([0.5,0.5]))),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorPanel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        res: float,\n",
    "        eff: float,\n",
    "        init_xyz:Tuple[float,float,float],\n",
    "        init_xy_span: Tuple[float,float],\n",
    "        area_cost_func: Callable[[Tensor], Tensor],\n",
    "        device: torch.device = DEVICE\n",
    "    ):\n",
    "        if res <= 0:\n",
    "            raise ValueError(f'Resolution must be positive')\n",
    "        if eff <= 0:\n",
    "            raise ValueError(f'Efficiency must be positive')\n",
    "            \n",
    "        super().__init__()\n",
    "        self.area_cost_func, self.device = area_cost_func, device\n",
    "        self.register_buffer('resolution', torch.tensor(float(res), requires_grad=True, device=self.device))\n",
    "        self.register_buffer('efficiency', torch.tensor(float(eff), requires_grad=True, device=self.device))\n",
    "        self.xyz = nn.Parameter(torch.tensor(init_xyz, device=self.device))\n",
    "        self.xy_span = nn.Parameter(torch.tensor(init_xy_span, device=self.device))\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'''{self.__class__} located at {self.xyz.data}, and xy span {self.xy_span}'''\n",
    "    \n",
    "    def get_xy_mask(self, xy: Tensor) -> Tensor:\n",
    "        xy_low = self.xy-(self.xy_span/2)\n",
    "        xy_high = self.xy+(self.xy_span/2)\n",
    "        return (xy[:,0] >= xy_low[0]) * (xy[:,0] < xy_high[0]) * (xy[:,1] >= xy_low[1]) * (xy[:,1] < xy_high[1])\n",
    "    \n",
    "    def get_resolution(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training:\n",
    "            gauss = torch.distributions.Normal(self.xy, self.xy_span)  # maybe upscale span?\n",
    "            res = self.resolution*torch.exp(gauss.log_prob(xy))/torch.exp(gauss.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            res = torch.zeros((len(xy),2), device=self.device)  # Zero detection outside detector\n",
    "            res[mask] = self.resolution\n",
    "        return res\n",
    "    \n",
    "    def get_efficiency(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training:\n",
    "            gauss = torch.distributions.Normal(self.xy, self.xy_span)  # maybe upscale span?\n",
    "            scale = torch.exp(gauss.log_prob(xy))/torch.exp(gauss.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "            eff = self.efficiency*torch.prod(scale, dim=-1)  # Maybe weight product by xy distance?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            eff = torch.zeros(len(xy), device=self.device)  # Zero detection outside detector\n",
    "            eff[mask] = self.efficiency\n",
    "        return eff\n",
    "        \n",
    "    def get_hits(self, mu: MuonBatch) -> Dict[str, Tensor]:\n",
    "        mask = mu.get_xy_mask(self.xy-(self.xy_span/2), self.xy+(self.xy_span/2))  # Muons in panel\n",
    "        \n",
    "        xy0 = self.xy-(self.xy_span/2)  # Low-left of voxel\n",
    "        rel_xy = mu.xy - xy0\n",
    "        res = self.get_resolution(mu.xy, mask)        \n",
    "        rel_xy = rel_xy + (torch.randn((len(mu), 2), device=self.device) / res)\n",
    "        \n",
    "        if not self.training:  # Prevent reco hit from exiting panel\n",
    "            span = self.xy_span.detach().cpu().numpy()\n",
    "            rel_xy[mask] = torch.stack([torch.clamp(rel_xy[mask][:,0], 0, span[0]),\n",
    "                                        torch.clamp(rel_xy[mask][:,1], 0, span[1])], dim=-1)  \n",
    "        reco_xy = xy0 + rel_xy\n",
    "\n",
    "        hits = {\n",
    "            \"reco_xy\": reco_xy,\n",
    "            \"gen_xy\": mu.xy,\n",
    "            \"z\": self.z.expand_as(mu.x)[:, None],\n",
    "        }\n",
    "        return hits\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        return self.area_cost_func(self.xy_span.prod())\n",
    "    \n",
    "    @property\n",
    "    def xy(self) -> Tensor:\n",
    "        return self.xyz[:2]\n",
    "    \n",
    "    @property\n",
    "    def z(self) -> Tensor:\n",
    "        return self.xyz[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume.layer import Layer\n",
    "\n",
    "class DetectorLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pos: str,\n",
    "        lw: Tensor,\n",
    "        z: float,\n",
    "        size: float,\n",
    "        panels: nn.ModuleList,\n",
    "        device: torch.device = DEVICE,\n",
    "    ):\n",
    "        super().__init__(lw=lw, z=z, size=size, device=device)\n",
    "        if isinstance(panels, list):\n",
    "            panels = nn.ModuleList(panels)\n",
    "        self.pos, self.panels = pos, panels\n",
    "    \n",
    "    def get_panel_zorder(self) -> List[int]:\n",
    "        return np.argsort([p.z.detach().cpu().item() for p in self.panels])[::-1]\n",
    "        \n",
    "    def check_panels(self) -> None:\n",
    "        with torch.no_grad(): \n",
    "            for p in self.panels:\n",
    "                torch.clamp_(p.z, min=self.z.detach().cpu()[0]-self.size, max=self.z.detach().cpu()[0])\n",
    "\n",
    "    def forward(self, mu: MuonBatch) -> None:\n",
    "        self.check_panels()\n",
    "        for i in self.get_panel_zorder():\n",
    "            self.scatter_and_propagate(mu, mu.z-self.panels[i].z)  # Move to panel\n",
    "            mu.append_hits(self.panels[i].get_hits(mu), self.pos)\n",
    "        self.scatter_and_propagate(mu, mu.z-(self.z-self.size))  # Move to bottom of layer\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        for i, p in enumerate(self.panels):\n",
    "            cost = p.get_cost() if i == 0 else cost + p.get_cost()\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = nn.ModuleList([DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,0.95], init_xy_span=[0.5,0.5], area_cost_func=area_cost),\n",
    "          DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,1], init_xy_span=[0.5,0.5], area_cost_func=area_cost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reco_xy': tensor([[0.8537, 0.3913],\n",
       "         [0.5144, 0.1396],\n",
       "         [0.6477, 0.0123],\n",
       "         [0.6648, 0.5230],\n",
       "         [0.5296, 0.3103],\n",
       "         [0.0233, 0.0278],\n",
       "         [0.4278, 0.3119],\n",
       "         [0.9979, 0.8233],\n",
       "         [0.2812, 0.4295],\n",
       "         [0.3095, 0.5282],\n",
       "         [0.5817, 0.6820],\n",
       "         [0.2556, 0.2778],\n",
       "         [0.1383, 0.8353],\n",
       "         [0.1377, 0.9950],\n",
       "         [0.9907, 0.5764],\n",
       "         [0.5002, 0.2260],\n",
       "         [0.5969, 0.6513],\n",
       "         [0.8109, 0.4266],\n",
       "         [0.7520, 0.7530],\n",
       "         [0.0809, 0.7013],\n",
       "         [0.2711, 0.5733],\n",
       "         [0.8446, 0.5537],\n",
       "         [0.8130, 0.5741],\n",
       "         [0.6924, 0.1557],\n",
       "         [0.1481, 0.5860],\n",
       "         [0.0105, 0.4562],\n",
       "         [0.4795, 0.3550],\n",
       "         [0.5641, 0.1796],\n",
       "         [0.7572, 0.0948],\n",
       "         [0.3441, 0.5539],\n",
       "         [0.6536, 0.4874],\n",
       "         [0.0428, 0.7446],\n",
       "         [0.6943, 0.1368],\n",
       "         [0.6070, 0.9627],\n",
       "         [0.4143, 0.7163],\n",
       "         [0.3070, 0.2140],\n",
       "         [0.1405, 0.7320],\n",
       "         [0.9845, 0.3376],\n",
       "         [0.5464, 0.1693],\n",
       "         [0.1029, 0.0522],\n",
       "         [0.0376, 0.0435],\n",
       "         [0.1704, 0.2459],\n",
       "         [0.2417, 0.8620],\n",
       "         [0.4098, 0.6182],\n",
       "         [0.5327, 0.4347],\n",
       "         [0.3757, 0.7202],\n",
       "         [0.7269, 0.5973],\n",
       "         [0.9229, 0.7068],\n",
       "         [0.4764, 0.2281],\n",
       "         [0.2326, 0.2339],\n",
       "         [0.5673, 0.7940],\n",
       "         [0.5031, 0.7443],\n",
       "         [0.4288, 0.3597],\n",
       "         [0.6017, 0.8430],\n",
       "         [0.1728, 0.8093],\n",
       "         [0.7960, 0.7365],\n",
       "         [0.4104, 0.0951],\n",
       "         [0.8036, 0.0810],\n",
       "         [0.8216, 0.4957],\n",
       "         [0.9295, 0.1246],\n",
       "         [0.7196, 0.9112],\n",
       "         [0.5603, 0.3497],\n",
       "         [0.9911, 0.1271],\n",
       "         [0.1853, 0.5059],\n",
       "         [0.0332, 0.7416],\n",
       "         [0.6803, 0.2764],\n",
       "         [0.8365, 0.6180],\n",
       "         [0.7900, 0.8759],\n",
       "         [0.5902, 0.1362],\n",
       "         [0.5133, 0.0021],\n",
       "         [0.8283, 0.1794],\n",
       "         [0.9123, 0.7177],\n",
       "         [0.6426, 0.2239],\n",
       "         [0.6099, 0.1603],\n",
       "         [0.9859, 0.8267],\n",
       "         [0.9264, 0.0124],\n",
       "         [0.7536, 0.8041],\n",
       "         [0.8280, 0.4219],\n",
       "         [0.0145, 0.6317],\n",
       "         [0.0307, 0.9785],\n",
       "         [0.2655, 0.4406],\n",
       "         [0.2122, 0.4924],\n",
       "         [0.5982, 0.9246],\n",
       "         [0.1210, 0.8139],\n",
       "         [0.6844, 0.2984],\n",
       "         [0.9238, 0.2481],\n",
       "         [0.4119, 0.1241],\n",
       "         [0.3129, 0.0519],\n",
       "         [0.9843, 0.5323],\n",
       "         [0.1320, 0.6433],\n",
       "         [0.9330, 0.7372],\n",
       "         [0.2042, 0.7620],\n",
       "         [0.9613, 0.3797],\n",
       "         [0.7377, 0.3254],\n",
       "         [0.5959, 0.6338],\n",
       "         [0.9298, 0.0750],\n",
       "         [0.5834, 0.8175],\n",
       "         [0.6111, 0.0155],\n",
       "         [0.8488, 0.9726],\n",
       "         [0.7633, 0.7727]], grad_fn=<AddBackward0>),\n",
       " 'gen_xy': tensor([[0.8539, 0.3912],\n",
       "         [0.5144, 0.1394],\n",
       "         [0.6475, 0.0121],\n",
       "         [0.6649, 0.5229],\n",
       "         [0.5295, 0.3102],\n",
       "         [0.0232, 0.0278],\n",
       "         [0.4278, 0.3117],\n",
       "         [0.9976, 0.8233],\n",
       "         [0.2812, 0.4295],\n",
       "         [0.3095, 0.5282],\n",
       "         [0.5818, 0.6822],\n",
       "         [0.2553, 0.2778],\n",
       "         [0.1383, 0.8354],\n",
       "         [0.1378, 0.9950],\n",
       "         [0.9907, 0.5762],\n",
       "         [0.5003, 0.2259],\n",
       "         [0.5970, 0.6513],\n",
       "         [0.8108, 0.4266],\n",
       "         [0.7520, 0.7529],\n",
       "         [0.0808, 0.7015],\n",
       "         [0.2710, 0.5732],\n",
       "         [0.8445, 0.5537],\n",
       "         [0.8130, 0.5740],\n",
       "         [0.6926, 0.1557],\n",
       "         [0.1481, 0.5862],\n",
       "         [0.0105, 0.4563],\n",
       "         [0.4794, 0.3551],\n",
       "         [0.5641, 0.1795],\n",
       "         [0.7573, 0.0947],\n",
       "         [0.3440, 0.5538],\n",
       "         [0.6535, 0.4873],\n",
       "         [0.0426, 0.7444],\n",
       "         [0.6942, 0.1369],\n",
       "         [0.6072, 0.9624],\n",
       "         [0.4143, 0.7165],\n",
       "         [0.3071, 0.2141],\n",
       "         [0.1407, 0.7320],\n",
       "         [0.9842, 0.3376],\n",
       "         [0.5466, 0.1695],\n",
       "         [0.1028, 0.0521],\n",
       "         [0.0375, 0.0435],\n",
       "         [0.1705, 0.2458],\n",
       "         [0.2418, 0.8617],\n",
       "         [0.4098, 0.6182],\n",
       "         [0.5327, 0.4347],\n",
       "         [0.3758, 0.7201],\n",
       "         [0.7271, 0.5972],\n",
       "         [0.9230, 0.7067],\n",
       "         [0.4765, 0.2280],\n",
       "         [0.2326, 0.2339],\n",
       "         [0.5672, 0.7942],\n",
       "         [0.5029, 0.7444],\n",
       "         [0.4288, 0.3597],\n",
       "         [0.6017, 0.8428],\n",
       "         [0.1727, 0.8093],\n",
       "         [0.7961, 0.7365],\n",
       "         [0.4105, 0.0952],\n",
       "         [0.8036, 0.0812],\n",
       "         [0.8215, 0.4956],\n",
       "         [0.9293, 0.1245],\n",
       "         [0.7197, 0.9110],\n",
       "         [0.5603, 0.3497],\n",
       "         [0.9912, 0.1272],\n",
       "         [0.1851, 0.5059],\n",
       "         [0.0330, 0.7416],\n",
       "         [0.6804, 0.2765],\n",
       "         [0.8366, 0.6181],\n",
       "         [0.7900, 0.8758],\n",
       "         [0.5901, 0.1362],\n",
       "         [0.5133, 0.0022],\n",
       "         [0.8283, 0.1794],\n",
       "         [0.9124, 0.7176],\n",
       "         [0.6424, 0.2239],\n",
       "         [0.6099, 0.1603],\n",
       "         [0.9858, 0.8268],\n",
       "         [0.9264, 0.0122],\n",
       "         [0.7536, 0.8041],\n",
       "         [0.8280, 0.4217],\n",
       "         [0.0146, 0.6315],\n",
       "         [0.0307, 0.9789],\n",
       "         [0.2654, 0.4407],\n",
       "         [0.2123, 0.4925],\n",
       "         [0.5981, 0.9246],\n",
       "         [0.1211, 0.8141],\n",
       "         [0.6845, 0.2985],\n",
       "         [0.9237, 0.2480],\n",
       "         [0.4119, 0.1240],\n",
       "         [0.3129, 0.0520],\n",
       "         [0.9842, 0.5323],\n",
       "         [0.1321, 0.6433],\n",
       "         [0.9329, 0.7374],\n",
       "         [0.2043, 0.7619],\n",
       "         [0.9614, 0.3797],\n",
       "         [0.7378, 0.3254],\n",
       "         [0.5958, 0.6339],\n",
       "         [0.9301, 0.0750],\n",
       "         [0.5834, 0.8174],\n",
       "         [0.6111, 0.0156],\n",
       "         [0.8491, 0.9724],\n",
       "         [0.7633, 0.7729]]),\n",
       " 'z': tensor([[0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500]], grad_fn=<UnsqueezeBackward0>)}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panels[0].get_hits(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DetectorLayer(pos='above', lw=Tensor([1,1]), z=1, size=0.1, panels=panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2500e-07, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_panel_zorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9500]), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       "  (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 1.0000]), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       ")"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tomopt.muon.muon_batch.MuonBatch.__init__.<locals>.<lambda>()>,\n",
       "            {'above': defaultdict(list,\n",
       "                         {'reco_xy': [tensor([[0.8539, 0.3912],\n",
       "                                   [0.5144, 0.1395],\n",
       "                                   [0.6473, 0.0123],\n",
       "                                   [0.6649, 0.5231],\n",
       "                                   [0.5294, 0.3103],\n",
       "                                   [0.0230, 0.0281],\n",
       "                                   [0.4280, 0.3116],\n",
       "                                   [0.9977, 0.8231],\n",
       "                                   [0.2811, 0.4296],\n",
       "                                   [0.3094, 0.5281],\n",
       "                                   [0.5818, 0.6822],\n",
       "                                   [0.2553, 0.2778],\n",
       "                                   [0.1382, 0.8355],\n",
       "                                   [0.1375, 0.9951],\n",
       "                                   [0.9905, 0.5761],\n",
       "                                   [0.5002, 0.2258],\n",
       "                                   [0.5970, 0.6512],\n",
       "                                   [0.8110, 0.4264],\n",
       "                                   [0.7520, 0.7531],\n",
       "                                   [0.0806, 0.7014],\n",
       "                                   [0.2712, 0.5732],\n",
       "                                   [0.8446, 0.5539],\n",
       "                                   [0.8130, 0.5740],\n",
       "                                   [0.6925, 0.1557],\n",
       "                                   [0.1480, 0.5861],\n",
       "                                   [0.0103, 0.4561],\n",
       "                                   [0.4793, 0.3550],\n",
       "                                   [0.5641, 0.1793],\n",
       "                                   [0.7574, 0.0949],\n",
       "                                   [0.3439, 0.5538],\n",
       "                                   [0.6535, 0.4873],\n",
       "                                   [0.0427, 0.7443],\n",
       "                                   [0.6943, 0.1367],\n",
       "                                   [0.6073, 0.9622],\n",
       "                                   [0.4141, 0.7168],\n",
       "                                   [0.3072, 0.2142],\n",
       "                                   [0.1409, 0.7321],\n",
       "                                   [0.9844, 0.3376],\n",
       "                                   [0.5467, 0.1695],\n",
       "                                   [0.1027, 0.0525],\n",
       "                                   [0.0378, 0.0435],\n",
       "                                   [0.1705, 0.2458],\n",
       "                                   [0.2418, 0.8616],\n",
       "                                   [0.4095, 0.6183],\n",
       "                                   [0.5327, 0.4346],\n",
       "                                   [0.3756, 0.7201],\n",
       "                                   [0.7270, 0.5973],\n",
       "                                   [0.9231, 0.7066],\n",
       "                                   [0.4766, 0.2280],\n",
       "                                   [0.2327, 0.2339],\n",
       "                                   [0.5673, 0.7943],\n",
       "                                   [0.5030, 0.7444],\n",
       "                                   [0.4288, 0.3595],\n",
       "                                   [0.6016, 0.8428],\n",
       "                                   [0.1728, 0.8094],\n",
       "                                   [0.7962, 0.7365],\n",
       "                                   [0.4107, 0.0950],\n",
       "                                   [0.8037, 0.0815],\n",
       "                                   [0.8214, 0.4955],\n",
       "                                   [0.9293, 0.1245],\n",
       "                                   [0.7196, 0.9109],\n",
       "                                   [0.5603, 0.3498],\n",
       "                                   [0.9910, 0.1273],\n",
       "                                   [0.1855, 0.5061],\n",
       "                                   [0.0328, 0.7416],\n",
       "                                   [0.6804, 0.2764],\n",
       "                                   [0.8364, 0.6180],\n",
       "                                   [0.7900, 0.8759],\n",
       "                                   [0.5901, 0.1360],\n",
       "                                   [0.5133, 0.0020],\n",
       "                                   [0.8281, 0.1795],\n",
       "                                   [0.9121, 0.7174],\n",
       "                                   [0.6423, 0.2238],\n",
       "                                   [0.6100, 0.1605],\n",
       "                                   [0.9858, 0.8268],\n",
       "                                   [0.9263, 0.0122],\n",
       "                                   [0.7538, 0.8042],\n",
       "                                   [0.8281, 0.4217],\n",
       "                                   [0.0146, 0.6315],\n",
       "                                   [0.0303, 0.9792],\n",
       "                                   [0.2655, 0.4407],\n",
       "                                   [0.2122, 0.4924],\n",
       "                                   [0.5979, 0.9245],\n",
       "                                   [0.1210, 0.8142],\n",
       "                                   [0.6844, 0.2983],\n",
       "                                   [0.9236, 0.2479],\n",
       "                                   [0.4119, 0.1240],\n",
       "                                   [0.3131, 0.0519],\n",
       "                                   [0.9840, 0.5320],\n",
       "                                   [0.1320, 0.6431],\n",
       "                                   [0.9332, 0.7377],\n",
       "                                   [0.2044, 0.7621],\n",
       "                                   [0.9611, 0.3798],\n",
       "                                   [0.7377, 0.3254],\n",
       "                                   [0.5957, 0.6339],\n",
       "                                   [0.9302, 0.0746],\n",
       "                                   [0.5834, 0.8173],\n",
       "                                   [0.6109, 0.0156],\n",
       "                                   [0.8490, 0.9726],\n",
       "                                   [0.7633, 0.7729]], grad_fn=<AddBackward0>),\n",
       "                           tensor([[0.8503, 0.3877],\n",
       "                                   [0.5210, 0.1397],\n",
       "                                   [0.6428, 0.0130],\n",
       "                                   [0.6722, 0.5220],\n",
       "                                   [0.5261, 0.3129],\n",
       "                                   [0.0227, 0.0361],\n",
       "                                   [0.4329, 0.3096],\n",
       "                                   [0.9966, 0.8240],\n",
       "                                   [0.2770, 0.4269],\n",
       "                                   [0.3195, 0.5197],\n",
       "                                   [0.5795, 0.6784],\n",
       "                                   [0.2629, 0.2756],\n",
       "                                   [0.1319, 0.8329],\n",
       "                                   [0.1295, 1.0038],\n",
       "                                   [0.9966, 0.5755],\n",
       "                                   [0.4993, 0.2285],\n",
       "                                   [0.6031, 0.6473],\n",
       "                                   [0.8027, 0.4264],\n",
       "                                   [0.7518, 0.7540],\n",
       "                                   [0.0812, 0.6965],\n",
       "                                   [0.2610, 0.5733],\n",
       "                                   [0.8401, 0.5528],\n",
       "                                   [0.8068, 0.5682],\n",
       "                                   [0.6945, 0.1634],\n",
       "                                   [0.1426, 0.5862],\n",
       "                                   [0.0129, 0.4611],\n",
       "                                   [0.4877, 0.3595],\n",
       "                                   [0.5674, 0.1735],\n",
       "                                   [0.7551, 0.0943],\n",
       "                                   [0.3465, 0.5568],\n",
       "                                   [0.6530, 0.4897],\n",
       "                                   [0.0403, 0.7383],\n",
       "                                   [0.6933, 0.1406],\n",
       "                                   [0.6131, 0.9665],\n",
       "                                   [0.4031, 0.7130],\n",
       "                                   [0.3102, 0.2092],\n",
       "                                   [0.1431, 0.7279],\n",
       "                                   [0.9770, 0.3401],\n",
       "                                   [0.5384, 0.1702],\n",
       "                                   [0.1092, 0.0521],\n",
       "                                   [0.0300, 0.0421],\n",
       "                                   [0.1649, 0.2559],\n",
       "                                   [0.2380, 0.8671],\n",
       "                                   [0.4107, 0.6154],\n",
       "                                   [0.5419, 0.4357],\n",
       "                                   [0.3753, 0.7133],\n",
       "                                   [0.7248, 0.5931],\n",
       "                                   [0.9179, 0.7007],\n",
       "                                   [0.4759, 0.2239],\n",
       "                                   [0.2278, 0.2277],\n",
       "                                   [0.5643, 0.7892],\n",
       "                                   [0.5058, 0.7380],\n",
       "                                   [0.4217, 0.3605],\n",
       "                                   [0.6048, 0.8380],\n",
       "                                   [0.1764, 0.8174],\n",
       "                                   [0.7985, 0.7344],\n",
       "                                   [0.4151, 0.0980],\n",
       "                                   [0.8060, 0.0781],\n",
       "                                   [0.8251, 0.5040],\n",
       "                                   [0.9284, 0.1255],\n",
       "                                   [0.7213, 0.9165],\n",
       "                                   [0.5568, 0.3506],\n",
       "                                   [0.9865, 0.1289],\n",
       "                                   [0.1754, 0.5075],\n",
       "                                   [0.0445, 0.7384],\n",
       "                                   [0.6865, 0.2749],\n",
       "                                   [0.8379, 0.6198],\n",
       "                                   [0.7850, 0.8781],\n",
       "                                   [0.5921, 0.1394],\n",
       "                                   [0.5185, 0.0032],\n",
       "                                   [0.8295, 0.1764],\n",
       "                                   [0.9045, 0.7128],\n",
       "                                   [0.6471, 0.2246],\n",
       "                                   [0.6115, 0.1500],\n",
       "                                   [0.9925, 0.8304],\n",
       "                                   [0.9250, 0.0198],\n",
       "                                   [0.7452, 0.8017],\n",
       "                                   [0.8264, 0.4286],\n",
       "                                   [0.0172, 0.6288],\n",
       "                                   [0.0351, 0.9820],\n",
       "                                   [0.2716, 0.4401],\n",
       "                                   [0.2119, 0.5056],\n",
       "                                   [0.6015, 0.9226],\n",
       "                                   [0.1250, 0.8112],\n",
       "                                   [0.6849, 0.2870],\n",
       "                                   [0.9291, 0.2641],\n",
       "                                   [0.4096, 0.1203],\n",
       "                                   [0.3123, 0.0446],\n",
       "                                   [0.9843, 0.5330],\n",
       "                                   [0.1346, 0.6496],\n",
       "                                   [0.9386, 0.7337],\n",
       "                                   [0.2033, 0.7728],\n",
       "                                   [0.9588, 0.3754],\n",
       "                                   [0.7383, 0.3173],\n",
       "                                   [0.5965, 0.6314],\n",
       "                                   [0.9319, 0.0711],\n",
       "                                   [0.5790, 0.8216],\n",
       "                                   [0.6072, 0.0120],\n",
       "                                   [0.8430, 0.9739],\n",
       "                                   [0.7671, 0.7625]], grad_fn=<AddBackward0>)],\n",
       "                          'gen_xy': [tensor([[0.8467, 0.3842],\n",
       "                                   [0.5277, 0.1402],\n",
       "                                   [0.6383, 0.0134],\n",
       "                                   [0.6795, 0.5214],\n",
       "                                   [0.5229, 0.3157],\n",
       "                                   [0.0227, 0.0444],\n",
       "                                   [0.4381, 0.3074],\n",
       "                                   [0.9957, 0.8242],\n",
       "                                   [0.2727, 0.4243],\n",
       "                                   [0.3300, 0.5114],\n",
       "                                   [0.5766, 0.6750],\n",
       "                                   [0.2704, 0.2737],\n",
       "                                   [0.1254, 0.8306],\n",
       "                                   [0.1214, 1.0125],\n",
       "                                   [1.0024, 0.5743],\n",
       "                                   [0.4984, 0.2309],\n",
       "                                   [0.6098, 0.6434],\n",
       "                                   [0.7947, 0.4263],\n",
       "                                   [0.7511, 0.7551],\n",
       "                                   [0.0816, 0.6912],\n",
       "                                   [0.2511, 0.5736],\n",
       "                                   [0.8357, 0.5520],\n",
       "                                   [0.8006, 0.5624],\n",
       "                                   [0.6966, 0.1710],\n",
       "                                   [0.1371, 0.5861],\n",
       "                                   [0.0154, 0.4661],\n",
       "                                   [0.4961, 0.3641],\n",
       "                                   [0.5710, 0.1674],\n",
       "                                   [0.7527, 0.0941],\n",
       "                                   [0.3492, 0.5599],\n",
       "                                   [0.6525, 0.4921],\n",
       "                                   [0.0380, 0.7321],\n",
       "                                   [0.6930, 0.1444],\n",
       "                                   [0.6187, 0.9703],\n",
       "                                   [0.3918, 0.7093],\n",
       "                                   [0.3137, 0.2045],\n",
       "                                   [0.1453, 0.7237],\n",
       "                                   [0.9698, 0.3425],\n",
       "                                   [0.5302, 0.1710],\n",
       "                                   [0.1156, 0.0524],\n",
       "                                   [0.0230, 0.0407],\n",
       "                                   [0.1588, 0.2660],\n",
       "                                   [0.2343, 0.8723],\n",
       "                                   [0.4117, 0.6127],\n",
       "                                   [0.5512, 0.4363],\n",
       "                                   [0.3748, 0.7064],\n",
       "                                   [0.7230, 0.5889],\n",
       "                                   [0.9126, 0.6948],\n",
       "                                   [0.4750, 0.2197],\n",
       "                                   [0.2227, 0.2216],\n",
       "                                   [0.5616, 0.7840],\n",
       "                                   [0.5086, 0.7317],\n",
       "                                   [0.4150, 0.3614],\n",
       "                                   [0.6079, 0.8334],\n",
       "                                   [0.1802, 0.8255],\n",
       "                                   [0.8006, 0.7322],\n",
       "                                   [0.4198, 0.1011],\n",
       "                                   [0.8081, 0.0753],\n",
       "                                   [0.8288, 0.5121],\n",
       "                                   [0.9273, 0.1262],\n",
       "                                   [0.7231, 0.9215],\n",
       "                                   [0.5536, 0.3515],\n",
       "                                   [0.9818, 0.1310],\n",
       "                                   [0.1659, 0.5092],\n",
       "                                   [0.0559, 0.7353],\n",
       "                                   [0.6928, 0.2732],\n",
       "                                   [0.8394, 0.6216],\n",
       "                                   [0.7801, 0.8802],\n",
       "                                   [0.5943, 0.1428],\n",
       "                                   [0.5235, 0.0043],\n",
       "                                   [0.8308, 0.1734],\n",
       "                                   [0.8966, 0.7080],\n",
       "                                   [0.6516, 0.2253],\n",
       "                                   [0.6128, 0.1395],\n",
       "                                   [0.9990, 0.8342],\n",
       "                                   [0.9240, 0.0280],\n",
       "                                   [0.7370, 0.7993],\n",
       "                                   [0.8250, 0.4354],\n",
       "                                   [0.0202, 0.6261],\n",
       "                                   [0.0390, 0.9851],\n",
       "                                   [0.2778, 0.4391],\n",
       "                                   [0.2112, 0.5189],\n",
       "                                   [0.6048, 0.9205],\n",
       "                                   [0.1287, 0.8088],\n",
       "                                   [0.6855, 0.2753],\n",
       "                                   [0.9346, 0.2800],\n",
       "                                   [0.4070, 0.1164],\n",
       "                                   [0.3119, 0.0370],\n",
       "                                   [0.9845, 0.5334],\n",
       "                                   [0.1368, 0.6561],\n",
       "                                   [0.9442, 0.7299],\n",
       "                                   [0.2023, 0.7838],\n",
       "                                   [0.9572, 0.3710],\n",
       "                                   [0.7390, 0.3092],\n",
       "                                   [0.5974, 0.6291],\n",
       "                                   [0.9338, 0.0671],\n",
       "                                   [0.5746, 0.8254],\n",
       "                                   [0.6030, 0.0089],\n",
       "                                   [0.8368, 0.9754],\n",
       "                                   [0.7708, 0.7515]], grad_fn=<AsStridedBackward>),\n",
       "                           tensor([[0.8467, 0.3842],\n",
       "                                   [0.5277, 0.1402],\n",
       "                                   [0.6383, 0.0134],\n",
       "                                   [0.6795, 0.5214],\n",
       "                                   [0.5229, 0.3157],\n",
       "                                   [0.0227, 0.0444],\n",
       "                                   [0.4381, 0.3074],\n",
       "                                   [0.9957, 0.8242],\n",
       "                                   [0.2727, 0.4243],\n",
       "                                   [0.3300, 0.5114],\n",
       "                                   [0.5766, 0.6750],\n",
       "                                   [0.2704, 0.2737],\n",
       "                                   [0.1254, 0.8306],\n",
       "                                   [0.1214, 1.0125],\n",
       "                                   [1.0024, 0.5743],\n",
       "                                   [0.4984, 0.2309],\n",
       "                                   [0.6098, 0.6434],\n",
       "                                   [0.7947, 0.4263],\n",
       "                                   [0.7511, 0.7551],\n",
       "                                   [0.0816, 0.6912],\n",
       "                                   [0.2511, 0.5736],\n",
       "                                   [0.8357, 0.5520],\n",
       "                                   [0.8006, 0.5624],\n",
       "                                   [0.6966, 0.1710],\n",
       "                                   [0.1371, 0.5861],\n",
       "                                   [0.0154, 0.4661],\n",
       "                                   [0.4961, 0.3641],\n",
       "                                   [0.5710, 0.1674],\n",
       "                                   [0.7527, 0.0941],\n",
       "                                   [0.3492, 0.5599],\n",
       "                                   [0.6525, 0.4921],\n",
       "                                   [0.0380, 0.7321],\n",
       "                                   [0.6930, 0.1444],\n",
       "                                   [0.6187, 0.9703],\n",
       "                                   [0.3918, 0.7093],\n",
       "                                   [0.3137, 0.2045],\n",
       "                                   [0.1453, 0.7237],\n",
       "                                   [0.9698, 0.3425],\n",
       "                                   [0.5302, 0.1710],\n",
       "                                   [0.1156, 0.0524],\n",
       "                                   [0.0230, 0.0407],\n",
       "                                   [0.1588, 0.2660],\n",
       "                                   [0.2343, 0.8723],\n",
       "                                   [0.4117, 0.6127],\n",
       "                                   [0.5512, 0.4363],\n",
       "                                   [0.3748, 0.7064],\n",
       "                                   [0.7230, 0.5889],\n",
       "                                   [0.9126, 0.6948],\n",
       "                                   [0.4750, 0.2197],\n",
       "                                   [0.2227, 0.2216],\n",
       "                                   [0.5616, 0.7840],\n",
       "                                   [0.5086, 0.7317],\n",
       "                                   [0.4150, 0.3614],\n",
       "                                   [0.6079, 0.8334],\n",
       "                                   [0.1802, 0.8255],\n",
       "                                   [0.8006, 0.7322],\n",
       "                                   [0.4198, 0.1011],\n",
       "                                   [0.8081, 0.0753],\n",
       "                                   [0.8288, 0.5121],\n",
       "                                   [0.9273, 0.1262],\n",
       "                                   [0.7231, 0.9215],\n",
       "                                   [0.5536, 0.3515],\n",
       "                                   [0.9818, 0.1310],\n",
       "                                   [0.1659, 0.5092],\n",
       "                                   [0.0559, 0.7353],\n",
       "                                   [0.6928, 0.2732],\n",
       "                                   [0.8394, 0.6216],\n",
       "                                   [0.7801, 0.8802],\n",
       "                                   [0.5943, 0.1428],\n",
       "                                   [0.5235, 0.0043],\n",
       "                                   [0.8308, 0.1734],\n",
       "                                   [0.8966, 0.7080],\n",
       "                                   [0.6516, 0.2253],\n",
       "                                   [0.6128, 0.1395],\n",
       "                                   [0.9990, 0.8342],\n",
       "                                   [0.9240, 0.0280],\n",
       "                                   [0.7370, 0.7993],\n",
       "                                   [0.8250, 0.4354],\n",
       "                                   [0.0202, 0.6261],\n",
       "                                   [0.0390, 0.9851],\n",
       "                                   [0.2778, 0.4391],\n",
       "                                   [0.2112, 0.5189],\n",
       "                                   [0.6048, 0.9205],\n",
       "                                   [0.1287, 0.8088],\n",
       "                                   [0.6855, 0.2753],\n",
       "                                   [0.9346, 0.2800],\n",
       "                                   [0.4070, 0.1164],\n",
       "                                   [0.3119, 0.0370],\n",
       "                                   [0.9845, 0.5334],\n",
       "                                   [0.1368, 0.6561],\n",
       "                                   [0.9442, 0.7299],\n",
       "                                   [0.2023, 0.7838],\n",
       "                                   [0.9572, 0.3710],\n",
       "                                   [0.7390, 0.3092],\n",
       "                                   [0.5974, 0.6291],\n",
       "                                   [0.9338, 0.0671],\n",
       "                                   [0.5746, 0.8254],\n",
       "                                   [0.6030, 0.0089],\n",
       "                                   [0.8368, 0.9754],\n",
       "                                   [0.7708, 0.7515]], grad_fn=<AsStridedBackward>)],\n",
       "                          'z': [tensor([[1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.]], grad_fn=<UnsqueezeBackward0>),\n",
       "                           tensor([[0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500]], grad_fn=<UnsqueezeBackward0>)]})})"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    pos = 'above'\n",
    "    n_panels = 4\n",
    "    for z,d in zip(np.arange(lwh[2],0,-size), [1,0,0,0,0,0,0,1]):\n",
    "        if d:\n",
    "            layers.append(DetectorLayer(pos=pos, lw=lwh[:2], z=z, size=2*size,\n",
    "                                        panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                              init_xyz=[0.5,0.5,z-(i*(2*size)/n_panels)], init_xy_span=[0.5,0.5],\n",
    "                                                              area_cost_func=area_cost) for i in range(n_panels)]))\n",
    "        else:\n",
    "            pos = 'below'\n",
    "            layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volume(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        if isinstance(layers, list):\n",
    "            layers = nn.ModuleList(layers)\n",
    "        self.layers = layers\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Layer:\n",
    "        return self.layers[idx]\n",
    "\n",
    "    def get_detectors(self) -> List[DetectorLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, DetectorLayer)]\n",
    "\n",
    "    def get_passives(self) -> List[PassiveLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, PassiveLayer)]\n",
    "\n",
    "    def get_rad_cube(self) -> Tensor:\n",
    "        vols = list(reversed(self.get_passives()))  # reversed to match lookup_xyz_coords: layer zero = bottom layer\n",
    "        if len(vols) == 0:\n",
    "            raise ValueError(\"self.layers contains no passive layers\")\n",
    "        return torch.stack([v.rad_length for v in vols if v.rad_length is not None], dim=0)\n",
    "\n",
    "    def lookup_passive_xyz_coords(self, xyz: Tensor) -> Tensor:\n",
    "        r\"\"\"Assume same size for all layers for now and no intermedeate detector layers\"\"\"\n",
    "        if len(xyz.shape) == 1:\n",
    "            xyz = xyz[None, :]\n",
    "\n",
    "        if n := (\n",
    "            ((xyz[:, :2] > self.lw) + (xyz[:, :2] < 0)).sum(1) + (xyz[:, 2] < self.get_passive_z_range()[0]) + ((xyz[:, 2] > self.get_passive_z_range()[1]))\n",
    "        ).sum():\n",
    "            raise ValueError(f\"{n} Coordinates outside passive volume\")\n",
    "        xyz[:, 2] = xyz[:, 2] - self.get_passive_z_range()[0]\n",
    "        return torch.floor(xyz / self.size).long()\n",
    "\n",
    "    def load_rad_length(self, rad_length_func: Callable[..., Tensor]) -> None:\n",
    "        for p in self.get_passives():\n",
    "            p.load_rad_length(rad_length_func)\n",
    "\n",
    "    def forward(self, mu: MuonBatch) -> None:  # Expand to take volume as input, too\n",
    "        for l in self.layers:\n",
    "            l(mu)\n",
    "            mu.snapshot_xyz()\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        cost = None\n",
    "        for l in self.layers:\n",
    "            if hasattr(l, \"get_cost\"):\n",
    "                if cost is None:\n",
    "                    cost = l.get_cost()\n",
    "                else:\n",
    "                    cost = cost + l.get_cost()\n",
    "        if cost is None:\n",
    "            cost = torch.zeros((1))\n",
    "        return cost\n",
    "\n",
    "    @property\n",
    "    def lw(self) -> Tensor:\n",
    "        return self.get_passives()[-1].lw\n",
    "\n",
    "    @property\n",
    "    def passive_size(self) -> float:\n",
    "        return self.get_passives()[-1].size  # Same size for each passive layer\n",
    "\n",
    "    @property\n",
    "    def h(self) -> float:\n",
    "        return self.layers[0].z\n",
    "\n",
    "    def get_passive_z_range(self) -> Tuple[Tensor, Tensor]:\n",
    "        ps = self.get_passives()\n",
    "        return ps[-1].z - self.passive_size, ps[0].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 1.0000], dtype=torch.float64), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       "  (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9500], dtype=torch.float64), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       "  (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9000], dtype=torch.float64), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       "  (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.8500], dtype=torch.float64), and xy span Parameter containing:\n",
       "  tensor([0.5000, 0.5000], requires_grad=True)\n",
       ")"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 1.0000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.8500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.3000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.2500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.2000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.1500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 1.0000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.9000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.8500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.3000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.2500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.2000], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000, 0.1500], dtype=torch.float64), and xy span Parameter containing:\n",
       "        tensor([0.5000, 0.5000], requires_grad=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[   inf,    inf, 1.0000],\n",
       "         [0.5132, 0.2790, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.7103, 0.3179, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.3449, 0.6619, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [0.4820, 0.3869, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [0.6636, 0.6034, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [0.2884, 0.5669, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [0.3105, 0.5319, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [0.4703, 0.6597, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.4469, 0.5051, 1.0000],\n",
       "         [0.4105, 0.4562, 1.0000],\n",
       "         [0.6997, 0.6162, 1.0000],\n",
       "         [0.4731, 0.3636, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.6193, 0.5035, 1.0000],\n",
       "         [0.6544, 0.2738, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.7458, 0.6423, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [0.4154, 0.6793, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.6819, 0.2960, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [0.6483, 0.6690, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [0.6209, 0.4355, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [0.7162, 0.5769, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [  -inf,    inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000],\n",
       "         [   inf,    inf, 1.0000],\n",
       "         [  -inf,   -inf, 1.0000],\n",
       "         [   inf,   -inf, 1.0000]], dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([[   inf,    inf, 0.9500],\n",
       "         [0.5053, 0.2780, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [0.7031, 0.3256, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [0.3444, 0.6630, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [0.4821, 0.3846, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [0.6571, 0.5975, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [0.2891, 0.5616, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [0.3171, 0.5326, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [0.4777, 0.6623, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [0.3436, 0.7429, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [0.4480, 0.5116, 0.9500],\n",
       "         [0.4189, 0.4611, 0.9500],\n",
       "         [0.6984, 0.6146, 0.9500],\n",
       "         [0.4757, 0.3608, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [0.6214, 0.5065, 0.9500],\n",
       "         [0.6581, 0.2762, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [0.7470, 0.6522, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [0.4114, 0.6753, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [0.6758, 0.2969, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [0.6548, 0.6598, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [0.6215, 0.4351, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [0.6626, 0.2518, 0.9500],\n",
       "         [0.7168, 0.5759, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [  -inf,   -inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [  -inf,    inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500],\n",
       "         [   inf,   -inf, 0.9500],\n",
       "         [   inf,    inf, 0.9500]], dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([[  -inf,   -inf, 0.9000],\n",
       "         [0.5006, 0.2736, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.6917, 0.3337, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [0.3408, 0.6640, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.4795, 0.3859, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.6539, 0.5934, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [0.2899, 0.5503, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.3236, 0.5381, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [0.4788, 0.6645, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [0.3554, 0.7363, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [0.4481, 0.5164, 0.9000],\n",
       "         [0.4218, 0.4653, 0.9000],\n",
       "         [0.6955, 0.6102, 0.9000],\n",
       "         [0.4776, 0.3594, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [0.6235, 0.5075, 0.9000],\n",
       "         [0.6574, 0.2800, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.4060, 0.6737, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [0.6702, 0.2988, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [0.6621, 0.6489, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [0.6223, 0.4374, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [0.6626, 0.2544, 0.9000],\n",
       "         [0.7216, 0.5796, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [   inf,   -inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [  -inf,    inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [   inf,    inf, 0.9000],\n",
       "         [  -inf,   -inf, 0.9000]], dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([[   inf,    inf, 0.8500],\n",
       "         [0.4934, 0.2718, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.6856, 0.3422, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.7476, 0.2864, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [0.3379, 0.6662, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [0.4777, 0.3843, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [0.6470, 0.5885, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [0.2904, 0.5448, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.3278, 0.5380, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.4829, 0.6679, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.3650, 0.7274, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [0.4516, 0.5197, 0.8500],\n",
       "         [0.4323, 0.4688, 0.8500],\n",
       "         [0.6924, 0.6111, 0.8500],\n",
       "         [0.4819, 0.3591, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [0.6251, 0.5098, 0.8500],\n",
       "         [0.6599, 0.2849, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [0.4059, 0.6727, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [0.6653, 0.3015, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [0.6712, 0.6403, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,    inf, 0.8500],\n",
       "         [0.6239, 0.4387, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [0.6660, 0.2556, 0.8500],\n",
       "         [0.7265, 0.5801, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [0.2511, 0.5022, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [  -inf,    inf, 0.8500],\n",
       "         [   inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500],\n",
       "         [  -inf,   -inf, 0.8500]], dtype=torch.float64, grad_fn=<CatBackward>)]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = muons.get_hits(volume.lw)\n",
    "above_hits = [torch.cat([hits[\"above\"][\"reco_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "above_gen_hits = [torch.cat([hits[\"above\"][\"gen_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "above_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.5132, 0.2790, 1.0000], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([0.5053, 0.2780, 0.9500], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([0.5006, 0.2736, 0.9000], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([0.4934, 0.2718, 0.8500], dtype=torch.float64, grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[1] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([inf, inf, 1.], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([   inf,    inf, 0.9500], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([  -inf,   -inf, 0.9000], dtype=torch.float64, grad_fn=<SelectBackward>),\n",
       " tensor([   inf,    inf, 0.8500], dtype=torch.float64, grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[0] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_uncs(dets: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "    res = []\n",
    "    for l,h in zip(dets,hits):\n",
    "        r = 1 / l.get_resolution(h[:,:2])\n",
    "        res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = get_hit_uncs(volume.get_detectors()[0].panels, above_gen_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [0.0010, 0.0010, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [   inf,    inf, 0.0000],\n",
       "        [0.0010, 0.0010, 0.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([inf, inf, 0.], grad_fn=<SelectBackward>),\n",
       " tensor([inf, inf, 0.], grad_fn=<SelectBackward>),\n",
       " tensor([inf, inf, 0.], grad_fn=<SelectBackward>),\n",
       " tensor([inf, inf, 0.], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u[1] for u in uncs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "    r\"\"\"\n",
    "    hits = [muons,(x,y,z)]\n",
    "    uncs = [(unc,unc,0)]\n",
    "\n",
    "    Assume no uncertainty for z\n",
    "    \n",
    "    In eval mode:\n",
    "        Muons with <2 hits within panels have NaN trajectory.\n",
    "        Muons with >=2 hits in panels have valid trajectories\n",
    "    \"\"\"\n",
    "\n",
    "    hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "    hits = torch.where(torch.isinf(hits), torch.tensor([0.5], dtype=torch.float64, device=uncs.device), hits)\n",
    "    \n",
    "    stars, angles = [],[]\n",
    "    for i in range(2):  # seperate x and y resolutions\n",
    "        inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "        sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "        mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_x = mean_xz[:, :1]\n",
    "        mean_z = mean_xz[:, 1:]\n",
    "        mean_x_z = mean_xz_z[:, :1]\n",
    "        mean_z2 = mean_xz_z[:, 1:]\n",
    "        \n",
    "        stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "        angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "    xy_star = torch.cat(stars, dim=-1)\n",
    "    angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "    def _calc_xyz(z: Tensor) -> Tensor:\n",
    "        return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "\n",
    "    return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [-0.0085,  0.0081, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [    nan,     nan, -0.0500],\n",
       "        [ 0.0743, -0.0641, -0.0500]], dtype=torch.float64,\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_muon_trajectory(above_hits, uncs)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.utils import jacobian\n",
    "\n",
    "class PanelScatterBatch(ScatterBatch):\n",
    "    @staticmethod\n",
    "    def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "        r\"\"\"\n",
    "        hits = [muons,(x,y,z)]\n",
    "        uncs = [(unc,unc,0)]\n",
    "\n",
    "        Assume no uncertainty for z\n",
    "\n",
    "        In eval mode:\n",
    "            Muons with <2 hits within panels have NaN trajectory.\n",
    "            Muons with >=2 hits in panels have valid trajectories\n",
    "        \"\"\"\n",
    "\n",
    "        hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "        hits = torch.where(torch.isinf(hits), torch.tensor([0.5], dtype=torch.float64, device=uncs.device), hits)\n",
    "\n",
    "        stars, angles = [],[]\n",
    "        for i in range(2):  # seperate x and y resolutions\n",
    "            inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "            sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "            mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_x = mean_xz[:, :1]\n",
    "            mean_z = mean_xz[:, 1:]\n",
    "            mean_x_z = mean_xz_z[:, :1]\n",
    "            mean_z2 = mean_xz_z[:, 1:]\n",
    "\n",
    "            stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "            angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "        xy_star = torch.cat(stars, dim=-1)\n",
    "        angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "        def _calc_xyz(z: Tensor) -> Tensor:\n",
    "            return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "\n",
    "        return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_hit_uncs(dets: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "        res = []\n",
    "        for l,h in zip(dets,hits):\n",
    "            r = 1 / l.get_resolution(h[:,:2])\n",
    "            res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "        return res\n",
    "    \n",
    "    def compute_scatters(self) -> None:\n",
    "        r\"\"\"\n",
    "        Currently only handles detectors above and below passive volume\n",
    "\n",
    "        Scatter locations adapted from:\n",
    "        @MISC {3334866,\n",
    "            TITLE = {Closest points between two lines},\n",
    "            AUTHOR = {Brian (https://math.stackexchange.com/users/72614/brian)},\n",
    "            HOWPUBLISHED = {Mathematics Stack Exchange},\n",
    "            NOTE = {URL:https://math.stackexchange.com/q/3334866 (version: 2019-08-26)},\n",
    "            EPRINT = {https://math.stackexchange.com/q/3334866},\n",
    "            URL = {https://math.stackexchange.com/q/3334866}\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        # reco x, reco y, gen z, must be a list to allow computation of uncertainty\n",
    "        self.above_hits = [torch.cat([self.hits[\"above\"][\"reco_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "        self.below_hits = [torch.cat([self.hits[\"below\"][\"reco_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"reco_xy\"].shape[1])]\n",
    "        self.above_gen_hits = [torch.cat([self.hits[\"above\"][\"gen_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "        self.below_gen_hits = [torch.cat([self.hits[\"below\"][\"gen_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"gen_xy\"].shape[1])]\n",
    "        self.n_hits_above = len(self.above_hits)\n",
    "        \n",
    "        self.above_hit_uncs = self.get_hit_uncs(self.volume.get_detectors()[0].panels, self.above_gen_hits)\n",
    "        self.below_hit_uncs = self.get_hit_uncs(self.volume.get_detectors()[1].panels, self.below_gen_hits)\n",
    "    \n",
    "        v1 = self.get_muon_trajectory(self.above_hits, self.above_hit_uncs)\n",
    "        v2 = self.get_muon_trajectory(self.below_hits, self.below_hit_uncs)\n",
    "\n",
    "        # scatter locations\n",
    "        v3 = torch.cross(v1, v2, dim=1)  # connecting vector perpendicular to both lines\n",
    "        rhs = self.below_hits[0] - self.above_hits[0]\n",
    "        lhs = torch.stack([v1, -v2, v3], dim=1).transpose(2, 1)\n",
    "        coefs = torch.linalg.solve(lhs, rhs)  # solve p1+t1*v1 + t3*v3 = p2+t2*v2 => p2-p1 = t1*v1 - t2*v2 + t3*v3\n",
    "\n",
    "        q1 = self.above_hits[0] + (coefs[:, 0:1] * v1)  # closest point on v1\n",
    "        self._loc = q1 + (coefs[:, 2:3] * v3 / 2)  # Move halfway along v3 from q1\n",
    "        self._loc_unc: Optional[Tensor] = None\n",
    "\n",
    "        # Theta deviations\n",
    "        self._theta_in = torch.arctan(v1[:, :2] / v1[:, 2:3])\n",
    "        self._theta_out = torch.arctan(v2[:, :2] / v2[:, 2:3])\n",
    "        self._dtheta = torch.abs(self._theta_in - self._theta_out)\n",
    "        self._theta_in_unc: Optional[Tensor] = None\n",
    "        self._theta_out_unc: Optional[Tensor] = None\n",
    "        self._dtheta_unc: Optional[Tensor] = None\n",
    "\n",
    "        # xy deviations\n",
    "        self._dxy = coefs[:, 2:3] * v3[:, :2]\n",
    "        self._dxy_unc: Optional[Tensor] = None\n",
    "            \n",
    "    def _compute_unc(self, var: Tensor, hits: List[Tensor], hit_uncs: List[Tensor]) -> Tensor:\n",
    "        unc2_sum = None\n",
    "        for i, (xi, unci) in enumerate(zip(hits, hit_uncs)):\n",
    "            for j, (xj, uncj) in enumerate(zip(hits, hit_uncs)):\n",
    "                if j < i:\n",
    "                    continue\n",
    "                dv_dx_2 = torch.nan_to_num(jacobian(var, xi)).sum(2) * torch.nan_to_num(jacobian(var, xj)).sum(2) if i != j else torch.nan_to_num(jacobian(var, xi)).sum(2) ** 2  # Muons, var_xyz, hit_xyz\n",
    "                unc_2 = (dv_dx_2 * unci[:, None] * uncj[:, None]).sum(2)  # Muons, (x,y,z)\n",
    "                if unc2_sum is None:\n",
    "                    unc2_sum = unc_2\n",
    "                else:\n",
    "                    unc2_sum = unc2_sum + unc_2\n",
    "        return torch.sqrt(unc2_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb = PanelScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [0.6238, 0.3988, 0.5009],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan]], dtype=torch.float64,\n",
       "        grad_fn=<SliceBackward>),\n",
       " tensor([[   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [0.0491, 0.0484, 0.2836],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan],\n",
       "         [0.0003, 0.0004, 0.0005]], dtype=torch.float64,\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[:10], sb.location_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sb.get_scatter_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6238, 0.3988, 0.5009],\n",
       "         [0.3305, 0.6694, 0.6900],\n",
       "         [0.4685, 0.3809, 0.5706],\n",
       "         [0.6321, 0.5708, 0.6970],\n",
       "         [0.2928, 0.5149, 0.6623],\n",
       "         [0.5208, 0.6937, 0.3816],\n",
       "         [0.4517, 0.5210, 0.8136],\n",
       "         [0.4293, 0.4663, 0.8717],\n",
       "         [0.6872, 0.6016, 0.6620],\n",
       "         [0.4939, 0.3529, 0.6349]], dtype=torch.float64,\n",
       "        grad_fn=<SliceBackward>),\n",
       " tensor([[0.0491, 0.0484, 0.2836],\n",
       "         [0.0159, 0.0076, 0.3142],\n",
       "         [0.0042, 0.0038, 0.1610],\n",
       "         [0.0170, 0.0158, 0.1505],\n",
       "         [0.0025, 0.0326, 0.2090],\n",
       "         [0.0094, 0.0101, 0.1242],\n",
       "         [0.0099, 0.0370, 0.3888],\n",
       "         [0.0226, 0.0135, 0.1636],\n",
       "         [0.0072, 0.0058, 0.1727],\n",
       "         [0.0072, 0.0034, 0.1324]], dtype=torch.float64,\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[m][:10], sb.location_unc[m][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VolumeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = VolumeWrapper(volume=volume, res_opt=partial(torch.optim.SGD, lr=2e10), eff_opt=partial(torch.optim.SGD, lr=2e5),\n",
    "                        loss_func=DetectorLoss(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MetricLogger(show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation.callbacks.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamCap(Callback):\n",
    "    def on_volume_batch_begin(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            for d in self.wrapper.volume.get_detectors():\n",
    "                torch.clamp_(d.resolution, min=1, max=1e7)\n",
    "                torch.clamp_(d.efficiency, min=1e-7, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = wrapper.fit(25, n_mu_per_volume=1000, mu_bs=100, passive_bs=1, trn_passives=trn_passives, val_passives=trn_passives, cbs=[NoMoreNaNs(),ParamCap(),ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in volume.get_detectors():\n",
    "    print(1, d.resolution, d.efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
