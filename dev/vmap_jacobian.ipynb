{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import generate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import MuonBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.core import X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*1e5\n",
    "    if z >= 0.5 and z <= 0.5: rad_length[...] = X0['lead']#X0['beryllium']\n",
    "#     if z == 0.6 : rad_length[...] = X0['beryllium']\n",
    "        \n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume import PassiveLayer, DetectorLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_cost(x:Tensor) -> Tensor:\n",
    "    return torch.expm1(3*F.relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/100)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 100000\n",
    "    pos = 'above'\n",
    "    for z,d in zip(np.arange(lwh[2],0,-size), [1,1,0,0,0,0,0,0,1,1]):\n",
    "        if d:\n",
    "            layers.append(DetectorLayer(pos=pos, init_eff=init_eff, init_res=init_res,\n",
    "                                        lw=lwh[:2], z=z, size=size, eff_cost_func=eff_cost, res_cost_func=res_cost))\n",
    "        else:\n",
    "            pos = 'below'\n",
    "            layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume import Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = MuonBatch(generate_batch(1000), init_z=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.8.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /Users/giles/anaconda3/envs/tomopt/lib/python3.8/site-packages\n",
      "Requires: numpy, typing-extensions\n",
      "Required-by: torchvision, torchaudio, tomopt\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._vmap_internals import _vmap as vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0435, -0.9540])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot                            # [D], [D] -> []\n",
    "batched_dot = vmap(torch.dot)  # [N, D], [N, D] -> [N]\n",
    "x, y = torch.randn(2, 5), torch.randn(2, 5)\n",
    "batched_dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1251, 2.3924, 0.8084], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, feature_size = 3, 5\n",
    "weights = torch.randn(feature_size, requires_grad=True)\n",
    "\n",
    "def model(feature_vec):\n",
    "    # Very simple linear model with activation\n",
    "    return feature_vec.dot(weights).relu()\n",
    "\n",
    "examples = torch.randn(batch_size, feature_size)\n",
    "result = vmap(model)(examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0035, -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000, -0.2353,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000, -0.0000,  0.4516,  0.0000,  0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000,  0.4934,  0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000,  0.0000,  0.2062]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "N = 5\n",
    "f = lambda x: x ** 2\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "I_N = torch.eye(N)\n",
    "\n",
    "# Sequential approach\n",
    "jacobian_rows = [torch.autograd.grad(y, x, v, retain_graph=True)[0]\n",
    "                 for v in I_N.unbind()]\n",
    "jacobian = torch.stack(jacobian_rows)\n",
    "jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx = lambda x: 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0359,  4.4786,  3.8792,  1.3077, -0.1411], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dx(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9578, -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000, -0.1235,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000,  1.5151,  0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000,  3.4640, -0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000,  0.0000, -0.5435]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorized gradient computation\n",
    "def get_vjp(v):\n",
    "    return torch.autograd.grad(y, x, v, retain_graph=True)[0]\n",
    "jacobian = vmap(get_vjp)(I_N)\n",
    "jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_N.unbind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5018, -0.1176,  0.2258,  0.2467,  0.1031], requires_grad=True),\n",
       " tensor([0.2518, 0.0138, 0.0510, 0.0609, 0.0106], grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 µs ± 762 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "f = lambda x: x ** 2\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "I_N = torch.eye(N)\n",
    "\n",
    "%timeit torch.stack([torch.autograd.grad(y,x,v, retain_graph=True)[0] for v in I_N.unbind()]).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.5 µs ± 429 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def get_vjp(v): return torch.autograd.grad(y,x,v, retain_graph=True)[0].sum()\n",
    "vmap(get_vjp)(I_N)\n",
    "\n",
    "%timeit vmap(get_vjp)(I_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchwise_grad(y: Tensor, x: Tensor, create_graph: bool = False, allow_unused: bool = True) -> Tensor:\n",
    "    def get_vjp(v): return torch.autograd.grad(y, x, v, retain_graph=True, create_graph=create_graph, allow_unused=allow_unused)[0].sum()\n",
    "    return vmap(get_vjp)(torch.eye(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8767, -1.5492,  0.3309,  1.9931,  2.1301])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchwise_grad(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "f = lambda x: x ** 2\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "I_N = torch.eye(N)\n",
    "\n",
    "yb = torch.stack([y for _ in range(5)])\n",
    "\n",
    "torch.stack([torch.autograd.grad(y,x,v, retain_graph=True)[0] for v in I_N.unbind()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_y = yb.reshape(-1)\n",
    "I_N = torch.eye(len(flat_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26 ms ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jac = []\n",
    "for grad_y in I_N.unbind():\n",
    "    (grad_x,) = torch.autograd.grad(flat_y, x, grad_y, retain_graph=True)\n",
    "    jac.append(grad_x.reshape(x.shape))\n",
    "torch.stack(jac).reshape(yb.shape + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]],\n",
       "\n",
       "        [[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]],\n",
       "\n",
       "        [[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]],\n",
       "\n",
       "        [[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]],\n",
       "\n",
       "        [[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vjp(v): return torch.autograd.grad(flat_y, x, v, retain_graph=True)[0].reshape(x.shape)\n",
    "vmap(get_vjp)(I_N).reshape(yb.shape + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchwise_jacobian(y: Tensor, x: Tensor, create_graph: bool = False, allow_unused: bool = True) -> Tensor:\n",
    "    flat_y = y.reshape(-1)\n",
    "\n",
    "    def get_vjp(v): return torch.autograd.grad(flat_y, x, v, retain_graph=True, create_graph=create_graph, allow_unused=allow_unused)[0].reshape(x.shape)\n",
    "    \n",
    "    return vmap(get_vjp)(torch.eye(len(flat_y))).reshape(y.shape + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9484, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -1.7019,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000,  3.0440, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000, -0.4101, -0.0000],\n",
       "        [-0.0000, -0.0000,  0.0000, -0.0000, -0.0051]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchwise_jacobian(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 µs ± 3.37 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit batchwise_jacobian(yb, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.inference import ScatterBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 747 ms, total: 21.2 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%time scatters = ScatterBatch(batch, volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchwise grad scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def batchwise_jacobian(y: Tensor, x: Tensor, create_graph: bool = False, allow_unused: bool = True) -> Tensor:\n",
    "    flat_y = y.reshape(-1)\n",
    "\n",
    "    def get_vjp(v): return torch.autograd.grad(flat_y, x, v, retain_graph=True, create_graph=create_graph, allow_unused=allow_unused)[0].reshape(x.shape).sum((-1,-2))\n",
    "    \n",
    "    return vmap(get_vjp)(torch.eye(len(flat_y))).reshape(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BWScatterBatch(ScatterBatch):\n",
    "    def compute_scatters(self) -> None:\n",
    "        r\"\"\"\n",
    "        Currently only handles 2 detectors above and below passive volume\n",
    "\n",
    "        Scatter locations adapted from:\n",
    "        @MISC {3334866,\n",
    "            TITLE = {Closest points between two lines},\n",
    "            AUTHOR = {Brian (https://math.stackexchange.com/users/72614/brian)},\n",
    "            HOWPUBLISHED = {Mathematics Stack Exchange},\n",
    "            NOTE = {URL:https://math.stackexchange.com/q/3334866 (version: 2019-08-26)},\n",
    "            EPRINT = {https://math.stackexchange.com/q/3334866},\n",
    "            URL = {https://math.stackexchange.com/q/3334866}\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        # self.hits in layers\n",
    "        xa0 = torch.cat([self.hits[\"above\"][\"xy\"][:, 0], self.hits[\"above\"][\"z\"][:, 0]], dim=-1)  # reco x, reco y, gen z\n",
    "        xa1 = torch.cat([self.hits[\"above\"][\"xy\"][:, 1], self.hits[\"above\"][\"z\"][:, 1]], dim=-1)\n",
    "        xb0 = torch.cat([self.hits[\"below\"][\"xy\"][:, 1], self.hits[\"below\"][\"z\"][:, 1]], dim=-1)\n",
    "        xb1 = torch.cat([self.hits[\"below\"][\"xy\"][:, 0], self.hits[\"below\"][\"z\"][:, 0]], dim=-1)\n",
    "\n",
    "        dets = self.volume.get_detectors()\n",
    "        res = []\n",
    "        for p, l, i in zip((\"above\", \"above\", \"below\", \"below\"), dets, (0, 1, 0, 1)):\n",
    "            x = l.abs2idx(self.hits[p][\"xy\"][:, i])\n",
    "            res.append(l.resolution[x[:, 0], x[:, 1]])\n",
    "        res2 = torch.stack(res, dim=1)[:, :, None] ** 2\n",
    "\n",
    "        # Extrapolate muon-path vectors from self.hits\n",
    "        v1 = xa1 - xa0\n",
    "        v2 = xb1 - xb0\n",
    "\n",
    "        # scatter locations\n",
    "        v3 = torch.cross(v1, v2, dim=1)  # connecting vector perpendicular to both lines\n",
    "        rhs = xb0 - xa0\n",
    "        lhs = torch.stack([v1, -v2, v3], dim=1).transpose(2, 1)\n",
    "        coefs = torch.linalg.solve(lhs, rhs)  # solve p1+t1*v1 + t3*v3 = p2+t2*v2 => p2-p1 = t1*v1 - t2*v2 + t3*v3\n",
    "\n",
    "        q1 = xa0 + (coefs[:, 0:1] * v1)  # closest point on v1\n",
    "        self._loc = q1 + (coefs[:, 2:3] * v3 / 2)  # Move halfway along v3 from q1\n",
    "        \n",
    "        \n",
    "        # Theta deviations\n",
    "        self._theta_in = torch.arctan(v1[:, :2] / v1[:, 2:3])\n",
    "        self._theta_out = torch.arctan(v2[:, :2] / v2[:, 2:3])\n",
    "        self._dtheta = torch.abs(self._theta_in - self._theta_out)\n",
    "\n",
    "        # xy deviations\n",
    "        self._dxy = coefs[:, 2:3] * v3[:, :2]\n",
    "        \n",
    "        # loc uncertainty\n",
    "        dloc_dres = torch.stack([batchwise_jacobian(self._loc, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._loc_unc = torch.sqrt((dloc_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # dtheta uncertainty\n",
    "        ddtheta_dres = torch.stack([batchwise_jacobian(self._dtheta, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._dtheta_unc = torch.sqrt((ddtheta_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # dxy uncertainty\n",
    "        ddxy_dres = torch.stack([batchwise_jacobian(self._dxy, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._dxy_unc = torch.sqrt((ddxy_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # theta_in uncertainty\n",
    "        dtheta_in_dres = torch.stack([batchwise_jacobian(self._theta_in, l.resolution).sum((-1, -2)) for l in dets[:2]], dim=1)\n",
    "        self._theta_in_unc = torch.sqrt((dtheta_in_dres.pow(2) * res2[:, :2]).sum(1))\n",
    "\n",
    "        # theta_out uncertainty\n",
    "        dtheta_out_dres = torch.stack([batchwise_jacobian(self._theta_out, l.resolution).sum((-1, -2)) for l in dets[2:]], dim=1)\n",
    "        self._theta_out_unc = torch.sqrt((dtheta_out_dres.pow(2) * res2[:, 2:]).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 1.72 s, total: 15.1 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%time scatters = BWScatterBatch(batch, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VMapBWScatterBatch(ScatterBatch):\n",
    "    def compute_scatters(self) -> None:\n",
    "        r\"\"\"\n",
    "        Currently only handles 2 detectors above and below passive volume\n",
    "\n",
    "        Scatter locations adapted from:\n",
    "        @MISC {3334866,\n",
    "            TITLE = {Closest points between two lines},\n",
    "            AUTHOR = {Brian (https://math.stackexchange.com/users/72614/brian)},\n",
    "            HOWPUBLISHED = {Mathematics Stack Exchange},\n",
    "            NOTE = {URL:https://math.stackexchange.com/q/3334866 (version: 2019-08-26)},\n",
    "            EPRINT = {https://math.stackexchange.com/q/3334866},\n",
    "            URL = {https://math.stackexchange.com/q/3334866}\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        # self.hits in layers\n",
    "        xa0 = torch.cat([self.hits[\"above\"][\"xy\"][:, 0], self.hits[\"above\"][\"z\"][:, 0]], dim=-1)  # reco x, reco y, gen z\n",
    "        xa1 = torch.cat([self.hits[\"above\"][\"xy\"][:, 1], self.hits[\"above\"][\"z\"][:, 1]], dim=-1)\n",
    "        xb0 = torch.cat([self.hits[\"below\"][\"xy\"][:, 1], self.hits[\"below\"][\"z\"][:, 1]], dim=-1)\n",
    "        xb1 = torch.cat([self.hits[\"below\"][\"xy\"][:, 0], self.hits[\"below\"][\"z\"][:, 0]], dim=-1)\n",
    "\n",
    "        dets = self.volume.get_detectors()\n",
    "        res = []\n",
    "        for p, l, i in zip((\"above\", \"above\", \"below\", \"below\"), dets, (0, 1, 0, 1)):\n",
    "            x = l.abs2idx(self.hits[p][\"xy\"][:, i])\n",
    "            res.append(l.resolution[x[:, 0], x[:, 1]])\n",
    "        res = torch.stack(res, dim=1)[:, :, None]\n",
    "        res2 = res ** 2\n",
    "\n",
    "        # Extrapolate muon-path vectors from self.hits\n",
    "        v1 = xa1 - xa0\n",
    "        v2 = xb1 - xb0\n",
    "\n",
    "        # scatter locations\n",
    "        v3 = torch.cross(v1, v2, dim=1)  # connecting vector perpendicular to both lines\n",
    "        rhs = xb0 - xa0\n",
    "        lhs = torch.stack([v1, -v2, v3], dim=1).transpose(2, 1)\n",
    "        coefs = torch.linalg.solve(lhs, rhs)  # solve p1+t1*v1 + t3*v3 = p2+t2*v2 => p2-p1 = t1*v1 - t2*v2 + t3*v3\n",
    "\n",
    "        q1 = xa0 + (coefs[:, 0:1] * v1)  # closest point on v1\n",
    "        self._loc = q1 + (coefs[:, 2:3] * v3 / 2)  # Move halfway along v3 from q1\n",
    "        \n",
    "        \n",
    "        # Theta deviations\n",
    "        self._theta_in = torch.arctan(v1[:, :2] / v1[:, 2:3])\n",
    "        self._theta_out = torch.arctan(v2[:, :2] / v2[:, 2:3])\n",
    "        self._dtheta = torch.abs(self._theta_in - self._theta_out)\n",
    "\n",
    "        # xy deviations\n",
    "        self._dxy = coefs[:, 2:3] * v3[:, :2]\n",
    "            \n",
    "        reses = torch.stack([l.resolution for l in dets])\n",
    "        print(vmap(lambda r: batchwise_jacobian(self._loc, r).sum((-1, -2)))(reses).shape)\n",
    "        \n",
    "        # loc uncertainty\n",
    "        dloc_dres = torch.stack([batchwise_jacobian(self._loc, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._loc_unc = torch.sqrt((dloc_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # dtheta uncertainty\n",
    "        ddtheta_dres = torch.stack([batchwise_jacobian(self._dtheta, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._dtheta_unc = torch.sqrt((ddtheta_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # dxy uncertainty\n",
    "        ddxy_dres = torch.stack([batchwise_jacobian(self._dxy, l.resolution).sum((-1, -2)) for l in dets], dim=1)\n",
    "        self._dxy_unc = torch.sqrt((ddxy_dres.pow(2) * res2).sum(1))\n",
    "\n",
    "        # theta_in uncertainty\n",
    "        dtheta_in_dres = torch.stack([batchwise_jacobian(self._theta_in, l.resolution).sum((-1, -2)) for l in dets[:2]], dim=1)\n",
    "        self._theta_in_unc = torch.sqrt((dtheta_in_dres.pow(2) * res2[:, :2]).sum(1))\n",
    "\n",
    "        # theta_out uncertainty\n",
    "        dtheta_out_dres = torch.stack([batchwise_jacobian(self._theta_out, l.resolution).sum((-1, -2)) for l in dets[2:]], dim=1)\n",
    "        self._theta_out_unc = torch.sqrt((dtheta_out_dres.pow(2) * res2[:, 2:]).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.autograd.grad(outputs, inputs, grad_outputs) called inside torch.vmap. We do not support the case where any inputs are vmapped tensors (input 0 is being vmapped over). Please call autograd.grad() outside torch.vmap or file a bug report with your use case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/cernbox/mode_muon_tomography/tomopt/inference/scattering.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mu, volume)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_scatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_scatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-4c4a71426d20>\u001b[0m in \u001b[0;36mcompute_scatters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchwise_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# loc uncertainty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tomopt/lib/python3.8/site-packages/torch/_vmap_internals.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0m_validate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-4c4a71426d20>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchwise_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# loc uncertainty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-017efa4ed0b3>\u001b[0m in \u001b[0;36mbatchwise_jacobian\u001b[0;34m(y, x, create_graph, allow_unused)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_unused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vjp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tomopt/lib/python3.8/site-packages/torch/_vmap_internals.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0m_validate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-017efa4ed0b3>\u001b[0m in \u001b[0;36mget_vjp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mflat_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_unused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vjp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tomopt/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.autograd.grad(outputs, inputs, grad_outputs) called inside torch.vmap. We do not support the case where any inputs are vmapped tensors (input 0 is being vmapped over). Please call autograd.grad() outside torch.vmap or file a bug report with your use case."
     ]
    }
   ],
   "source": [
    "%time scatters = VMapBWScatterBatch(batch, volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
