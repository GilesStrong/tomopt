{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.core import *\n",
    "from tomopt.optimisation import *\n",
    "from tomopt.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-edc514db5f58>:4: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:23.)\n",
      "  x = torch.linspace(-10, 100*100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd88531c40>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def area_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/1000)**2\n",
    "\n",
    "x = torch.linspace(-10, 100*100)\n",
    "plt.plot(x, area_cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([0.5,0.5], requires_grad=True)\n",
    "s = torch.tensor([0.5,1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = torch.distributions.Normal(c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5353], grad_fn=<ProdBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(torch.exp(gauss.log_prob(Tensor([[0.5,0.5], [1,1]])))/torch.exp(gauss.log_prob(Tensor([0.5,0.5]))),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorPanel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        res: float,\n",
    "        eff: float,\n",
    "        init_xyz:Tuple[float,float,float],\n",
    "        init_xy_span: Tuple[float,float],\n",
    "        area_cost_func: Callable[[Tensor], Tensor],\n",
    "        device: torch.device = DEVICE\n",
    "    ):\n",
    "        if res <= 0:\n",
    "            raise ValueError(f'Resolution must be positive')\n",
    "        if eff <= 0:\n",
    "            raise ValueError(f'Efficiency must be positive')\n",
    "            \n",
    "        super().__init__()\n",
    "        self.area_cost_func, self.device = area_cost_func, device\n",
    "        self.register_buffer('resolution', torch.tensor(float(res), requires_grad=True, device=self.device))\n",
    "        self.register_buffer('efficiency', torch.tensor(float(eff), requires_grad=True, device=self.device))\n",
    "        self.xy = nn.Parameter(torch.tensor(init_xyz[:2], device=self.device))\n",
    "        self.z = nn.Parameter(torch.tensor(init_xyz[2], device=self.device))\n",
    "        self.xy_span = nn.Parameter(torch.tensor(init_xy_span, device=self.device))\n",
    "        self.realistic_validation = False\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'''{self.__class__} located at xy={self.xy.data}, z={self.z.data}, and xy span {self.xy_span.data}'''\n",
    "    \n",
    "    def get_xy_mask(self, xy: Tensor) -> Tensor:\n",
    "        xy_low = self.xy-(self.xy_span/2)\n",
    "        xy_high = self.xy+(self.xy_span/2)\n",
    "        return (xy[:,0] >= xy_low[0]) * (xy[:,0] < xy_high[0]) * (xy[:,1] >= xy_low[1]) * (xy[:,1] < xy_high[1])\n",
    "    \n",
    "    def get_gauss(self) -> torch.distributions.Normal:\n",
    "        try:\n",
    "            return torch.distributions.Normal(self.xy, self.xy_span)  # maybe upscale span?\n",
    "        except ValueError:\n",
    "            print(f'Invalid parameters for Gaussian: loc={self.xy}, scale={self.xy_span}'); assert False\n",
    "    \n",
    "    def get_resolution(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training or not self.realistic_validation:\n",
    "            g = self.get_gauss()\n",
    "            res = self.resolution*torch.exp(g.log_prob(xy))/torch.exp(g.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            res = torch.zeros((len(xy),2), device=self.device)  # Zero detection outside detector\n",
    "            res[mask] = self.resolution\n",
    "        return res\n",
    "    \n",
    "    def get_efficiency(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training or not self.realistic_validation:\n",
    "            g = self.get_gauss()\n",
    "            scale = torch.exp(g.log_prob(xy))/torch.exp(g.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "            eff = self.efficiency*torch.prod(scale, dim=-1)  # Maybe weight product by xy distance?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            eff = torch.zeros(len(xy), device=self.device)  # Zero detection outside detector\n",
    "            eff[mask] = self.efficiency\n",
    "        return eff\n",
    "        \n",
    "    def get_hits(self, mu: MuonBatch) -> Dict[str, Tensor]:\n",
    "        mask = mu.get_xy_mask(self.xy-(self.xy_span/2), self.xy+(self.xy_span/2))  # Muons in panel\n",
    "        \n",
    "        xy0 = self.xy-(self.xy_span/2)  # Low-left of voxel\n",
    "        rel_xy = mu.xy - xy0\n",
    "        res = self.get_resolution(mu.xy, mask)        \n",
    "        rel_xy = rel_xy + (torch.randn((len(mu), 2), device=self.device) / res)\n",
    "        \n",
    "        if not self.training and self.realistic_validation:  # Prevent reco hit from exiting panel\n",
    "            span = self.xy_span.detach().cpu().numpy()\n",
    "            rel_xy[mask] = torch.stack([torch.clamp(rel_xy[mask][:,0], 0, span[0]),\n",
    "                                        torch.clamp(rel_xy[mask][:,1], 0, span[1])], dim=-1)  \n",
    "        reco_xy = xy0 + rel_xy\n",
    "\n",
    "        hits = {\n",
    "            \"reco_xy\": reco_xy,\n",
    "            \"gen_xy\": mu.xy.detach().clone(),\n",
    "            \"z\": self.z.expand_as(mu.x)[:, None],\n",
    "        }\n",
    "        return hits\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        return self.area_cost_func(self.xy_span.prod())\n",
    "    \n",
    "    def clamp_params(self, xyz_low:Tuple[float,float,float], xyz_high:Tuple[float,float,float]) -> None:\n",
    "        with torch.no_grad():\n",
    "            eps = np.random.uniform(0, 1e-5)  # prevent hits at same z due to clamping\n",
    "            torch.clamp_(self.x, min=xyz_low[0], max=xyz_high[0])\n",
    "            torch.clamp_(self.y, min=xyz_low[1], max=xyz_high[1])\n",
    "            torch.clamp_(self.z, min=xyz_low[2]+eps, max=xyz_high[2]-eps)\n",
    "            torch.clamp_(self.xy_span[0], min=1e-7, max=xyz_high[0])\n",
    "            torch.clamp_(self.xy_span[1], min=1e-7, max=xyz_high[1])\n",
    "    \n",
    "    @property\n",
    "    def x(self) -> Tensor:\n",
    "        return self.xy[0]\n",
    "    \n",
    "    @property\n",
    "    def y(self) -> Tensor:\n",
    "        return self.xy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume.layer import Layer\n",
    "\n",
    "class DetectorLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pos: str,\n",
    "        lw: Tensor,\n",
    "        z: float,\n",
    "        size: float,\n",
    "        panels: nn.ModuleList,\n",
    "        device: torch.device = DEVICE,\n",
    "    ):\n",
    "        super().__init__(lw=lw, z=z, size=size, device=device)\n",
    "        if isinstance(panels, list):\n",
    "            panels = nn.ModuleList(panels)\n",
    "        self.pos, self.panels = pos, panels\n",
    "    \n",
    "    def get_panel_zorder(self) -> List[int]:\n",
    "        return np.argsort([p.z.detach().cpu().item() for p in self.panels])[::-1]\n",
    "        \n",
    "    def conform_detector(self) -> None:\n",
    "        lw = self.lw.detach().cpu().numpy()\n",
    "        z = self.z.detach().cpu()[0]\n",
    "        for p in self.panels:\n",
    "            p.clamp_params(xyz_low=(0,0,z-self.size), xyz_high=(lw[0],lw[1],z))\n",
    "                \n",
    "    def forward(self, mu: MuonBatch) -> None:\n",
    "        for i in self.get_panel_zorder():\n",
    "            self.scatter_and_propagate(mu, mu.z-self.panels[i].z)  # Move to panel\n",
    "            mu.append_hits(self.panels[i].get_hits(mu), self.pos)\n",
    "        self.scatter_and_propagate(mu, mu.z-(self.z-self.size))  # Move to bottom of layer\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        for i, p in enumerate(self.panels):\n",
    "            cost = p.get_cost() if i == 0 else cost + p.get_cost()\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = nn.ModuleList([DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,0.95], init_xy_span=[0.5,0.5], area_cost_func=area_cost),\n",
    "                        DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,1.], init_xy_span=[0.5,0.5], area_cost_func=area_cost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reco_xy': tensor([[0.0209, 0.9249],\n",
       "         [0.8763, 0.0846],\n",
       "         [0.9999, 0.6358],\n",
       "         [0.9698, 0.0469],\n",
       "         [0.3111, 0.3817],\n",
       "         [0.0077, 0.1053],\n",
       "         [0.4790, 0.6022],\n",
       "         [0.7274, 0.6906],\n",
       "         [0.6189, 0.7468],\n",
       "         [0.9344, 0.6258],\n",
       "         [0.8272, 0.4341],\n",
       "         [0.8801, 0.2498],\n",
       "         [0.7309, 0.6516],\n",
       "         [0.3231, 0.4701],\n",
       "         [0.8343, 0.0226],\n",
       "         [0.2000, 0.2095],\n",
       "         [0.3919, 0.2097],\n",
       "         [0.6139, 0.4870],\n",
       "         [0.0115, 0.4139],\n",
       "         [0.3111, 0.1521],\n",
       "         [0.4994, 0.5440],\n",
       "         [0.5628, 0.8794],\n",
       "         [0.3374, 0.0879],\n",
       "         [0.3492, 0.5249],\n",
       "         [0.3066, 0.1941],\n",
       "         [0.3792, 0.6587],\n",
       "         [0.8798, 0.8498],\n",
       "         [0.6192, 0.8117],\n",
       "         [0.5123, 0.0272],\n",
       "         [0.2354, 0.3029],\n",
       "         [0.8619, 0.4849],\n",
       "         [0.4241, 0.5705],\n",
       "         [0.5688, 0.9312],\n",
       "         [0.2554, 0.8274],\n",
       "         [0.0425, 0.2620],\n",
       "         [0.8119, 0.4160],\n",
       "         [0.9966, 0.6753],\n",
       "         [0.6144, 0.6187],\n",
       "         [0.8347, 0.6366],\n",
       "         [0.3389, 0.5086],\n",
       "         [0.9876, 0.0832],\n",
       "         [0.6707, 0.5468],\n",
       "         [0.3813, 0.0114],\n",
       "         [0.2499, 0.5032],\n",
       "         [0.4906, 0.4338],\n",
       "         [0.9051, 0.9671],\n",
       "         [0.0196, 0.0496],\n",
       "         [0.2841, 0.3912],\n",
       "         [0.5271, 0.0886],\n",
       "         [0.5622, 0.9028],\n",
       "         [0.5514, 0.6496],\n",
       "         [0.4325, 0.7880],\n",
       "         [0.6868, 0.2011],\n",
       "         [0.6004, 0.4228],\n",
       "         [0.2677, 0.3062],\n",
       "         [0.8611, 0.0470],\n",
       "         [0.4282, 0.3082],\n",
       "         [0.5280, 0.6559],\n",
       "         [0.3522, 0.5078],\n",
       "         [0.2738, 0.8320],\n",
       "         [0.3408, 0.5554],\n",
       "         [0.5056, 0.8653],\n",
       "         [0.9622, 0.9309],\n",
       "         [0.6745, 0.4013],\n",
       "         [0.3563, 0.5750],\n",
       "         [0.9004, 0.9092],\n",
       "         [0.4787, 0.3800],\n",
       "         [0.2705, 0.4751],\n",
       "         [0.2090, 0.2174],\n",
       "         [0.3172, 0.4001],\n",
       "         [0.2139, 0.9252],\n",
       "         [0.4308, 0.8100],\n",
       "         [0.8471, 0.2548],\n",
       "         [0.0173, 0.8404],\n",
       "         [0.0122, 0.4576],\n",
       "         [0.5365, 0.8275],\n",
       "         [0.0554, 0.3211],\n",
       "         [0.7285, 0.9798],\n",
       "         [0.9833, 0.0591],\n",
       "         [0.7968, 0.7778],\n",
       "         [0.7620, 0.2495],\n",
       "         [0.0289, 0.5681],\n",
       "         [0.2903, 0.8862],\n",
       "         [0.1062, 0.7851],\n",
       "         [0.1144, 0.3173],\n",
       "         [0.9397, 0.5370],\n",
       "         [0.0139, 0.0527],\n",
       "         [0.6394, 0.4498],\n",
       "         [0.5380, 0.1846],\n",
       "         [0.6826, 0.0432],\n",
       "         [0.8867, 0.2410],\n",
       "         [0.5859, 0.7827],\n",
       "         [0.0016, 0.1826],\n",
       "         [0.0802, 0.4029],\n",
       "         [0.4906, 0.6408],\n",
       "         [0.8654, 0.4686],\n",
       "         [0.6511, 0.7728],\n",
       "         [0.6962, 0.3200],\n",
       "         [0.2220, 0.7046],\n",
       "         [0.0220, 0.9473]], grad_fn=<AddBackward0>),\n",
       " 'gen_xy': tensor([[0.0208, 0.9247],\n",
       "         [0.8761, 0.0846],\n",
       "         [0.9999, 0.6357],\n",
       "         [0.9695, 0.0467],\n",
       "         [0.3110, 0.3817],\n",
       "         [0.0077, 0.1051],\n",
       "         [0.4791, 0.6021],\n",
       "         [0.7276, 0.6907],\n",
       "         [0.6189, 0.7469],\n",
       "         [0.9346, 0.6257],\n",
       "         [0.8271, 0.4343],\n",
       "         [0.8801, 0.2497],\n",
       "         [0.7308, 0.6517],\n",
       "         [0.3231, 0.4703],\n",
       "         [0.8343, 0.0224],\n",
       "         [0.2000, 0.2096],\n",
       "         [0.3918, 0.2099],\n",
       "         [0.6140, 0.4870],\n",
       "         [0.0111, 0.4141],\n",
       "         [0.3111, 0.1521],\n",
       "         [0.4993, 0.5441],\n",
       "         [0.5629, 0.8793],\n",
       "         [0.3374, 0.0878],\n",
       "         [0.3491, 0.5250],\n",
       "         [0.3067, 0.1940],\n",
       "         [0.3792, 0.6588],\n",
       "         [0.8800, 0.8499],\n",
       "         [0.6193, 0.8118],\n",
       "         [0.5124, 0.0270],\n",
       "         [0.2355, 0.3029],\n",
       "         [0.8621, 0.4848],\n",
       "         [0.4243, 0.5705],\n",
       "         [0.5688, 0.9311],\n",
       "         [0.2551, 0.8275],\n",
       "         [0.0426, 0.2620],\n",
       "         [0.8120, 0.4159],\n",
       "         [0.9966, 0.6753],\n",
       "         [0.6144, 0.6188],\n",
       "         [0.8346, 0.6367],\n",
       "         [0.3389, 0.5086],\n",
       "         [0.9873, 0.0831],\n",
       "         [0.6707, 0.5468],\n",
       "         [0.3814, 0.0118],\n",
       "         [0.2499, 0.5034],\n",
       "         [0.4904, 0.4336],\n",
       "         [0.9052, 0.9667],\n",
       "         [0.0195, 0.0497],\n",
       "         [0.2841, 0.3911],\n",
       "         [0.5270, 0.0888],\n",
       "         [0.5621, 0.9029],\n",
       "         [0.5516, 0.6497],\n",
       "         [0.4324, 0.7879],\n",
       "         [0.6868, 0.2011],\n",
       "         [0.6005, 0.4229],\n",
       "         [0.2680, 0.3064],\n",
       "         [0.8612, 0.0468],\n",
       "         [0.4281, 0.3080],\n",
       "         [0.5280, 0.6558],\n",
       "         [0.3522, 0.5078],\n",
       "         [0.2737, 0.8323],\n",
       "         [0.3407, 0.5556],\n",
       "         [0.5055, 0.8654],\n",
       "         [0.9621, 0.9310],\n",
       "         [0.6745, 0.4013],\n",
       "         [0.3562, 0.5750],\n",
       "         [0.9004, 0.9091],\n",
       "         [0.4786, 0.3799],\n",
       "         [0.2703, 0.4752],\n",
       "         [0.2091, 0.2175],\n",
       "         [0.3172, 0.4002],\n",
       "         [0.2140, 0.9252],\n",
       "         [0.4309, 0.8100],\n",
       "         [0.8471, 0.2549],\n",
       "         [0.0175, 0.8404],\n",
       "         [0.0122, 0.4576],\n",
       "         [0.5366, 0.8276],\n",
       "         [0.0555, 0.3209],\n",
       "         [0.7286, 0.9798],\n",
       "         [0.9835, 0.0592],\n",
       "         [0.7967, 0.7779],\n",
       "         [0.7621, 0.2493],\n",
       "         [0.0288, 0.5682],\n",
       "         [0.2901, 0.8862],\n",
       "         [0.1060, 0.7851],\n",
       "         [0.1142, 0.3173],\n",
       "         [0.9396, 0.5371],\n",
       "         [0.0141, 0.0528],\n",
       "         [0.6394, 0.4498],\n",
       "         [0.5380, 0.1846],\n",
       "         [0.6826, 0.0433],\n",
       "         [0.8868, 0.2411],\n",
       "         [0.5858, 0.7825],\n",
       "         [0.0016, 0.1826],\n",
       "         [0.0802, 0.4027],\n",
       "         [0.4907, 0.6408],\n",
       "         [0.8654, 0.4687],\n",
       "         [0.6510, 0.7727],\n",
       "         [0.6960, 0.3201],\n",
       "         [0.2221, 0.7045],\n",
       "         [0.0222, 0.9473]]),\n",
       " 'z': tensor([[0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500]], grad_fn=<UnsqueezeBackward0>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panels[0].get_hits(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DetectorLayer(pos='above', lw=Tensor([1,1]), z=1, size=0.1, panels=panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2500e-07, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_panel_zorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=1.0, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tomopt.muon.muon_batch.MuonBatch.__init__.<locals>.<lambda>()>,\n",
       "            {'above': defaultdict(list,\n",
       "                         {'reco_xy': [tensor([[0.0210, 0.9251],\n",
       "                                   [0.8763, 0.0844],\n",
       "                                   [0.9999, 0.6356],\n",
       "                                   [0.9693, 0.0467],\n",
       "                                   [0.3110, 0.3817],\n",
       "                                   [0.0077, 0.1052],\n",
       "                                   [0.4791, 0.6022],\n",
       "                                   [0.7276, 0.6905],\n",
       "                                   [0.6190, 0.7467],\n",
       "                                   [0.9346, 0.6257],\n",
       "                                   [0.8271, 0.4343],\n",
       "                                   [0.8801, 0.2496],\n",
       "                                   [0.7307, 0.6518],\n",
       "                                   [0.3232, 0.4704],\n",
       "                                   [0.8342, 0.0224],\n",
       "                                   [0.2001, 0.2099],\n",
       "                                   [0.3918, 0.2100],\n",
       "                                   [0.6142, 0.4869],\n",
       "                                   [0.0113, 0.4142],\n",
       "                                   [0.3112, 0.1519],\n",
       "                                   [0.4993, 0.5440],\n",
       "                                   [0.5629, 0.8791],\n",
       "                                   [0.3373, 0.0879],\n",
       "                                   [0.3490, 0.5250],\n",
       "                                   [0.3067, 0.1941],\n",
       "                                   [0.3792, 0.6588],\n",
       "                                   [0.8802, 0.8499],\n",
       "                                   [0.6193, 0.8117],\n",
       "                                   [0.5123, 0.0270],\n",
       "                                   [0.2354, 0.3028],\n",
       "                                   [0.8620, 0.4850],\n",
       "                                   [0.4241, 0.5705],\n",
       "                                   [0.5688, 0.9312],\n",
       "                                   [0.2553, 0.8276],\n",
       "                                   [0.0426, 0.2620],\n",
       "                                   [0.8121, 0.4159],\n",
       "                                   [0.9967, 0.6752],\n",
       "                                   [0.6142, 0.6185],\n",
       "                                   [0.8345, 0.6366],\n",
       "                                   [0.3387, 0.5086],\n",
       "                                   [0.9874, 0.0834],\n",
       "                                   [0.6706, 0.5469],\n",
       "                                   [0.3815, 0.0118],\n",
       "                                   [0.2499, 0.5034],\n",
       "                                   [0.4903, 0.4336],\n",
       "                                   [0.9052, 0.9667],\n",
       "                                   [0.0194, 0.0494],\n",
       "                                   [0.2840, 0.3910],\n",
       "                                   [0.5270, 0.0891],\n",
       "                                   [0.5620, 0.9028],\n",
       "                                   [0.5516, 0.6496],\n",
       "                                   [0.4325, 0.7877],\n",
       "                                   [0.6869, 0.2011],\n",
       "                                   [0.6004, 0.4231],\n",
       "                                   [0.2681, 0.3063],\n",
       "                                   [0.8613, 0.0467],\n",
       "                                   [0.4281, 0.3082],\n",
       "                                   [0.5282, 0.6558],\n",
       "                                   [0.3522, 0.5077],\n",
       "                                   [0.2737, 0.8322],\n",
       "                                   [0.3408, 0.5554],\n",
       "                                   [0.5055, 0.8654],\n",
       "                                   [0.9624, 0.9307],\n",
       "                                   [0.6745, 0.4012],\n",
       "                                   [0.3563, 0.5751],\n",
       "                                   [0.9004, 0.9091],\n",
       "                                   [0.4787, 0.3799],\n",
       "                                   [0.2701, 0.4752],\n",
       "                                   [0.2091, 0.2176],\n",
       "                                   [0.3170, 0.4002],\n",
       "                                   [0.2141, 0.9250],\n",
       "                                   [0.4308, 0.8100],\n",
       "                                   [0.8472, 0.2548],\n",
       "                                   [0.0174, 0.8405],\n",
       "                                   [0.0123, 0.4575],\n",
       "                                   [0.5366, 0.8279],\n",
       "                                   [0.0552, 0.3210],\n",
       "                                   [0.7286, 0.9802],\n",
       "                                   [0.9836, 0.0592],\n",
       "                                   [0.7967, 0.7777],\n",
       "                                   [0.7621, 0.2492],\n",
       "                                   [0.0292, 0.5682],\n",
       "                                   [0.2903, 0.8860],\n",
       "                                   [0.1059, 0.7849],\n",
       "                                   [0.1142, 0.3173],\n",
       "                                   [0.9396, 0.5372],\n",
       "                                   [0.0140, 0.0530],\n",
       "                                   [0.6393, 0.4498],\n",
       "                                   [0.5380, 0.1845],\n",
       "                                   [0.6828, 0.0432],\n",
       "                                   [0.8869, 0.2412],\n",
       "                                   [0.5857, 0.7826],\n",
       "                                   [0.0016, 0.1827],\n",
       "                                   [0.0801, 0.4027],\n",
       "                                   [0.4907, 0.6409],\n",
       "                                   [0.8655, 0.4688],\n",
       "                                   [0.6510, 0.7724],\n",
       "                                   [0.6959, 0.3200],\n",
       "                                   [0.2221, 0.7046],\n",
       "                                   [0.0221, 0.9473]], grad_fn=<AddBackward0>),\n",
       "                           tensor([[2.2762e-02, 9.2952e-01],\n",
       "                                   [8.6942e-01, 8.0288e-02],\n",
       "                                   [9.9273e-01, 6.3565e-01],\n",
       "                                   [9.6773e-01, 4.0159e-02],\n",
       "                                   [3.0385e-01, 3.7778e-01],\n",
       "                                   [9.0252e-03, 1.1243e-01],\n",
       "                                   [4.7070e-01, 5.9444e-01],\n",
       "                                   [7.2361e-01, 6.9554e-01],\n",
       "                                   [6.1905e-01, 7.5278e-01],\n",
       "                                   [9.3344e-01, 6.1986e-01],\n",
       "                                   [8.2471e-01, 4.2791e-01],\n",
       "                                   [8.8866e-01, 2.4967e-01],\n",
       "                                   [7.3022e-01, 6.5804e-01],\n",
       "                                   [3.1744e-01, 4.6850e-01],\n",
       "                                   [8.3059e-01, 2.3307e-02],\n",
       "                                   [2.0676e-01, 2.0811e-01],\n",
       "                                   [3.9695e-01, 2.1740e-01],\n",
       "                                   [6.1142e-01, 4.9641e-01],\n",
       "                                   [1.6734e-02, 4.1139e-01],\n",
       "                                   [3.0791e-01, 1.5160e-01],\n",
       "                                   [4.9846e-01, 5.4263e-01],\n",
       "                                   [5.5948e-01, 8.7751e-01],\n",
       "                                   [3.3733e-01, 8.6450e-02],\n",
       "                                   [3.3832e-01, 5.2466e-01],\n",
       "                                   [3.0802e-01, 1.9779e-01],\n",
       "                                   [3.8396e-01, 6.5259e-01],\n",
       "                                   [8.8483e-01, 8.4838e-01],\n",
       "                                   [6.1952e-01, 8.1495e-01],\n",
       "                                   [5.0395e-01, 2.2429e-02],\n",
       "                                   [2.3419e-01, 2.9712e-01],\n",
       "                                   [8.6691e-01, 4.7837e-01],\n",
       "                                   [4.1680e-01, 5.7129e-01],\n",
       "                                   [5.5981e-01, 9.2166e-01],\n",
       "                                   [2.5468e-01, 8.2390e-01],\n",
       "                                   [4.2827e-02, 2.6150e-01],\n",
       "                                   [8.0209e-01, 4.1840e-01],\n",
       "                                   [9.9718e-01, 6.7965e-01],\n",
       "                                   [6.0925e-01, 6.1271e-01],\n",
       "                                   [8.3893e-01, 6.4458e-01],\n",
       "                                   [3.2715e-01, 5.1411e-01],\n",
       "                                   [9.8241e-01, 7.9660e-02],\n",
       "                                   [6.7035e-01, 5.5195e-01],\n",
       "                                   [3.8191e-01, 7.5044e-04],\n",
       "                                   [2.4988e-01, 5.0335e-01],\n",
       "                                   [4.9245e-01, 4.3559e-01],\n",
       "                                   [8.9687e-01, 9.6899e-01],\n",
       "                                   [2.3033e-02, 4.2328e-02],\n",
       "                                   [2.8187e-01, 3.9014e-01],\n",
       "                                   [5.2609e-01, 8.6342e-02],\n",
       "                                   [5.7397e-01, 9.0454e-01],\n",
       "                                   [5.4927e-01, 6.4781e-01],\n",
       "                                   [4.3013e-01, 7.8875e-01],\n",
       "                                   [6.9011e-01, 2.0010e-01],\n",
       "                                   [6.0089e-01, 4.1812e-01],\n",
       "                                   [2.6532e-01, 3.1400e-01],\n",
       "                                   [8.5680e-01, 4.6444e-02],\n",
       "                                   [4.1876e-01, 3.0276e-01],\n",
       "                                   [5.2852e-01, 6.5058e-01],\n",
       "                                   [3.4688e-01, 4.9831e-01],\n",
       "                                   [2.7486e-01, 8.3436e-01],\n",
       "                                   [3.4955e-01, 5.6174e-01],\n",
       "                                   [5.1325e-01, 8.6788e-01],\n",
       "                                   [9.5925e-01, 9.2929e-01],\n",
       "                                   [6.7146e-01, 4.0659e-01],\n",
       "                                   [3.6016e-01, 5.7486e-01],\n",
       "                                   [9.0191e-01, 9.0360e-01],\n",
       "                                   [4.7961e-01, 3.7620e-01],\n",
       "                                   [2.7041e-01, 4.7167e-01],\n",
       "                                   [2.1299e-01, 2.2068e-01],\n",
       "                                   [3.2115e-01, 3.9258e-01],\n",
       "                                   [2.1564e-01, 9.3538e-01],\n",
       "                                   [4.3150e-01, 8.0849e-01],\n",
       "                                   [8.4692e-01, 2.5883e-01],\n",
       "                                   [2.0732e-02, 8.4250e-01],\n",
       "                                   [2.0086e-02, 4.6206e-01],\n",
       "                                   [5.4080e-01, 8.2812e-01],\n",
       "                                   [5.5346e-02, 3.1804e-01],\n",
       "                                   [7.3658e-01, 9.7931e-01],\n",
       "                                   [9.7564e-01, 6.0845e-02],\n",
       "                                   [7.8986e-01, 7.8529e-01],\n",
       "                                   [7.5099e-01, 2.4314e-01],\n",
       "                                   [2.1561e-02, 5.6119e-01],\n",
       "                                   [2.8798e-01, 8.8585e-01],\n",
       "                                   [1.1038e-01, 7.8657e-01],\n",
       "                                   [1.1543e-01, 3.1256e-01],\n",
       "                                   [9.3568e-01, 5.3157e-01],\n",
       "                                   [1.8485e-02, 6.0097e-02],\n",
       "                                   [6.3812e-01, 4.4803e-01],\n",
       "                                   [5.3285e-01, 1.9018e-01],\n",
       "                                   [6.8961e-01, 3.9979e-02],\n",
       "                                   [8.9236e-01, 2.4678e-01],\n",
       "                                   [5.8888e-01, 7.8749e-01],\n",
       "                                   [5.7389e-03, 1.8665e-01],\n",
       "                                   [7.5359e-02, 4.0080e-01],\n",
       "                                   [4.8679e-01, 6.3889e-01],\n",
       "                                   [8.6903e-01, 4.6531e-01],\n",
       "                                   [6.4925e-01, 7.6685e-01],\n",
       "                                   [6.9523e-01, 3.2006e-01],\n",
       "                                   [2.3310e-01, 7.0688e-01],\n",
       "                                   [1.9989e-02, 9.3858e-01]], grad_fn=<AddBackward0>)],\n",
       "                          'gen_xy': [tensor([[0.0208, 0.9247],\n",
       "                                   [0.8761, 0.0846],\n",
       "                                   [0.9999, 0.6357],\n",
       "                                   [0.9695, 0.0467],\n",
       "                                   [0.3110, 0.3817],\n",
       "                                   [0.0077, 0.1051],\n",
       "                                   [0.4791, 0.6021],\n",
       "                                   [0.7276, 0.6907],\n",
       "                                   [0.6189, 0.7469],\n",
       "                                   [0.9346, 0.6257],\n",
       "                                   [0.8271, 0.4343],\n",
       "                                   [0.8801, 0.2497],\n",
       "                                   [0.7308, 0.6517],\n",
       "                                   [0.3231, 0.4703],\n",
       "                                   [0.8343, 0.0224],\n",
       "                                   [0.2000, 0.2096],\n",
       "                                   [0.3918, 0.2099],\n",
       "                                   [0.6140, 0.4870],\n",
       "                                   [0.0111, 0.4141],\n",
       "                                   [0.3111, 0.1521],\n",
       "                                   [0.4993, 0.5441],\n",
       "                                   [0.5629, 0.8793],\n",
       "                                   [0.3374, 0.0878],\n",
       "                                   [0.3491, 0.5250],\n",
       "                                   [0.3067, 0.1940],\n",
       "                                   [0.3792, 0.6588],\n",
       "                                   [0.8800, 0.8499],\n",
       "                                   [0.6193, 0.8118],\n",
       "                                   [0.5124, 0.0270],\n",
       "                                   [0.2355, 0.3029],\n",
       "                                   [0.8621, 0.4848],\n",
       "                                   [0.4243, 0.5705],\n",
       "                                   [0.5688, 0.9311],\n",
       "                                   [0.2551, 0.8275],\n",
       "                                   [0.0426, 0.2620],\n",
       "                                   [0.8120, 0.4159],\n",
       "                                   [0.9966, 0.6753],\n",
       "                                   [0.6144, 0.6188],\n",
       "                                   [0.8346, 0.6367],\n",
       "                                   [0.3389, 0.5086],\n",
       "                                   [0.9873, 0.0831],\n",
       "                                   [0.6707, 0.5468],\n",
       "                                   [0.3814, 0.0118],\n",
       "                                   [0.2499, 0.5034],\n",
       "                                   [0.4904, 0.4336],\n",
       "                                   [0.9052, 0.9667],\n",
       "                                   [0.0195, 0.0497],\n",
       "                                   [0.2841, 0.3911],\n",
       "                                   [0.5270, 0.0888],\n",
       "                                   [0.5621, 0.9029],\n",
       "                                   [0.5516, 0.6497],\n",
       "                                   [0.4324, 0.7879],\n",
       "                                   [0.6868, 0.2011],\n",
       "                                   [0.6005, 0.4229],\n",
       "                                   [0.2680, 0.3064],\n",
       "                                   [0.8612, 0.0468],\n",
       "                                   [0.4281, 0.3080],\n",
       "                                   [0.5280, 0.6558],\n",
       "                                   [0.3522, 0.5078],\n",
       "                                   [0.2737, 0.8323],\n",
       "                                   [0.3407, 0.5556],\n",
       "                                   [0.5055, 0.8654],\n",
       "                                   [0.9621, 0.9310],\n",
       "                                   [0.6745, 0.4013],\n",
       "                                   [0.3562, 0.5750],\n",
       "                                   [0.9004, 0.9091],\n",
       "                                   [0.4786, 0.3799],\n",
       "                                   [0.2703, 0.4752],\n",
       "                                   [0.2091, 0.2175],\n",
       "                                   [0.3172, 0.4002],\n",
       "                                   [0.2140, 0.9252],\n",
       "                                   [0.4309, 0.8100],\n",
       "                                   [0.8471, 0.2549],\n",
       "                                   [0.0175, 0.8404],\n",
       "                                   [0.0122, 0.4576],\n",
       "                                   [0.5366, 0.8276],\n",
       "                                   [0.0555, 0.3209],\n",
       "                                   [0.7286, 0.9798],\n",
       "                                   [0.9835, 0.0592],\n",
       "                                   [0.7967, 0.7779],\n",
       "                                   [0.7621, 0.2493],\n",
       "                                   [0.0288, 0.5682],\n",
       "                                   [0.2901, 0.8862],\n",
       "                                   [0.1060, 0.7851],\n",
       "                                   [0.1142, 0.3173],\n",
       "                                   [0.9396, 0.5371],\n",
       "                                   [0.0141, 0.0528],\n",
       "                                   [0.6394, 0.4498],\n",
       "                                   [0.5380, 0.1846],\n",
       "                                   [0.6826, 0.0433],\n",
       "                                   [0.8868, 0.2411],\n",
       "                                   [0.5858, 0.7825],\n",
       "                                   [0.0016, 0.1826],\n",
       "                                   [0.0802, 0.4027],\n",
       "                                   [0.4907, 0.6408],\n",
       "                                   [0.8654, 0.4687],\n",
       "                                   [0.6510, 0.7727],\n",
       "                                   [0.6960, 0.3201],\n",
       "                                   [0.2221, 0.7045],\n",
       "                                   [0.0222, 0.9473]]),\n",
       "                           tensor([[2.2555e-02, 9.2932e-01],\n",
       "                                   [8.6941e-01, 8.0107e-02],\n",
       "                                   [9.9252e-01, 6.3569e-01],\n",
       "                                   [9.6785e-01, 4.0495e-02],\n",
       "                                   [3.0389e-01, 3.7808e-01],\n",
       "                                   [9.1383e-03, 1.1248e-01],\n",
       "                                   [4.7067e-01, 5.9456e-01],\n",
       "                                   [7.2367e-01, 6.9551e-01],\n",
       "                                   [6.1879e-01, 7.5305e-01],\n",
       "                                   [9.3401e-01, 6.1991e-01],\n",
       "                                   [8.2469e-01, 4.2792e-01],\n",
       "                                   [8.8865e-01, 2.4979e-01],\n",
       "                                   [7.3023e-01, 6.5802e-01],\n",
       "                                   [3.1733e-01, 4.6837e-01],\n",
       "                                   [8.3029e-01, 2.3086e-02],\n",
       "                                   [2.0668e-01, 2.0827e-01],\n",
       "                                   [3.9690e-01, 2.1753e-01],\n",
       "                                   [6.1137e-01, 4.9624e-01],\n",
       "                                   [1.7009e-02, 4.1150e-01],\n",
       "                                   [3.0777e-01, 1.5144e-01],\n",
       "                                   [4.9852e-01, 5.4252e-01],\n",
       "                                   [5.5954e-01, 8.7749e-01],\n",
       "                                   [3.3735e-01, 8.6366e-02],\n",
       "                                   [3.3831e-01, 5.2473e-01],\n",
       "                                   [3.0794e-01, 1.9769e-01],\n",
       "                                   [3.8408e-01, 6.5248e-01],\n",
       "                                   [8.8468e-01, 8.4837e-01],\n",
       "                                   [6.1973e-01, 8.1472e-01],\n",
       "                                   [5.0399e-01, 2.2219e-02],\n",
       "                                   [2.3418e-01, 2.9710e-01],\n",
       "                                   [8.6706e-01, 4.7838e-01],\n",
       "                                   [4.1686e-01, 5.7152e-01],\n",
       "                                   [5.5975e-01, 9.2182e-01],\n",
       "                                   [2.5459e-01, 8.2395e-01],\n",
       "                                   [4.2893e-02, 2.6147e-01],\n",
       "                                   [8.0203e-01, 4.1841e-01],\n",
       "                                   [9.9709e-01, 6.7956e-01],\n",
       "                                   [6.0947e-01, 6.1270e-01],\n",
       "                                   [8.3881e-01, 6.4471e-01],\n",
       "                                   [3.2721e-01, 5.1399e-01],\n",
       "                                   [9.8266e-01, 7.9727e-02],\n",
       "                                   [6.7030e-01, 5.5196e-01],\n",
       "                                   [3.8192e-01, 7.4134e-04],\n",
       "                                   [2.4997e-01, 5.0342e-01],\n",
       "                                   [4.9237e-01, 4.3552e-01],\n",
       "                                   [8.9684e-01, 9.6921e-01],\n",
       "                                   [2.3142e-02, 4.2333e-02],\n",
       "                                   [2.8183e-01, 3.9031e-01],\n",
       "                                   [5.2609e-01, 8.6167e-02],\n",
       "                                   [5.7396e-01, 9.0488e-01],\n",
       "                                   [5.4923e-01, 6.4779e-01],\n",
       "                                   [4.3024e-01, 7.8892e-01],\n",
       "                                   [6.8998e-01, 2.0010e-01],\n",
       "                                   [6.0094e-01, 4.1802e-01],\n",
       "                                   [2.6534e-01, 3.1391e-01],\n",
       "                                   [8.5679e-01, 4.6397e-02],\n",
       "                                   [4.1890e-01, 3.0270e-01],\n",
       "                                   [5.2835e-01, 6.5050e-01],\n",
       "                                   [3.4691e-01, 4.9829e-01],\n",
       "                                   [2.7505e-01, 8.3403e-01],\n",
       "                                   [3.4963e-01, 5.6169e-01],\n",
       "                                   [5.1312e-01, 8.6787e-01],\n",
       "                                   [9.5927e-01, 9.2935e-01],\n",
       "                                   [6.7153e-01, 4.0663e-01],\n",
       "                                   [3.6047e-01, 5.7495e-01],\n",
       "                                   [9.0182e-01, 9.0361e-01],\n",
       "                                   [4.7945e-01, 3.7618e-01],\n",
       "                                   [2.7044e-01, 4.7177e-01],\n",
       "                                   [2.1288e-01, 2.2056e-01],\n",
       "                                   [3.2122e-01, 3.9228e-01],\n",
       "                                   [2.1559e-01, 9.3543e-01],\n",
       "                                   [4.3157e-01, 8.0841e-01],\n",
       "                                   [8.4685e-01, 2.5888e-01],\n",
       "                                   [2.0716e-02, 8.4265e-01],\n",
       "                                   [1.9978e-02, 4.6212e-01],\n",
       "                                   [5.4066e-01, 8.2815e-01],\n",
       "                                   [5.5328e-02, 3.1800e-01],\n",
       "                                   [7.3653e-01, 9.7930e-01],\n",
       "                                   [9.7554e-01, 6.1085e-02],\n",
       "                                   [7.8968e-01, 7.8533e-01],\n",
       "                                   [7.5099e-01, 2.4315e-01],\n",
       "                                   [2.1666e-02, 5.6124e-01],\n",
       "                                   [2.8812e-01, 8.8611e-01],\n",
       "                                   [1.1048e-01, 7.8648e-01],\n",
       "                                   [1.1529e-01, 3.1270e-01],\n",
       "                                   [9.3549e-01, 5.3162e-01],\n",
       "                                   [1.8673e-02, 5.9851e-02],\n",
       "                                   [6.3788e-01, 4.4789e-01],\n",
       "                                   [5.3269e-01, 1.9012e-01],\n",
       "                                   [6.8965e-01, 3.9740e-02],\n",
       "                                   [8.9246e-01, 2.4669e-01],\n",
       "                                   [5.8891e-01, 7.8742e-01],\n",
       "                                   [5.8155e-03, 1.8667e-01],\n",
       "                                   [7.5284e-02, 4.0087e-01],\n",
       "                                   [4.8687e-01, 6.3896e-01],\n",
       "                                   [8.6900e-01, 4.6541e-01],\n",
       "                                   [6.4916e-01, 7.6697e-01],\n",
       "                                   [6.9524e-01, 3.2005e-01],\n",
       "                                   [2.3314e-01, 7.0691e-01],\n",
       "                                   [2.0110e-02, 9.3880e-01]])],\n",
       "                          'z': [tensor([[1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.],\n",
       "                                   [1.]], grad_fn=<UnsqueezeBackward0>),\n",
       "                           tensor([[0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500]], grad_fn=<UnsqueezeBackward0>)]})})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    n_panels = 4\n",
    "    layers.append(DetectorLayer(pos='above', lw=lwh[:2], z=1, size=2*size,\n",
    "                                panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,1-(i*(2*size)/n_panels)], init_xy_span=[0.5,0.5],\n",
    "                                                      area_cost_func=area_cost) for i in range(n_panels)]))\n",
    "    for z in [0.8,0.7,0.6,0.5,0.4,0.3]:\n",
    "        layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "    layers.append(DetectorLayer(pos='below', lw=lwh[:2], z=0.2, size=2*size,\n",
    "                                panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,0.2-(i*(2*size)/n_panels)], init_xy_span=[0.5,0.5],\n",
    "                                                      area_cost_func=area_cost) for i in range(n_panels)]))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volume(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        if isinstance(layers, list):\n",
    "            layers = nn.ModuleList(layers)\n",
    "        self.layers = layers\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Layer:\n",
    "        return self.layers[idx]\n",
    "\n",
    "    def get_detectors(self) -> List[DetectorLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, DetectorLayer)]\n",
    "\n",
    "    def get_passives(self) -> List[PassiveLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, PassiveLayer)]\n",
    "\n",
    "    def get_rad_cube(self) -> Tensor:\n",
    "        vols = list(reversed(self.get_passives()))  # reversed to match lookup_xyz_coords: layer zero = bottom layer\n",
    "        if len(vols) == 0:\n",
    "            raise ValueError(\"self.layers contains no passive layers\")\n",
    "        return torch.stack([v.rad_length for v in vols if v.rad_length is not None], dim=0)\n",
    "\n",
    "    def lookup_passive_xyz_coords(self, xyz: Tensor) -> Tensor:\n",
    "        r\"\"\"Assume same size for all layers for now and no intermedeate detector layers\"\"\"\n",
    "        if len(xyz.shape) == 1:\n",
    "            xyz = xyz[None, :]\n",
    "\n",
    "        if n := (\n",
    "            ((xyz[:, :2] > self.lw) + (xyz[:, :2] < 0)).sum(1) + (xyz[:, 2] < self.get_passive_z_range()[0]) + ((xyz[:, 2] > self.get_passive_z_range()[1]))\n",
    "        ).sum():\n",
    "            raise ValueError(f\"{n} Coordinates outside passive volume\")\n",
    "        xyz[:, 2] = xyz[:, 2] - self.get_passive_z_range()[0]\n",
    "        return torch.floor(xyz / self.size).long()\n",
    "\n",
    "    def load_rad_length(self, rad_length_func: Callable[..., Tensor]) -> None:\n",
    "        for p in self.get_passives():\n",
    "            p.load_rad_length(rad_length_func)\n",
    "\n",
    "    def forward(self, mu: MuonBatch) -> None:  # Expand to take volume as input, too\n",
    "        for l in self.layers:\n",
    "            l(mu)\n",
    "            mu.snapshot_xyz()\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        cost = None\n",
    "        for l in self.layers:\n",
    "            if hasattr(l, \"get_cost\"):\n",
    "                if cost is None:\n",
    "                    cost = l.get_cost()\n",
    "                else:\n",
    "                    cost = cost + l.get_cost()\n",
    "        if cost is None:\n",
    "            cost = torch.zeros((1))\n",
    "        return cost\n",
    "\n",
    "    @property\n",
    "    def lw(self) -> Tensor:\n",
    "        return self.get_passives()[-1].lw\n",
    "\n",
    "    @property\n",
    "    def passive_size(self) -> float:\n",
    "        return self.get_passives()[-1].size  # Same size for each passive layer\n",
    "\n",
    "    @property\n",
    "    def h(self) -> float:\n",
    "        return self.layers[0].z\n",
    "\n",
    "    def get_passive_z_range(self) -> Tuple[Tensor, Tensor]:\n",
    "        ps = self.get_passives()\n",
    "        return ps[-1].z-self.passive_size, ps[0].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=1.0, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "  (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "  (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.8000])\n",
      "tensor([0.7000])\n",
      "tensor([0.6000])\n",
      "tensor([0.5000])\n",
      "tensor([0.4000])\n",
      "tensor([0.3000])\n",
      "tensor([0.2000])\n"
     ]
    }
   ],
   "source": [
    "for l in volume: print(l.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2000]), tensor([0.8000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.get_passive_z_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "  (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "  (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[-1].panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=1.0, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=1.0, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# volume.train()\n",
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8589, 0.7916, 1.0000],\n",
       "         [0.2207, 0.5713, 1.0000],\n",
       "         [0.6911, 0.3212, 1.0000],\n",
       "         [0.4688, 0.9503, 1.0000],\n",
       "         [0.7409, 0.6686, 1.0000],\n",
       "         [0.5305, 0.9282, 1.0000],\n",
       "         [0.5700, 0.9633, 1.0000],\n",
       "         [0.8782, 0.2879, 1.0000],\n",
       "         [0.8318, 0.5664, 1.0000],\n",
       "         [0.9348, 0.7302, 1.0000],\n",
       "         [0.4821, 0.5587, 1.0000],\n",
       "         [0.7702, 0.4576, 1.0000],\n",
       "         [0.1130, 0.6128, 1.0000],\n",
       "         [0.3272, 0.4270, 1.0000],\n",
       "         [0.0736, 0.7754, 1.0000],\n",
       "         [0.9356, 0.0893, 1.0000],\n",
       "         [0.3831, 0.9369, 1.0000],\n",
       "         [0.4393, 0.5800, 1.0000],\n",
       "         [0.0444, 0.5172, 1.0000],\n",
       "         [0.8299, 0.4071, 1.0000],\n",
       "         [0.3935, 0.5992, 1.0000],\n",
       "         [0.4685, 0.1541, 1.0000],\n",
       "         [0.6604, 0.1700, 1.0000],\n",
       "         [0.1252, 0.5836, 1.0000],\n",
       "         [0.9798, 0.9645, 1.0000],\n",
       "         [0.1747, 0.7527, 1.0000],\n",
       "         [0.5503, 0.2083, 1.0000],\n",
       "         [0.5799, 0.5353, 1.0000],\n",
       "         [0.6944, 0.0717, 1.0000],\n",
       "         [0.4274, 0.1633, 1.0000],\n",
       "         [0.8649, 0.0542, 1.0000],\n",
       "         [0.2733, 0.5549, 1.0000],\n",
       "         [0.6777, 0.6437, 1.0000],\n",
       "         [0.7595, 0.7930, 1.0000],\n",
       "         [0.4032, 0.3152, 1.0000],\n",
       "         [0.6626, 0.2227, 1.0000],\n",
       "         [0.2958, 0.6190, 1.0000],\n",
       "         [0.4667, 0.2481, 1.0000],\n",
       "         [0.3684, 0.3925, 1.0000],\n",
       "         [0.4261, 0.9177, 1.0000],\n",
       "         [0.5400, 0.9287, 1.0000],\n",
       "         [0.0267, 0.3189, 1.0000],\n",
       "         [0.2613, 0.8100, 1.0000],\n",
       "         [0.5244, 0.9120, 1.0000],\n",
       "         [0.6609, 0.7977, 1.0000],\n",
       "         [0.3979, 0.6083, 1.0000],\n",
       "         [0.1274, 0.3235, 1.0000],\n",
       "         [0.2569, 0.1433, 1.0000],\n",
       "         [0.2581, 0.4888, 1.0000],\n",
       "         [0.1475, 0.0256, 1.0000],\n",
       "         [0.9990, 0.6367, 1.0000],\n",
       "         [0.3788, 0.8327, 1.0000],\n",
       "         [0.1632, 0.2041, 1.0000],\n",
       "         [0.8075, 0.5176, 1.0000],\n",
       "         [0.6060, 0.6055, 1.0000],\n",
       "         [0.3346, 0.7178, 1.0000],\n",
       "         [0.6216, 0.1097, 1.0000],\n",
       "         [0.9634, 0.2456, 1.0000],\n",
       "         [0.2934, 0.6688, 1.0000],\n",
       "         [0.5126, 0.8685, 1.0000],\n",
       "         [0.9960, 0.7180, 1.0000],\n",
       "         [0.2984, 0.9059, 1.0000],\n",
       "         [0.5637, 0.9369, 1.0000],\n",
       "         [0.9811, 0.4617, 1.0000],\n",
       "         [0.2702, 0.7177, 1.0000],\n",
       "         [0.6367, 0.2518, 1.0000],\n",
       "         [0.4930, 0.8722, 1.0000],\n",
       "         [0.5423, 0.7350, 1.0000],\n",
       "         [0.0781, 0.4246, 1.0000],\n",
       "         [0.6507, 0.7017, 1.0000],\n",
       "         [0.3406, 0.6279, 1.0000],\n",
       "         [0.6473, 0.6728, 1.0000],\n",
       "         [0.6433, 0.7181, 1.0000],\n",
       "         [0.6022, 0.7441, 1.0000],\n",
       "         [0.9527, 0.0368, 1.0000],\n",
       "         [0.9434, 0.2738, 1.0000],\n",
       "         [0.0222, 0.4133, 1.0000],\n",
       "         [0.8491, 0.0752, 1.0000],\n",
       "         [0.8249, 0.1722, 1.0000],\n",
       "         [0.5135, 0.3848, 1.0000],\n",
       "         [0.3487, 0.5611, 1.0000],\n",
       "         [0.6748, 0.2093, 1.0000]], grad_fn=<CatBackward>),\n",
       " tensor([[0.8466, 0.7882, 0.9500],\n",
       "         [0.2254, 0.5774, 0.9500],\n",
       "         [0.6927, 0.3200, 0.9500],\n",
       "         [0.4625, 0.9471, 0.9500],\n",
       "         [0.7392, 0.6694, 0.9500],\n",
       "         [0.5267, 0.9254, 0.9500],\n",
       "         [0.5648, 0.9598, 0.9500],\n",
       "         [0.8659, 0.2881, 0.9500],\n",
       "         [0.8257, 0.5694, 0.9500],\n",
       "         [0.9363, 0.7219, 0.9500],\n",
       "         [0.4821, 0.5499, 0.9500],\n",
       "         [0.7556, 0.4550, 0.9500],\n",
       "         [0.1073, 0.6160, 0.9500],\n",
       "         [0.3275, 0.4197, 0.9500],\n",
       "         [0.0909, 0.7765, 0.9500],\n",
       "         [0.9331, 0.0886, 0.9500],\n",
       "         [0.3780, 0.9309, 0.9500],\n",
       "         [0.4384, 0.5819, 0.9500],\n",
       "         [0.0571, 0.5104, 0.9500],\n",
       "         [0.8306, 0.4109, 0.9500],\n",
       "         [0.3991, 0.5935, 0.9500],\n",
       "         [0.4773, 0.1495, 0.9500],\n",
       "         [0.6595, 0.1703, 0.9500],\n",
       "         [0.1254, 0.5876, 0.9500],\n",
       "         [0.9793, 0.9637, 0.9500],\n",
       "         [0.1802, 0.7614, 0.9500],\n",
       "         [0.5477, 0.1995, 0.9500],\n",
       "         [0.5807, 0.5344, 0.9500],\n",
       "         [0.6894, 0.0677, 0.9500],\n",
       "         [0.4190, 0.1598, 0.9500],\n",
       "         [0.8605, 0.0524, 0.9500],\n",
       "         [0.2672, 0.5530, 0.9500],\n",
       "         [0.6791, 0.6359, 0.9500],\n",
       "         [0.7582, 0.7858, 0.9500],\n",
       "         [0.4065, 0.3194, 0.9500],\n",
       "         [0.6591, 0.2179, 0.9500],\n",
       "         [0.2931, 0.6181, 0.9500],\n",
       "         [0.4623, 0.2491, 0.9500],\n",
       "         [0.3756, 0.3991, 0.9500],\n",
       "         [0.4216, 0.9167, 0.9500],\n",
       "         [0.5246, 0.9302, 0.9500],\n",
       "         [0.0283, 0.3230, 0.9500],\n",
       "         [0.2629, 0.8079, 0.9500],\n",
       "         [0.5291, 0.9059, 0.9500],\n",
       "         [0.6634, 0.8032, 0.9500],\n",
       "         [0.3927, 0.6121, 0.9500],\n",
       "         [0.1299, 0.3296, 0.9500],\n",
       "         [0.2545, 0.1371, 0.9500],\n",
       "         [0.2636, 0.4907, 0.9500],\n",
       "         [0.1574, 0.0255, 0.9500],\n",
       "         [0.9925, 0.6365, 0.9500],\n",
       "         [0.3817, 0.8347, 0.9500],\n",
       "         [0.1631, 0.2054, 0.9500],\n",
       "         [0.8092, 0.5188, 0.9500],\n",
       "         [0.6101, 0.6084, 0.9500],\n",
       "         [0.3394, 0.7264, 0.9500],\n",
       "         [0.6299, 0.1082, 0.9500],\n",
       "         [0.9550, 0.2441, 0.9500],\n",
       "         [0.2950, 0.6740, 0.9500],\n",
       "         [0.5110, 0.8707, 0.9500],\n",
       "         [0.9870, 0.7235, 0.9500],\n",
       "         [0.3013, 0.9072, 0.9500],\n",
       "         [0.5596, 0.9395, 0.9500],\n",
       "         [0.9762, 0.4520, 0.9500],\n",
       "         [0.2620, 0.7135, 0.9500],\n",
       "         [0.6401, 0.2549, 0.9500],\n",
       "         [0.4899, 0.8718, 0.9500],\n",
       "         [0.5428, 0.7227, 0.9500],\n",
       "         [0.0787, 0.4242, 0.9500],\n",
       "         [0.6532, 0.7012, 0.9500],\n",
       "         [0.3382, 0.6324, 0.9500],\n",
       "         [0.6476, 0.6746, 0.9500],\n",
       "         [0.6378, 0.7165, 0.9500],\n",
       "         [0.6005, 0.7406, 0.9500],\n",
       "         [0.9552, 0.0363, 0.9500],\n",
       "         [0.9418, 0.2628, 0.9500],\n",
       "         [0.0314, 0.4136, 0.9500],\n",
       "         [0.8424, 0.0730, 0.9500],\n",
       "         [0.8155, 0.1793, 0.9500],\n",
       "         [0.5152, 0.3813, 0.9500],\n",
       "         [0.3440, 0.5608, 0.9500],\n",
       "         [0.6762, 0.2068, 0.9500]], grad_fn=<CatBackward>),\n",
       " tensor([[0.8397, 0.7879, 0.9000],\n",
       "         [0.2294, 0.5821, 0.9000],\n",
       "         [0.6999, 0.3183, 0.9000],\n",
       "         [0.4586, 0.9475, 0.9000],\n",
       "         [0.7362, 0.6690, 0.9000],\n",
       "         [0.5276, 0.9236, 0.9000],\n",
       "         [0.5610, 0.9521, 0.9000],\n",
       "         [0.8552, 0.2851, 0.9000],\n",
       "         [0.8216, 0.5693, 0.9000],\n",
       "         [0.9356, 0.7136, 0.9000],\n",
       "         [0.4822, 0.5448, 0.9000],\n",
       "         [0.7425, 0.4551, 0.9000],\n",
       "         [0.1052, 0.6219, 0.9000],\n",
       "         [0.3282, 0.4133, 0.9000],\n",
       "         [0.1063, 0.7744, 0.9000],\n",
       "         [0.9355, 0.0855, 0.9000],\n",
       "         [0.3763, 0.9312, 0.9000],\n",
       "         [0.4368, 0.5854, 0.9000],\n",
       "         [0.0635, 0.5089, 0.9000],\n",
       "         [0.8324, 0.4112, 0.9000],\n",
       "         [0.4032, 0.5873, 0.9000],\n",
       "         [0.4835, 0.1511, 0.9000],\n",
       "         [0.6585, 0.1721, 0.9000],\n",
       "         [0.1271, 0.5936, 0.9000],\n",
       "         [0.9741, 0.9625, 0.9000],\n",
       "         [0.1867, 0.7682, 0.9000],\n",
       "         [0.5496, 0.1966, 0.9000],\n",
       "         [0.5814, 0.5325, 0.9000],\n",
       "         [0.6858, 0.0685, 0.9000],\n",
       "         [0.4095, 0.1572, 0.9000],\n",
       "         [0.8517, 0.0538, 0.9000],\n",
       "         [0.2576, 0.5543, 0.9000],\n",
       "         [0.6827, 0.6285, 0.9000],\n",
       "         [0.7578, 0.7765, 0.9000],\n",
       "         [0.4138, 0.3217, 0.9000],\n",
       "         [0.6564, 0.2118, 0.9000],\n",
       "         [0.2911, 0.6136, 0.9000],\n",
       "         [0.4575, 0.2506, 0.9000],\n",
       "         [0.3764, 0.4038, 0.9000],\n",
       "         [0.4185, 0.9174, 0.9000],\n",
       "         [0.5106, 0.9321, 0.9000],\n",
       "         [0.0323, 0.3301, 0.9000],\n",
       "         [0.2643, 0.8065, 0.9000],\n",
       "         [0.5339, 0.9018, 0.9000],\n",
       "         [0.6679, 0.8086, 0.9000],\n",
       "         [0.3881, 0.6183, 0.9000],\n",
       "         [0.1350, 0.3354, 0.9000],\n",
       "         [0.2523, 0.1339, 0.9000],\n",
       "         [0.2673, 0.4932, 0.9000],\n",
       "         [0.1624, 0.0239, 0.9000],\n",
       "         [0.9896, 0.6358, 0.9000],\n",
       "         [0.3826, 0.8322, 0.9000],\n",
       "         [0.1632, 0.2075, 0.9000],\n",
       "         [0.8091, 0.5214, 0.9000],\n",
       "         [0.6149, 0.6138, 0.9000],\n",
       "         [0.3443, 0.7344, 0.9000],\n",
       "         [0.6372, 0.1059, 0.9000],\n",
       "         [0.9485, 0.2387, 0.9000],\n",
       "         [0.2955, 0.6819, 0.9000],\n",
       "         [0.5127, 0.8713, 0.9000],\n",
       "         [0.9811, 0.7262, 0.9000],\n",
       "         [0.3054, 0.9078, 0.9000],\n",
       "         [0.5580, 0.9412, 0.9000],\n",
       "         [0.9731, 0.4448, 0.9000],\n",
       "         [0.2582, 0.7108, 0.9000],\n",
       "         [0.6467, 0.2582, 0.9000],\n",
       "         [0.4875, 0.8744, 0.9000],\n",
       "         [0.5406, 0.7115, 0.9000],\n",
       "         [0.0798, 0.4269, 0.9000],\n",
       "         [0.6517, 0.6981, 0.9000],\n",
       "         [0.3336, 0.6370, 0.9000],\n",
       "         [0.6461, 0.6748, 0.9000],\n",
       "         [0.6292, 0.7110, 0.9000],\n",
       "         [0.6003, 0.7358, 0.9000],\n",
       "         [0.9592, 0.0346, 0.9000],\n",
       "         [0.9393, 0.2535, 0.9000],\n",
       "         [0.0424, 0.4146, 0.9000],\n",
       "         [0.8354, 0.0709, 0.9000],\n",
       "         [0.8118, 0.1858, 0.9000],\n",
       "         [0.5148, 0.3840, 0.9000],\n",
       "         [0.3402, 0.5600, 0.9000],\n",
       "         [0.6737, 0.2068, 0.9000]], grad_fn=<CatBackward>),\n",
       " tensor([[0.8328, 0.7848, 0.8500],\n",
       "         [0.2318, 0.5856, 0.8500],\n",
       "         [0.7036, 0.3163, 0.8500],\n",
       "         [0.4538, 0.9464, 0.8500],\n",
       "         [0.7356, 0.6669, 0.8500],\n",
       "         [0.5236, 0.9243, 0.8500],\n",
       "         [0.5543, 0.9501, 0.8500],\n",
       "         [0.8441, 0.2796, 0.8500],\n",
       "         [0.8197, 0.5723, 0.8500],\n",
       "         [0.9378, 0.7032, 0.8500],\n",
       "         [0.4842, 0.5366, 0.8500],\n",
       "         [0.7261, 0.4529, 0.8500],\n",
       "         [0.1009, 0.6253, 0.8500],\n",
       "         [0.3301, 0.4096, 0.8500],\n",
       "         [0.1241, 0.7735, 0.8500],\n",
       "         [0.9348, 0.0846, 0.8500],\n",
       "         [0.3723, 0.9299, 0.8500],\n",
       "         [0.4348, 0.5872, 0.8500],\n",
       "         [0.0693, 0.5015, 0.8500],\n",
       "         [0.8330, 0.4138, 0.8500],\n",
       "         [0.4049, 0.5835, 0.8500],\n",
       "         [0.4913, 0.1482, 0.8500],\n",
       "         [0.6586, 0.1721, 0.8500],\n",
       "         [0.1268, 0.5967, 0.8500],\n",
       "         [0.9702, 0.9614, 0.8500],\n",
       "         [0.1906, 0.7756, 0.8500],\n",
       "         [0.5486, 0.1936, 0.8500],\n",
       "         [0.5828, 0.5329, 0.8500],\n",
       "         [0.6846, 0.0673, 0.8500],\n",
       "         [0.4012, 0.1545, 0.8500],\n",
       "         [0.8457, 0.0511, 0.8500],\n",
       "         [0.2541, 0.5555, 0.8500],\n",
       "         [0.6816, 0.6213, 0.8500],\n",
       "         [0.7596, 0.7722, 0.8500],\n",
       "         [0.4189, 0.3251, 0.8500],\n",
       "         [0.6494, 0.2081, 0.8500],\n",
       "         [0.2921, 0.6104, 0.8500],\n",
       "         [0.4546, 0.2534, 0.8500],\n",
       "         [0.3826, 0.4096, 0.8500],\n",
       "         [0.4141, 0.9124, 0.8500],\n",
       "         [0.4949, 0.9327, 0.8500],\n",
       "         [0.0339, 0.3371, 0.8500],\n",
       "         [0.2648, 0.8040, 0.8500],\n",
       "         [0.5366, 0.8965, 0.8500],\n",
       "         [0.6723, 0.8117, 0.8500],\n",
       "         [0.3862, 0.6218, 0.8500],\n",
       "         [0.1406, 0.3425, 0.8500],\n",
       "         [0.2451, 0.1310, 0.8500],\n",
       "         [0.2765, 0.4965, 0.8500],\n",
       "         [0.1683, 0.0273, 0.8500],\n",
       "         [0.9832, 0.6374, 0.8500],\n",
       "         [0.3841, 0.8299, 0.8500],\n",
       "         [0.1660, 0.2097, 0.8500],\n",
       "         [0.8107, 0.5187, 0.8500],\n",
       "         [0.6210, 0.6175, 0.8500],\n",
       "         [0.3485, 0.7402, 0.8500],\n",
       "         [0.6471, 0.1051, 0.8500],\n",
       "         [0.9444, 0.2360, 0.8500],\n",
       "         [0.2968, 0.6915, 0.8500],\n",
       "         [0.5098, 0.8723, 0.8500],\n",
       "         [0.9711, 0.7295, 0.8500],\n",
       "         [0.3064, 0.9096, 0.8500],\n",
       "         [0.5556, 0.9448, 0.8500],\n",
       "         [0.9721, 0.4366, 0.8500],\n",
       "         [0.2502, 0.7050, 0.8500],\n",
       "         [0.6479, 0.2622, 0.8500],\n",
       "         [0.4855, 0.8712, 0.8500],\n",
       "         [0.5403, 0.6998, 0.8500],\n",
       "         [0.0787, 0.4258, 0.8500],\n",
       "         [0.6492, 0.6978, 0.8500],\n",
       "         [0.3303, 0.6412, 0.8500],\n",
       "         [0.6481, 0.6764, 0.8500],\n",
       "         [0.6205, 0.7073, 0.8500],\n",
       "         [0.5985, 0.7320, 0.8500],\n",
       "         [0.9587, 0.0328, 0.8500],\n",
       "         [0.9367, 0.2430, 0.8500],\n",
       "         [0.0487, 0.4178, 0.8500],\n",
       "         [0.8251, 0.0697, 0.8500],\n",
       "         [0.8013, 0.1926, 0.8500],\n",
       "         [0.5132, 0.3864, 0.8500],\n",
       "         [0.3363, 0.5582, 0.8500],\n",
       "         [0.6753, 0.2021, 0.8500]], grad_fn=<CatBackward>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = muons.get_hits(volume.lw)\n",
    "above_hits = [torch.cat([hits[\"above\"][\"reco_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "above_gen_hits = [torch.cat([hits[\"above\"][\"gen_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "above_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1677e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.5815e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.2342e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.3653e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-7.6918e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.1026e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.1309e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.9204e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.9050e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.4494e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.3852e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  7.2282e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 5.4755e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00,  3.7050e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.7507e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00, -9.6373e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-4.1996e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00, -3.4384e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.3974e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00,  6.1097e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tomopt.utils import jacobian\n",
    "jacobian(above_hits[0], volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tomopt.utils import jacobian\n",
    "jacobian(above_hits[0], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2207, 0.5713, 1.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.2254, 0.5774, 0.9500], grad_fn=<SelectBackward>),\n",
       " tensor([0.2294, 0.5821, 0.9000], grad_fn=<SelectBackward>),\n",
       " tensor([0.2318, 0.5856, 0.8500], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[1] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.8589, 0.7916, 1.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.8466, 0.7882, 0.9500], grad_fn=<SelectBackward>),\n",
       " tensor([0.8397, 0.7879, 0.9000], grad_fn=<SelectBackward>),\n",
       " tensor([0.8328, 0.7848, 0.8500], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[0] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_uncs(dets: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "    res = []\n",
    "    for l,h in zip(dets,hits):\n",
    "        r = 1 / l.get_resolution(h[:,:2])\n",
    "        res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = get_hit_uncs(volume.get_detectors()[0].panels, above_gen_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0013, 0.0012, 0.0000],\n",
       "        [0.0012, 0.0010, 0.0000],\n",
       "        [0.0011, 0.0011, 0.0000],\n",
       "        [0.0010, 0.0015, 0.0000],\n",
       "        [0.0011, 0.0011, 0.0000],\n",
       "        [0.0010, 0.0014, 0.0000],\n",
       "        [0.0010, 0.0015, 0.0000],\n",
       "        [0.0013, 0.0011, 0.0000],\n",
       "        [0.0012, 0.0010, 0.0000],\n",
       "        [0.0015, 0.0011, 0.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0012, 0.0010, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0012, 0.0010, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0012, 0.0010, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0012, 0.0010, 0.0000], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u[1] for u in uncs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0019,  0.0000],\n",
       "         [ 0.0000, -0.0014],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0013,  0.0000],\n",
       "         [ 0.0000, -0.0003],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0008,  0.0000],\n",
       "         [ 0.0000,  0.0008],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0001,  0.0000],\n",
       "         [ 0.0000, -0.0027],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0011,  0.0000],\n",
       "         [ 0.0000, -0.0007],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0001,  0.0000],\n",
       "         [ 0.0000, -0.0025],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0003,  0.0000],\n",
       "         [ 0.0000, -0.0028],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0020,  0.0000],\n",
       "         [ 0.0000,  0.0009],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0016,  0.0000],\n",
       "         [ 0.0000, -0.0003],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0025,  0.0000],\n",
       "         [ 0.0000, -0.0010],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(uncs[0], volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(uncs[0], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "    r\"\"\"\n",
    "    hits = [muons,(x,y,z)]\n",
    "    uncs = [(unc,unc,0)]\n",
    "\n",
    "    Assume no uncertainty for z\n",
    "    \n",
    "    In eval mode:\n",
    "        Muons with <2 hits within panels have NaN trajectory.\n",
    "        Muons with >=2 hits in panels have valid trajectories\n",
    "    \"\"\"\n",
    "\n",
    "    hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "    hits = torch.where(torch.isinf(hits), torch.tensor([0.5], device=uncs.device), hits)\n",
    "    \n",
    "    stars, angles = [],[]\n",
    "    for i in range(2):  # seperate x and y resolutions\n",
    "        inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "        sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "        mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_x = mean_xz[:, :1]\n",
    "        mean_z = mean_xz[:, 1:]\n",
    "        mean_x_z = mean_xz_z[:, :1]\n",
    "        mean_z2 = mean_xz_z[:, 1:]\n",
    "        \n",
    "        stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "        angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "    xy_star = torch.cat(stars, dim=-1)\n",
    "    angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "    def _calc_xyz(z: Tensor) -> Tensor:\n",
    "        return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "\n",
    "    return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0085, -0.0021, -0.0500],\n",
       "        [ 0.0037,  0.0047, -0.0500],\n",
       "        [ 0.0045, -0.0017, -0.0500],\n",
       "        [-0.0049, -0.0011, -0.0500],\n",
       "        [-0.0019, -0.0005, -0.0500],\n",
       "        [-0.0020, -0.0013, -0.0500],\n",
       "        [-0.0051, -0.0047, -0.0500],\n",
       "        [-0.0113, -0.0028, -0.0500],\n",
       "        [-0.0040,  0.0018, -0.0500],\n",
       "        [ 0.0008, -0.0089, -0.0500]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = get_muon_trajectory(above_hits, uncs); traj[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0788e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00, -7.2597e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-4.8749e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.4931e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.1975e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.6285e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 7.2997e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00, -2.8291e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 6.2742e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.4687e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.2562e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0376e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0712e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.3328e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.4914e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -4.4183e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.2426e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  5.9713e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.8235e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  5.3114e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(traj, volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1262, -0.0303, -1.0000],\n",
       "        [ 0.0545,  0.0689, -1.0000],\n",
       "        [ 0.0583, -0.0223, -1.0000],\n",
       "        [-0.0704, -0.0188, -1.0000],\n",
       "        [-0.0267, -0.0048, -1.0000],\n",
       "        [-0.0296, -0.0219, -1.0000],\n",
       "        [-0.0708, -0.0657, -1.0000],\n",
       "        [-0.1612, -0.0332, -1.0000],\n",
       "        [-0.0603,  0.0259, -1.0000],\n",
       "        [ 0.0116, -0.1240, -1.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(traj, volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.utils import jacobian\n",
    "\n",
    "class PanelScatterBatch(ScatterBatch):\n",
    "    @staticmethod\n",
    "    def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "        r\"\"\"\n",
    "        hits = [muons,(x,y,z)]\n",
    "        uncs = [(unc,unc,0)]\n",
    "\n",
    "        Assume no uncertainty for z\n",
    "\n",
    "        In eval mode:\n",
    "            Muons with <2 hits within panels have NaN trajectory.\n",
    "            Muons with >=2 hits in panels have valid trajectories\n",
    "        \"\"\"\n",
    "\n",
    "        hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "        hits = torch.where(torch.isinf(hits), torch.tensor([0.5], device=uncs.device), hits)\n",
    "\n",
    "        stars, angles = [],[]\n",
    "        for i in range(2):  # seperate x and y resolutions\n",
    "            inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "            sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "            mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_x = mean_xz[:, :1]\n",
    "            mean_z = mean_xz[:, 1:]\n",
    "            mean_x_z = mean_xz_z[:, :1]\n",
    "            mean_z2 = mean_xz_z[:, 1:]\n",
    "\n",
    "            stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "            angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "        xy_star = torch.cat(stars, dim=-1)\n",
    "        angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "        def _calc_xyz(z: Tensor) -> Tensor:\n",
    "            return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "        \n",
    "        return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_hit_uncs(zordered_panels: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "        res = []\n",
    "        for l,h in zip(zordered_panels,hits):\n",
    "            r = 1 / l.get_resolution(h[:,:2])\n",
    "            res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "        return res\n",
    "    \n",
    "    def compute_tracks(self) -> None:\n",
    "        # reco x, reco y, gen z, must be a list to allow computation of uncertainty\n",
    "        self.above_hits = [torch.cat([self.hits[\"above\"][\"reco_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "        self.below_hits = [torch.cat([self.hits[\"below\"][\"reco_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"reco_xy\"].shape[1])]\n",
    "        self.above_gen_hits = [torch.cat([self.hits[\"above\"][\"gen_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "        self.below_gen_hits = [torch.cat([self.hits[\"below\"][\"gen_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"gen_xy\"].shape[1])]\n",
    "        self.n_hits_above = len(self.above_hits)\n",
    "        \n",
    "        self.above_hit_uncs = self.get_hit_uncs([self.volume.get_detectors()[0].panels[i] for i in self.volume.get_detectors()[0].get_panel_zorder()], self.above_gen_hits)\n",
    "        self.below_hit_uncs = self.get_hit_uncs([self.volume.get_detectors()[1].panels[i] for i in self.volume.get_detectors()[1].get_panel_zorder()], self.below_gen_hits)\n",
    "    \n",
    "        self.track_in = self.get_muon_trajectory(self.above_hits, self.above_hit_uncs)\n",
    "        self.track_out = self.get_muon_trajectory(self.below_hits, self.below_hit_uncs)\n",
    "        \n",
    "    def _compute_unc(self, var: Tensor, hits: List[Tensor], hit_uncs: List[Tensor]) -> Tensor:\n",
    "        unc2_sum = None\n",
    "        for i, (xi, unci) in enumerate(zip(hits, hit_uncs)):\n",
    "            for j, (xj, uncj) in enumerate(zip(hits, hit_uncs)):\n",
    "                if j < i:\n",
    "                    continue\n",
    "                dv_dx_2 = torch.nan_to_num(jacobian(var, xi)).sum(2) * torch.nan_to_num(jacobian(var, xj)).sum(2) if i != j else torch.nan_to_num(jacobian(var, xi)).sum(2) ** 2  # Muons, var_xyz, hit_xyz\n",
    "                unc_2 = (dv_dx_2 * unci[:, None] * uncj[:, None]).sum(2)  # Muons, (x,y,z)\n",
    "                if unc2_sum is None:\n",
    "                    unc2_sum = unc_2\n",
    "                else:\n",
    "                    unc2_sum = unc2_sum + unc_2\n",
    "        return torch.sqrt(unc2_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb = PanelScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7680, 0.7690, 0.4610],\n",
       "         [0.2959, 0.6663, 0.0562],\n",
       "         [0.7378, 0.3101, 0.5135],\n",
       "         [0.3989, 0.9321, 0.2823],\n",
       "         [0.7248, 0.6639, 0.5769],\n",
       "         [0.5143, 0.9082, 0.4860],\n",
       "         [0.5293, 0.9260, 0.6049],\n",
       "         [0.6737, 0.2378, 0.0898],\n",
       "         [0.7937, 0.5850, 0.5042],\n",
       "         [0.9444, 0.6244, 0.4084]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0315, 0.0101, 0.1766],\n",
       "         [0.0355, 0.0551, 0.5257],\n",
       "         [0.0559, 0.0180, 0.6598],\n",
       "         [0.0152, 0.0062, 0.1970],\n",
       "         [0.0034, 0.0030, 0.0715],\n",
       "         [0.0158, 0.0131, 0.5185],\n",
       "         [0.0176, 0.0142, 0.1677],\n",
       "         [0.0701, 0.0115, 0.2964],\n",
       "         [0.0116, 0.0048, 0.1680],\n",
       "         [0.0078, 0.0441, 0.2362]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[:10], sb.location_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sb.get_scatter_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7680, 0.7690, 0.4610],\n",
       "         [0.7378, 0.3101, 0.5135],\n",
       "         [0.3989, 0.9321, 0.2823],\n",
       "         [0.7248, 0.6639, 0.5769],\n",
       "         [0.5143, 0.9082, 0.4860],\n",
       "         [0.5293, 0.9260, 0.6049],\n",
       "         [0.7937, 0.5850, 0.5042],\n",
       "         [0.9444, 0.6244, 0.4084],\n",
       "         [0.4905, 0.4812, 0.4306],\n",
       "         [0.5721, 0.4374, 0.3198]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0315, 0.0101, 0.1766],\n",
       "         [0.0559, 0.0180, 0.6598],\n",
       "         [0.0152, 0.0062, 0.1970],\n",
       "         [0.0034, 0.0030, 0.0715],\n",
       "         [0.0158, 0.0131, 0.5185],\n",
       "         [0.0176, 0.0142, 0.1677],\n",
       "         [0.0116, 0.0048, 0.1680],\n",
       "         [0.0078, 0.0441, 0.2362],\n",
       "         [0.0032, 0.0600, 0.4385],\n",
       "         [0.1217, 0.0112, 0.4040]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[m][:10], sb.location_unc[m][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.6891e-02, -2.6739e-02, -4.5713e-01],\n",
       "        [-1.7147e-02,  4.8778e-03,  1.8893e-01],\n",
       "        [-5.0219e-03, -4.3740e-03, -6.4951e-02],\n",
       "        [ 2.0342e-04,  2.4510e-04,  3.8689e-03],\n",
       "        [-1.4466e-02, -1.4685e-02, -4.5616e-01],\n",
       "        [-3.3918e-03, -2.0937e-03, -3.3505e-02],\n",
       "        [-2.0497e-03,  9.6994e-04, -2.8146e-02],\n",
       "        [ 5.6328e-03, -2.4199e-02, -1.3575e-01],\n",
       "        [-6.6763e-05,  3.1729e-03,  2.3809e-02],\n",
       "        [-2.5899e-02, -1.9242e-03, -8.5740e-02]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location[m], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4536e+00,  4.2024e-01,  7.3946e+00],\n",
       "        [ 4.2235e-01, -1.5032e-01, -6.3497e+00],\n",
       "        [-8.5119e-01, -2.3806e-01, -1.1695e+01],\n",
       "        [ 5.4081e-02,  4.8047e-02,  7.3624e-01],\n",
       "        [-1.2628e-01, -9.4798e-02, -4.9784e+00],\n",
       "        [-2.3164e-01, -1.6458e-01, -2.9229e+00],\n",
       "        [-3.5779e-01,  1.1225e-01, -5.7023e+00],\n",
       "        [-3.4734e-01,  2.5884e+00,  1.2758e+01],\n",
       "        [ 2.0255e-01, -5.3549e+00, -3.9313e+01],\n",
       "        [ 2.3438e+01,  2.1090e+00,  7.7516e+01]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location[m], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.4590e-03, -2.3704e-03, -4.1048e-02],\n",
       "        [ 6.8226e-03,  2.4344e-03,  8.4206e-02],\n",
       "        [-7.5571e-04, -1.0427e-03, -6.9404e-03],\n",
       "        [-8.9731e-05, -1.9924e-04, -4.3719e-03],\n",
       "        [-2.6519e-03, -1.9197e-03, -8.0201e-02],\n",
       "        [-2.3645e-03, -1.4394e-03, -2.2900e-02],\n",
       "        [-2.0792e-03, -6.7638e-04, -3.2938e-02],\n",
       "        [-2.6552e-03, -1.5375e-02, -8.3083e-02],\n",
       "        [-9.4770e-05, -2.7503e-03, -1.9873e-02],\n",
       "        [-3.7862e-02, -3.2372e-03, -1.2612e-01]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5814e-03, -1.4348e-03, -2.5036e-02],\n",
       "        [-2.7486e-03, -9.7646e-04, -3.3463e-02],\n",
       "        [-1.1080e-03, -1.0199e-03, -1.1854e-02],\n",
       "        [-2.6314e-05, -6.8020e-05, -1.4926e-03],\n",
       "        [-2.1404e-03, -1.5622e-03, -6.4091e-02],\n",
       "        [-2.1810e-03, -1.3278e-03, -2.1137e-02],\n",
       "        [-1.3020e-03, -4.4262e-04, -2.0809e-02],\n",
       "        [-2.2322e-03, -1.2590e-02, -6.8500e-02],\n",
       "        [-1.0639e-05, -3.3137e-04, -2.3909e-03],\n",
       "        [-2.0535e-02, -1.7639e-03, -6.8402e-02]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8006e-03, -1.6703e-03],\n",
       "        [-6.0448e-04, -5.4739e-04],\n",
       "        [-1.4554e-05, -4.9316e-03],\n",
       "        [-1.0565e-03, -5.0156e-04],\n",
       "        [-1.3009e-05, -4.3740e-03],\n",
       "        [-7.9970e-05, -5.5255e-03],\n",
       "        [-2.2051e-03, -7.0900e-05],\n",
       "        [-4.3810e-03, -9.7334e-04],\n",
       "        [-5.3618e-06, -5.3638e-05],\n",
       "        [-1.3804e-03, -2.8325e-05]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.dtheta_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7583e-03, -2.3293e-03],\n",
       "        [-8.7095e-04, -7.7663e-04],\n",
       "        [-2.0709e-05, -6.9072e-03],\n",
       "        [-1.4815e-03, -7.0452e-04],\n",
       "        [-1.8396e-05, -6.0836e-03],\n",
       "        [-1.1249e-04, -7.5605e-03],\n",
       "        [-3.0594e-03, -1.0064e-04],\n",
       "        [-6.2327e-03, -1.3298e-03],\n",
       "        [-7.5818e-06, -7.5605e-05],\n",
       "        [-1.8400e-03, -4.0115e-05]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.theta_in_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1973e-03, -1.6208e-03],\n",
       "        [-1.7891e-03, -9.1008e-04],\n",
       "        [-2.5191e-04, -6.1237e-03],\n",
       "        [-1.1062e-03, -4.5252e-04],\n",
       "        [-1.9175e-06, -4.9994e-03],\n",
       "        [-4.1742e-06, -5.0408e-03],\n",
       "        [-2.0121e-03, -1.9391e-04],\n",
       "        [-6.9006e-03, -1.5990e-04],\n",
       "        [-1.8235e-06, -5.1494e-05],\n",
       "        [-2.3737e-05, -1.0106e-04]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.theta_out_unc[m], volume.get_detectors()[1].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X0 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelX0Inferer(X0Inferer):\n",
    "    def compute_efficiency(self) -> Tensor:\n",
    "        eff = None\n",
    "        for pos, hits in enumerate([self.scatters.above_gen_hits, self.scatters.below_gen_hits]):\n",
    "            leff = None\n",
    "            layer = self.volume.get_detectors()[pos]\n",
    "            panel_idxs = layer.get_panel_zorder()\n",
    "            effs = torch.stack([layer.panels[i].get_efficiency(hits[i][self.mask,:2]) for i in panel_idxs], dim=0)\n",
    "            for r in range(2,len(effs)+1):  # Muon goes through any combination of at least 2 panels\n",
    "                c = torch.combinations(torch.arange(0,len(effs)), r=r)\n",
    "                e = effs[c].prod(1).sum(0)  \n",
    "                if leff is None:\n",
    "                    leff = e\n",
    "                else:\n",
    "                    leff = leff + e\n",
    "            if eff is None:\n",
    "                eff = leff\n",
    "            else:\n",
    "                eff = eff * leff  # Muons detected above & below passive volume\n",
    "        return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0inf = PanelX0Inferer(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0656, 1.8534, 0.7087, 2.1828, 0.9167, 0.8039, 1.7809, 0.5693, 4.1359,\n",
       "        3.0996, 0.6444, 2.6725, 3.6721, 1.0810, 3.8835, 1.2077, 1.2985, 1.0346,\n",
       "        0.1016, 0.7982, 3.8977, 0.8986, 0.2694, 2.8413, 3.2907, 1.3965, 0.8293,\n",
       "        0.5728, 1.1685, 1.2397, 0.9378, 2.7652, 1.2835, 0.5403, 1.4203, 0.8341,\n",
       "        2.7947, 1.7504, 0.4645, 0.5711, 1.4000, 2.0504, 3.3721, 0.8567, 2.2794,\n",
       "        2.5246, 2.8358, 2.6421, 0.2997, 2.9156], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff = x0inf.compute_efficiency(); eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5129, 0.0465, 0.6551, 2.0237, 0.9260, 0.9384, 1.5758, 0.8265, 0.3774,\n",
       "        1.5926], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].z, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9948, 0.5751, 0.6340, 0.8560, 0.7478, 0.7724, 0.8968, 0.6008, 0.0702,\n",
       "        1.0458], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dtheta, pred_dtheta_unc = x0inf.x0_from_dtheta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dtheta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0025, 0.0075, 0.0025, 0.0005, 0.0041, 0.0015, 0.0023, 0.0031, 0.0075,\n",
       "         0.0125], grad_fn=<SliceBackward>),\n",
       " tensor([0.0021, 0.0104, 0.0019, 0.0002, 0.0043, 0.0013, 0.0017, 0.0035, 0.0094,\n",
       "         0.0198], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dtheta[:10], pred_dtheta_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0022, 0.0026], grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(pred_dtheta[0], volume.get_detectors()[0].panels[0].xy, retain_graph=True, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1279, grad_fn=<SumBackward0>),)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(pred_dtheta[0], volume.get_detectors()[0].panels[0].z, retain_graph=True, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0898e-03,  2.1261e-03, -8.3289e-05,  1.9767e-05, -4.1984e-03,\n",
       "         2.4325e-04,  5.3207e-04,  1.9545e-03, -2.8835e-06,  2.8773e-03,\n",
       "         6.4084e-03,  2.0415e-04,  1.3406e-04,  1.5440e-03, -1.0448e-03,\n",
       "         1.0882e-03,  4.6174e-04,  6.3250e-04,  7.4398e-04,  5.6049e-04,\n",
       "        -1.7870e-05,  4.9218e-04,  8.2552e-04,  6.5805e-05,  1.0338e-03,\n",
       "         2.8523e-04,  2.6442e-04, -5.0536e-02,  9.6289e-04,  1.3080e-03,\n",
       "         1.4980e-03,  2.3724e-04,  8.6472e-04,  7.1463e-04,  1.7151e-03,\n",
       "         2.9199e-03,  9.1076e-05,  2.6988e-04, -1.7308e-01, -1.8560e-03,\n",
       "         1.0175e-03,  4.5483e-02,  2.3145e-05,  6.4889e-03, -6.8825e-03,\n",
       "        -8.6727e-05,  3.6954e-04,  1.9576e-05,  2.4062e-03,  1.1097e-02],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta, volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.4385e-04, -7.4295e-04,  4.2733e-05, -2.8091e-05, -8.8968e-04,\n",
       "        -5.8243e-04, -2.7056e-04, -1.2546e-03,  8.7527e-05, -5.2326e-03,\n",
       "         1.4127e-03,  1.6223e-04, -1.0046e-04,  4.7131e-04,  1.3601e-03,\n",
       "         2.8505e-04,  3.2663e-04,  2.1794e-04, -1.0857e-04,  1.5073e-04,\n",
       "        -2.1329e-04,  1.6874e-04,  2.5833e-04, -1.8026e-04,  3.9819e-03,\n",
       "         1.7866e-04, -3.1018e-05, -8.8169e-03, -1.9971e-04, -2.8977e-04,\n",
       "        -2.6437e-04,  1.4463e-04,  3.0024e-04, -5.3947e-04, -4.0343e-04,\n",
       "         8.4236e-04, -1.5631e-04, -2.2286e-04, -6.3144e-02, -3.8819e-03,\n",
       "        -5.4866e-04, -1.4576e-02, -2.6205e-05,  1.4536e-03,  3.9941e-04,\n",
       "        -3.1242e-04, -1.3154e-04, -1.2937e-05, -7.9021e-04,  1.3565e-03],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].z, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0448e-04, -6.2114e-04, -8.8436e-06, -9.6011e-06, -7.1574e-04,\n",
       "        -5.3919e-04, -1.4478e-04, -1.0417e-03, -1.1027e-05, -2.8717e-03,\n",
       "        -1.1783e-03, -5.5873e-05, -2.9201e-05, -4.4582e-04, -4.7661e-04,\n",
       "        -1.4098e-04, -3.0976e-04, -1.9571e-04, -1.0266e-04, -1.1494e-04,\n",
       "        -3.3900e-05, -1.1279e-04, -2.3102e-04, -5.2228e-05, -1.1043e-03,\n",
       "        -1.4211e-04, -4.7444e-05, -6.1640e-03, -2.8169e-04, -2.3468e-04,\n",
       "        -1.5323e-04, -2.9847e-05, -2.2238e-04, -1.9291e-04, -2.6906e-04,\n",
       "        -5.6460e-04, -3.3245e-05, -1.0786e-04, -4.9053e-02, -3.7897e-03,\n",
       "        -2.9893e-04, -7.1292e-03, -4.4294e-06, -8.9221e-04, -1.9672e-03,\n",
       "        -1.0831e-04, -4.4840e-05, -4.0260e-06, -6.9934e-04, -1.6792e-03],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, weight = x0inf.average_preds(x0_dtheta=pred_dtheta, x0_dtheta_unc=pred_dtheta_unc, x0_dxy=None, x0_dxy_unc=None, efficiency=eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 10, 10]), torch.Size([6, 10, 10]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, weight = x0inf.pred_x0(False)\n",
    "pred.shape, weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9.0482e-02, -3.9891e-02],\n",
       "          [ 9.0805e-02, -4.1124e-02],\n",
       "          [ 8.9953e-02, -4.0512e-02],\n",
       "          ...,\n",
       "          [-8.0357e-03,  9.1615e-04],\n",
       "          [ 3.2189e-03, -5.9352e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.0772e-02, -4.1311e-02],\n",
       "          [-3.7911e-03, -5.7704e-04],\n",
       "          [-3.7952e-03, -5.7738e-04],\n",
       "          ...,\n",
       "          [-6.2529e-04,  1.8206e-03],\n",
       "          [-8.9195e-04,  1.0621e-04],\n",
       "          [ 2.8515e-03, -5.9128e-02]],\n",
       "\n",
       "         [[ 1.0202e-02,  2.9946e-02],\n",
       "          [-1.9117e-05, -7.2922e-04],\n",
       "          [ 6.4333e-03, -6.7978e-03],\n",
       "          ...,\n",
       "          [-1.4553e-04,  1.4893e-03],\n",
       "          [-1.0261e-03,  1.1908e-03],\n",
       "          [-3.0831e-03, -6.7787e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2272e-05, -8.9420e-04],\n",
       "          [ 4.7146e-03, -3.6318e-03],\n",
       "          [ 3.8863e-03, -1.8801e-03],\n",
       "          ...,\n",
       "          [ 1.7596e-03,  2.4720e-03],\n",
       "          [-3.5328e-05,  2.5524e-03],\n",
       "          [-1.4313e-03, -3.0589e-02]],\n",
       "\n",
       "         [[ 4.2236e-05, -8.9421e-04],\n",
       "          [ 1.4334e-03, -7.2458e-04],\n",
       "          [ 3.1456e-03, -1.9897e-03],\n",
       "          ...,\n",
       "          [ 2.2202e-03,  2.5708e-03],\n",
       "          [ 5.5882e-03,  6.8414e-03],\n",
       "          [-1.4362e-03, -6.0009e-02]],\n",
       "\n",
       "         [[ 2.5864e-03, -2.8628e-04],\n",
       "          [ 2.6964e-03, -2.3764e-05],\n",
       "          [ 2.6849e-03, -1.2061e-05],\n",
       "          ...,\n",
       "          [ 2.3956e-03, -1.5875e-04],\n",
       "          [ 4.9086e-02, -2.2602e-02],\n",
       "          [ 5.8904e-04,  1.9566e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0370e-02, -3.9935e-02],\n",
       "          [ 9.0573e-02, -4.1177e-02],\n",
       "          [ 8.9264e-02, -4.0402e-02],\n",
       "          ...,\n",
       "          [-8.0348e-03,  9.1999e-04],\n",
       "          [ 3.2358e-03, -5.9353e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.0889e-02, -4.1333e-02],\n",
       "          [-3.7911e-03, -5.7667e-04],\n",
       "          [-3.7961e-03, -5.7712e-04],\n",
       "          ...,\n",
       "          [-5.6343e-04,  1.7789e-03],\n",
       "          [-7.7897e-04,  1.2980e-04],\n",
       "          [ 2.1804e-03, -5.7950e-02]],\n",
       "\n",
       "         [[ 7.8719e-03,  2.4082e-02],\n",
       "          [-1.9132e-05, -7.2925e-04],\n",
       "          [ 7.0010e-03, -7.1685e-03],\n",
       "          ...,\n",
       "          [-6.8497e-04,  1.4226e-03],\n",
       "          [-7.7079e-04,  4.5834e-04],\n",
       "          [ 4.5326e-04, -1.5937e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2363e-05, -8.9420e-04],\n",
       "          [ 3.7007e-03, -2.5666e-03],\n",
       "          [ 3.8669e-03, -1.8695e-03],\n",
       "          ...,\n",
       "          [ 2.0280e-03,  2.5513e-03],\n",
       "          [-3.6735e-05,  2.5463e-03],\n",
       "          [-1.6100e-03, -3.3450e-02]],\n",
       "\n",
       "         [[ 4.2332e-05, -8.9435e-04],\n",
       "          [ 9.5332e-04, -7.5689e-04],\n",
       "          [ 3.0092e-03, -2.0086e-03],\n",
       "          ...,\n",
       "          [ 2.2207e-03,  2.5702e-03],\n",
       "          [ 3.6713e-03,  4.4161e-03],\n",
       "          [-1.4739e-03, -5.9995e-02]],\n",
       "\n",
       "         [[ 2.5907e-03, -2.7933e-04],\n",
       "          [ 2.6929e-03, -2.3700e-05],\n",
       "          [ 2.6626e-03, -1.0677e-05],\n",
       "          ...,\n",
       "          [ 2.3734e-03, -1.4644e-04],\n",
       "          [ 3.4522e-02, -1.5745e-02],\n",
       "          [ 5.8871e-04,  1.9535e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0374e-02, -3.9974e-02],\n",
       "          [ 9.0926e-02, -4.1251e-02],\n",
       "          [ 8.9702e-02, -4.0476e-02],\n",
       "          ...,\n",
       "          [-8.0348e-03,  9.1538e-04],\n",
       "          [ 3.2518e-03, -5.9545e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.0772e-02, -4.1313e-02],\n",
       "          [-3.7895e-03, -5.7664e-04],\n",
       "          [-3.7957e-03, -5.7702e-04],\n",
       "          ...,\n",
       "          [-5.1097e-04,  1.7133e-03],\n",
       "          [-7.6454e-04,  1.3384e-04],\n",
       "          [ 1.5185e-03, -5.6079e-02]],\n",
       "\n",
       "         [[ 9.5013e-03,  2.9560e-02],\n",
       "          [-1.9119e-05, -7.2873e-04],\n",
       "          [ 7.6108e-03, -7.4749e-03],\n",
       "          ...,\n",
       "          [-1.1056e-03,  1.1789e-03],\n",
       "          [-7.1930e-04,  2.2528e-04],\n",
       "          [ 4.8544e-04, -7.1177e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2277e-05, -8.9409e-04],\n",
       "          [ 3.2120e-03, -2.1075e-03],\n",
       "          [ 3.8864e-03, -1.8730e-03],\n",
       "          ...,\n",
       "          [ 2.1510e-03,  2.5696e-03],\n",
       "          [-3.7283e-05,  2.5342e-03],\n",
       "          [-2.1121e-03, -4.4613e-02]],\n",
       "\n",
       "         [[ 4.2188e-05, -8.9439e-04],\n",
       "          [ 7.3808e-05, -9.6878e-04],\n",
       "          [ 3.0047e-03, -2.0039e-03],\n",
       "          ...,\n",
       "          [ 2.2162e-03,  2.5716e-03],\n",
       "          [ 3.0436e-03,  3.6368e-03],\n",
       "          [-1.4995e-03, -6.0152e-02]],\n",
       "\n",
       "         [[ 2.6222e-03, -2.4004e-04],\n",
       "          [ 2.6794e-03, -2.3551e-05],\n",
       "          [ 2.6175e-03, -7.1185e-06],\n",
       "          ...,\n",
       "          [ 2.3667e-03, -1.4150e-04],\n",
       "          [ 2.5814e-02, -1.1989e-02],\n",
       "          [ 5.8906e-04,  1.9500e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0260e-02, -3.9988e-02],\n",
       "          [ 9.0693e-02, -4.1234e-02],\n",
       "          [ 9.0337e-02, -4.0592e-02],\n",
       "          ...,\n",
       "          [-8.0341e-03,  9.1843e-04],\n",
       "          [ 3.2196e-03, -5.9544e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.1006e-02, -4.1340e-02],\n",
       "          [-3.7941e-03, -5.7734e-04],\n",
       "          [-3.7952e-03, -5.7639e-04],\n",
       "          ...,\n",
       "          [-4.4078e-04,  1.5471e-03],\n",
       "          [-7.6232e-04,  1.3494e-04],\n",
       "          [ 1.7697e-03, -5.5148e-02]],\n",
       "\n",
       "         [[ 1.7382e-02,  5.2349e-02],\n",
       "          [-1.9063e-05, -7.2861e-04],\n",
       "          [ 8.1004e-03, -7.5877e-03],\n",
       "          ...,\n",
       "          [-1.0684e-03,  8.7656e-04],\n",
       "          [-7.2720e-04,  1.7131e-04],\n",
       "          [ 6.7762e-04, -6.2318e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2323e-05, -8.9396e-04],\n",
       "          [ 3.0272e-03, -1.8884e-03],\n",
       "          [ 3.8917e-03, -1.8723e-03],\n",
       "          ...,\n",
       "          [ 2.1945e-03,  2.5746e-03],\n",
       "          [-3.7929e-05,  2.5124e-03],\n",
       "          [-2.9502e-03, -6.6299e-02]],\n",
       "\n",
       "         [[ 4.2149e-05, -8.9429e-04],\n",
       "          [-1.4889e-03, -1.4839e-03],\n",
       "          [ 3.1329e-03, -1.9666e-03],\n",
       "          ...,\n",
       "          [ 2.2162e-03,  2.5655e-03],\n",
       "          [ 2.8447e-03,  3.4089e-03],\n",
       "          [-1.5917e-03, -6.0175e-02]],\n",
       "\n",
       "         [[ 2.6328e-03, -1.8392e-04],\n",
       "          [ 2.6589e-03, -2.3383e-05],\n",
       "          [ 2.4985e-03, -2.3772e-07],\n",
       "          ...,\n",
       "          [ 2.3509e-03, -1.4147e-04],\n",
       "          [ 2.1563e-02, -1.0428e-02],\n",
       "          [ 5.8836e-04,  1.9517e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0145e-02, -3.9954e-02],\n",
       "          [ 9.0811e-02, -4.1240e-02],\n",
       "          [ 9.0603e-02, -4.0763e-02],\n",
       "          ...,\n",
       "          [-8.0364e-03,  9.1611e-04],\n",
       "          [ 3.1946e-03, -5.9398e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.0890e-02, -4.1325e-02],\n",
       "          [-3.7901e-03, -5.7608e-04],\n",
       "          [-3.7931e-03, -5.7657e-04],\n",
       "          ...,\n",
       "          [-3.8933e-04,  1.3212e-03],\n",
       "          [-7.6233e-04,  1.3290e-04],\n",
       "          [ 2.5124e-03, -5.6664e-02]],\n",
       "\n",
       "         [[ 4.0280e-02,  9.6809e-02],\n",
       "          [-1.8770e-05, -7.2814e-04],\n",
       "          [ 8.2849e-03, -7.2864e-03],\n",
       "          ...,\n",
       "          [-9.0814e-04,  7.2783e-04],\n",
       "          [-7.3287e-04,  1.5687e-04],\n",
       "          [ 1.8809e-03, -1.1017e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2647e-05, -8.9370e-04],\n",
       "          [ 3.0691e-03, -1.7167e-03],\n",
       "          [ 3.8874e-03, -1.8686e-03],\n",
       "          ...,\n",
       "          [ 2.2112e-03,  2.5716e-03],\n",
       "          [-3.5172e-05,  2.4692e-03],\n",
       "          [-3.4367e-03, -8.9405e-02]],\n",
       "\n",
       "         [[ 4.2232e-05, -8.9420e-04],\n",
       "          [-3.4726e-03, -2.5873e-03],\n",
       "          [ 3.3273e-03, -1.9225e-03],\n",
       "          ...,\n",
       "          [ 2.2162e-03,  2.5683e-03],\n",
       "          [ 2.8368e-03,  3.4520e-03],\n",
       "          [-1.6293e-03, -6.0346e-02]],\n",
       "\n",
       "         [[ 2.6022e-03, -1.3121e-04],\n",
       "          [ 2.6114e-03, -2.3251e-05],\n",
       "          [ 2.2219e-03,  1.1639e-05],\n",
       "          ...,\n",
       "          [ 2.3596e-03, -1.4501e-04],\n",
       "          [ 2.0292e-02, -1.0513e-02],\n",
       "          [ 5.8938e-04,  1.9529e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0146e-02, -3.9961e-02],\n",
       "          [ 9.0695e-02, -4.1267e-02],\n",
       "          [ 9.0518e-02, -4.0842e-02],\n",
       "          ...,\n",
       "          [-8.0357e-03,  9.1302e-04],\n",
       "          [ 3.1742e-03, -5.9396e-02],\n",
       "          [ 3.1093e-03, -5.9484e-02]],\n",
       "\n",
       "         [[ 9.1009e-02, -4.1380e-02],\n",
       "          [-3.7921e-03, -5.7543e-04],\n",
       "          [-3.7915e-03, -5.7762e-04],\n",
       "          ...,\n",
       "          [-4.1959e-04,  1.0545e-03],\n",
       "          [-7.6652e-04,  1.2187e-04],\n",
       "          [ 2.9708e-03, -5.8483e-02]],\n",
       "\n",
       "         [[ 7.3844e-02,  6.5471e-02],\n",
       "          [-1.6869e-05, -7.2312e-04],\n",
       "          [ 7.9445e-03, -6.2968e-03],\n",
       "          ...,\n",
       "          [-7.3049e-04,  7.3440e-04],\n",
       "          [-7.3164e-04,  1.5429e-04],\n",
       "          [ 7.0336e-03, -3.5247e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.4171e-05, -8.9166e-04],\n",
       "          [ 3.3773e-03, -1.4661e-03],\n",
       "          [ 3.8784e-03, -1.8756e-03],\n",
       "          ...,\n",
       "          [ 2.2209e-03,  2.5727e-03],\n",
       "          [-2.6395e-05,  2.3820e-03],\n",
       "          [-2.2805e-03, -8.7721e-02]],\n",
       "\n",
       "         [[ 4.2449e-05, -8.9397e-04],\n",
       "          [-2.7325e-03, -4.5974e-03],\n",
       "          [ 3.4662e-03, -1.8950e-03],\n",
       "          ...,\n",
       "          [ 2.2191e-03,  2.5680e-03],\n",
       "          [ 3.0116e-03,  3.8556e-03],\n",
       "          [-1.7227e-03, -6.0416e-02]],\n",
       "\n",
       "         [[ 2.4141e-03, -1.0481e-04],\n",
       "          [ 2.4380e-03, -2.3999e-05],\n",
       "          [ 1.4572e-03,  2.6147e-05],\n",
       "          ...,\n",
       "          [ 2.3509e-03, -1.5012e-04],\n",
       "          [ 2.1852e-02, -1.2029e-02],\n",
       "          [ 5.8777e-04,  1.9486e-04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].xy, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.9544e+00, -5.9372e+00, -5.9436e+00,  2.2373e-01,  2.1375e-01,\n",
       "           2.3279e-01, -3.0334e-01, -3.0333e-01, -1.0904e+01, -1.0914e+01],\n",
       "         [-5.9310e+00, -1.1822e-02, -1.1737e-02,  5.5133e-02,  1.0832e-01,\n",
       "           2.0218e-01, -6.8132e-02,  7.6727e-02,  5.6947e-02, -1.0885e+01],\n",
       "         [ 2.7598e-01, -2.7608e-02,  1.0458e+00,  8.0230e-02, -1.0318e+00,\n",
       "          -7.5277e-01,  9.4505e-02,  6.7340e-02,  1.0623e-01, -3.4703e+00],\n",
       "         [-2.9720e-02, -2.7605e-02,  1.0424e+00,  1.8064e-02,  1.6799e-02,\n",
       "          -5.8431e-02, -6.4582e-02,  2.1877e-01,  2.1546e-02, -1.5930e-02],\n",
       "         [ 2.7998e-01, -3.3059e-02,  1.0302e+00,  4.8389e-01,  2.1133e-01,\n",
       "           1.1665e-01,  3.9936e-02,  3.4356e-01,  1.4044e-03, -1.9963e-02],\n",
       "         [ 2.5589e-01, -1.6768e-02, -1.0995e-01,  1.0946e+00, -2.9944e+00,\n",
       "           4.7879e-02,  9.3865e-02, -3.8223e-03, -9.2522e-03,  4.8635e-02],\n",
       "         [-3.9600e-02, -7.2518e-02, -1.3297e-01,  6.5740e-01, -2.0421e-01,\n",
       "          -1.6105e-01,  1.0589e-01,  2.2752e-02, -3.6670e-02, -1.5541e-01],\n",
       "         [-1.2264e-03, -1.7657e-01,  6.6535e-01,  6.6780e-01, -4.2081e-02,\n",
       "           4.6834e-02, -2.1208e-03, -1.1081e-01, -3.6589e-02, -3.7027e-01],\n",
       "         [-1.2223e-03, -6.3508e-02,  5.9451e-01,  6.3143e-01, -2.7771e+00,\n",
       "           6.7081e-02,  4.9674e-02, -1.2778e-01, -1.2243e-01, -1.0239e+01],\n",
       "         [ 3.5565e-02,  4.9037e-02,  4.7036e-02,  1.5323e-02, -1.4462e-01,\n",
       "          -1.7478e-01, -8.9722e-02, -1.7661e-01, -1.6905e-01,  8.4575e-03]],\n",
       "\n",
       "        [[-5.9539e+00, -5.9368e+00, -5.9415e+00,  2.2444e-01,  2.0826e-01,\n",
       "           2.3155e-01, -3.0334e-01, -3.0332e-01, -1.0903e+01, -1.0914e+01],\n",
       "         [-5.9305e+00, -1.1823e-02, -1.1725e-02,  5.5132e-02,  9.5582e-02,\n",
       "           1.5873e-01, -5.5148e-02,  8.6246e-02,  5.1259e-02, -1.0799e+01],\n",
       "         [ 3.1737e-01, -2.7606e-02,  1.0461e+00,  6.9260e-02, -1.2535e+00,\n",
       "          -8.7383e-01,  9.4978e-02,  1.0928e-01,  6.6711e-02, -1.0326e+00],\n",
       "         [-2.5369e-02, -2.7605e-02,  1.1131e+00,  1.8118e-02,  1.6427e-02,\n",
       "          -5.8066e-02, -6.3769e-02,  2.1776e-01,  1.6115e-02, -1.5416e-02],\n",
       "         [ 2.9717e-01, -3.0908e-02,  9.4271e-01,  4.1670e-01,  1.7661e-01,\n",
       "           1.1920e-01,  7.3828e-02,  3.3882e-01, -6.4644e-03, -1.8193e-02],\n",
       "         [ 2.3656e-01, -2.4352e-02, -1.0462e-01,  1.0590e+00, -2.8530e+00,\n",
       "           4.1049e-02,  2.8110e-02,  1.0867e-03, -1.0565e-02,  4.7328e-02],\n",
       "         [-5.1586e-02, -6.9920e-02, -1.1483e-01,  6.5490e-01, -1.6243e-01,\n",
       "          -1.4569e-01,  8.1413e-02, -2.9376e-03, -3.6664e-02, -1.4418e-01],\n",
       "         [-1.2253e-03, -9.6581e-02,  6.6533e-01,  6.7067e-01, -8.7810e-02,\n",
       "           4.0296e-02, -2.1295e-03, -1.1952e-01, -3.6509e-02, -3.6624e-01],\n",
       "         [-1.2222e-03, -7.7516e-02,  5.9019e-01,  6.2406e-01, -2.7566e+00,\n",
       "           6.7079e-02,  6.3542e-02, -1.2782e-01, -1.1878e-01, -1.0228e+01],\n",
       "         [ 3.4582e-02,  4.8837e-02,  4.5600e-02, -1.7258e-02, -1.2372e-01,\n",
       "          -1.7528e-01, -1.0813e-01, -1.7665e-01, -1.1033e-01,  8.4589e-03]],\n",
       "\n",
       "        [[-5.9531e+00, -5.9362e+00, -5.9419e+00,  2.2048e-01,  1.9869e-01,\n",
       "           2.2942e-01, -3.0334e-01, -3.0332e-01, -1.0903e+01, -1.0914e+01],\n",
       "         [-5.9297e+00, -1.1824e-02, -1.1739e-02,  5.5132e-02,  9.3219e-02,\n",
       "           9.6056e-02, -4.9326e-02,  9.9674e-02,  5.0524e-02, -1.0685e+01],\n",
       "         [ 4.9028e-01, -2.7606e-02,  1.0620e+00,  6.6850e-02, -1.7041e+00,\n",
       "          -1.0671e+00,  9.5691e-02,  1.3727e-01,  5.2723e-02, -4.6539e-01],\n",
       "         [-2.0354e-02, -2.7605e-02,  1.3078e+00,  1.8278e-02,  1.5420e-02,\n",
       "          -5.5603e-02, -6.1778e-02,  2.1741e-01,  1.3350e-02, -1.4667e-02],\n",
       "         [ 3.0441e-01, -2.9150e-02,  8.4597e-01,  3.5966e-01,  1.4001e-01,\n",
       "           1.2130e-01,  9.5736e-02,  3.3054e-01, -8.2367e-03, -1.8058e-02],\n",
       "         [ 2.2524e-01, -2.5312e-02, -1.0283e-01,  1.0141e+00, -2.5396e+00,\n",
       "           1.2771e-02,  7.0473e-03,  1.1583e-03, -1.1025e-02,  4.6247e-02],\n",
       "         [-5.7416e-02, -6.6510e-02, -1.0792e-01,  6.5910e-01, -1.4654e-01,\n",
       "          -1.3648e-01,  4.9855e-02,  1.6062e-04, -3.6654e-02, -1.7917e-01],\n",
       "         [-1.2260e-03, -5.7055e-02,  6.6526e-01,  6.7809e-01, -1.0751e-01,\n",
       "           2.8719e-02, -2.1266e-03, -1.2392e-01, -3.6350e-02, -5.3298e-01],\n",
       "         [-1.2223e-03, -1.1941e-01,  5.9151e-01,  6.1732e-01, -2.7456e+00,\n",
       "           6.7075e-02,  6.8000e-02, -1.2784e-01, -1.1757e-01, -1.0217e+01],\n",
       "         [ 3.5216e-02,  4.8396e-02,  4.2543e-02, -6.6560e-02, -1.1180e-01,\n",
       "          -1.7550e-01, -1.1982e-01, -1.7666e-01, -4.0658e-02,  8.4593e-03]],\n",
       "\n",
       "        [[-5.9521e+00, -5.9360e+00, -5.9430e+00,  2.0784e-01,  1.8196e-01,\n",
       "           2.2563e-01, -3.0334e-01, -3.0333e-01, -1.0903e+01, -1.0914e+01],\n",
       "         [-5.9293e+00, -1.1829e-02, -1.1770e-02,  5.5132e-02,  1.0010e-01,\n",
       "           3.9426e-02, -4.7857e-02,  1.0988e-01,  5.0345e-02, -1.0689e+01],\n",
       "         [ 9.9757e-01, -2.7605e-02,  1.0850e+00,  6.9003e-02, -2.3886e+00,\n",
       "          -1.2879e+00,  9.6309e-02,  1.2918e-01,  5.0137e-02, -4.0323e-01],\n",
       "         [-4.7141e-03, -2.7604e-02,  1.5729e+00,  1.8706e-02,  1.2596e-02,\n",
       "          -4.9013e-02, -5.7360e-02,  2.1723e-01,  1.7898e-02, -1.0991e-02],\n",
       "         [ 3.0302e-01, -2.3770e-02,  7.4137e-01,  3.1165e-01,  1.0175e-01,\n",
       "           1.2295e-01,  1.0708e-01,  3.2930e-01, -6.2373e-03, -1.6861e-02],\n",
       "         [ 2.2968e-01, -1.9811e-02, -1.0209e-01,  9.5979e-01, -2.4107e+00,\n",
       "           5.8775e-03,  4.8815e-03,  1.1803e-03, -1.1140e-02,  4.5250e-02],\n",
       "         [-5.8078e-02, -6.2442e-02, -1.0482e-01,  6.7616e-01, -1.3984e-01,\n",
       "          -1.3176e-01,  5.0027e-02, -2.4633e-04, -3.6641e-02, -3.0356e-01],\n",
       "         [-1.2294e-03, -3.8539e-02,  6.6522e-01,  6.9205e-01, -1.1608e-01,\n",
       "           9.2340e-03, -2.0846e-03, -1.2601e-01, -3.6039e-02, -1.1515e+00],\n",
       "         [-1.2231e-03, -2.0057e-01,  5.9587e-01,  6.1188e-01, -2.7423e+00,\n",
       "           6.7075e-02,  6.5954e-02, -1.2784e-01, -1.1482e-01, -1.0206e+01],\n",
       "         [ 3.6738e-02,  4.7375e-02,  3.5482e-02, -1.3140e-01, -1.1109e-01,\n",
       "          -1.7550e-01, -1.2657e-01, -1.7662e-01,  3.3568e-02,  8.4589e-03]],\n",
       "\n",
       "        [[-5.9515e+00, -5.9357e+00, -5.9431e+00,  1.7718e-01,  1.5279e-01,\n",
       "           2.1855e-01, -3.0334e-01, -3.0333e-01, -1.0905e+01, -1.0914e+01],\n",
       "         [-5.9287e+00, -1.1839e-02, -1.1796e-02,  5.5133e-02,  1.1939e-01,\n",
       "           4.8410e-03, -4.8105e-02,  1.0978e-01,  5.0152e-02, -1.0809e+01],\n",
       "         [ 1.7254e+00, -2.7600e-02,  1.0947e+00,  7.7014e-02, -2.9670e+00,\n",
       "          -1.4560e+00,  9.6632e-02,  1.1985e-01,  4.9507e-02, -7.0176e-01],\n",
       "         [ 6.8490e-02, -2.7603e-02,  1.7226e+00,  1.9972e-02,  3.4949e-03,\n",
       "          -3.2448e-02, -4.8340e-02,  2.1702e-01,  3.5926e-02,  1.5611e-02],\n",
       "         [ 2.9719e-01,  3.9711e-03,  6.3061e-01,  2.7106e-01,  6.2226e-02,\n",
       "           1.2512e-01,  1.1211e-01,  3.2665e-01,  5.2777e-03,  8.8922e-03],\n",
       "         [ 2.5468e-01, -5.9908e-03, -1.0165e-01,  8.9565e-01, -2.6886e+00,\n",
       "           3.4303e-03,  1.2817e-02,  1.4516e-03, -1.0938e-02,  4.4082e-02],\n",
       "         [-5.3436e-02, -5.7659e-02, -1.0288e-01,  7.0610e-01, -1.3690e-01,\n",
       "          -1.2970e-01,  4.0864e-02, -1.9317e-02, -3.6625e-02, -6.9475e-01],\n",
       "         [-1.2419e-03, -3.7414e-02,  6.6516e-01,  7.1123e-01, -1.1993e-01,\n",
       "          -2.0624e-02, -9.8389e-04, -1.2699e-01, -3.5433e-02, -3.0355e+00],\n",
       "         [-1.2260e-03, -3.1176e-01,  6.0055e-01,  6.0835e-01, -2.7457e+00,\n",
       "           6.7076e-02,  5.9677e-02, -1.2782e-01, -1.0743e-01, -1.0196e+01],\n",
       "         [ 3.7232e-02,  4.4763e-02,  1.7896e-02, -1.9570e-01, -1.2242e-01,\n",
       "          -1.7532e-01, -1.2952e-01, -1.7646e-01,  1.3777e-01,  8.4567e-03]],\n",
       "\n",
       "        [[-5.9510e+00, -5.9353e+00, -5.9427e+00,  1.0186e-01,  1.0382e-01,\n",
       "           2.0452e-01, -3.0335e-01, -3.0334e-01, -1.0907e+01, -1.0914e+01],\n",
       "         [-5.9279e+00, -1.1861e-02, -1.1805e-02,  5.5132e-02,  1.5413e-01,\n",
       "          -1.4928e-02, -4.8801e-02,  9.8292e-02,  4.9187e-02, -1.0893e+01],\n",
       "         [-8.8028e-01, -2.7551e-02,  1.0648e+00,  1.0486e-01, -3.0664e+00,\n",
       "          -1.5222e+00,  9.6457e-02,  1.2217e-01,  4.8966e-02, -2.1794e+00],\n",
       "         [ 4.4577e-01, -2.7593e-02,  1.6265e+00,  2.4414e-02, -3.1259e-02,\n",
       "           3.5887e-03, -3.1489e-02,  2.1649e-01,  6.9568e-02,  1.0774e-01],\n",
       "         [ 2.8857e-01,  1.2206e-01,  5.1557e-01,  2.3601e-01,  2.1888e-02,\n",
       "           1.2949e-01,  1.1378e-01,  3.1401e-01,  5.4098e-02,  8.8358e-02],\n",
       "         [ 3.0307e-01,  2.0142e-02, -1.0116e-01,  8.2159e-01, -3.1526e+00,\n",
       "          -6.5065e-04,  1.2742e-02,  1.2962e-02, -9.8426e-03,  4.1482e-02],\n",
       "         [-4.1595e-02, -5.1872e-02, -1.0061e-01,  7.4360e-01, -1.3581e-01,\n",
       "          -1.2893e-01,  2.3232e-02, -2.8722e-02, -3.6595e-02, -2.0118e+00],\n",
       "         [-1.2978e-03, -6.3440e-02,  6.6515e-01,  7.2954e-01, -1.2157e-01,\n",
       "          -5.8299e-02,  2.3624e-02, -1.2743e-01, -3.4217e-02, -6.5129e+00],\n",
       "         [-1.2395e-03, -3.1042e-01,  6.0438e-01,  6.0710e-01, -2.7551e+00,\n",
       "           6.7073e-02,  4.9134e-02, -1.2776e-01, -8.6794e-02, -1.0185e+01],\n",
       "         [ 3.2245e-02,  3.7303e-02, -2.7107e-02, -2.3904e-01, -1.4513e-01,\n",
       "          -1.7486e-01, -1.2907e-01, -1.7612e-01,  3.1703e-01,  8.4364e-03]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].z, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.4487e-02,  1.9524e-02],\n",
       "          [ 2.4581e-02,  2.0270e-02],\n",
       "          [ 2.5216e-02,  2.0176e-02],\n",
       "          ...,\n",
       "          [ 6.2065e-03,  2.0290e-04],\n",
       "          [ 1.3135e-04, -5.0665e-02],\n",
       "          [ 2.5041e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4566e-02,  2.0481e-02],\n",
       "          [ 2.5786e-03,  3.4104e-04],\n",
       "          [ 2.5816e-03,  3.4120e-04],\n",
       "          ...,\n",
       "          [ 3.5544e-04,  7.6993e-04],\n",
       "          [ 5.8027e-04,  2.7309e-05],\n",
       "          [ 4.2069e-04, -5.0517e-02]],\n",
       "\n",
       "         [[ 2.0405e-03, -1.8178e-02],\n",
       "          [ 2.7553e-06,  4.8930e-04],\n",
       "          [-4.1595e-03,  3.8986e-03],\n",
       "          ...,\n",
       "          [ 1.0384e-04,  9.0201e-04],\n",
       "          [ 6.3191e-04,  7.1843e-04],\n",
       "          [ 3.1858e-03, -5.9112e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0833e-05,  7.9475e-04],\n",
       "          [ 1.3359e-03,  2.0778e-03],\n",
       "          [ 1.4737e-03,  6.7747e-04],\n",
       "          ...,\n",
       "          [ 1.2737e-03,  1.4499e-03],\n",
       "          [-1.1803e-05,  1.5059e-03],\n",
       "          [-9.9872e-04, -2.0377e-02]],\n",
       "\n",
       "         [[ 3.0834e-05,  7.9476e-04],\n",
       "          [ 4.0169e-04,  3.5014e-04],\n",
       "          [ 8.4752e-04,  7.0888e-04],\n",
       "          ...,\n",
       "          [ 1.5902e-03,  1.5062e-03],\n",
       "          [ 3.8432e-03,  3.9067e-03],\n",
       "          [-4.1437e-03, -5.0198e-02]],\n",
       "\n",
       "         [[ 2.3031e-03,  2.3163e-04],\n",
       "          [ 2.3846e-03,  1.0654e-05],\n",
       "          [ 2.3772e-03,  3.5121e-06],\n",
       "          ...,\n",
       "          [ 2.0787e-03, -7.0890e-05],\n",
       "          [ 4.1252e-02, -1.3166e-02],\n",
       "          [ 5.6364e-04,  1.8124e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4457e-02,  1.9547e-02],\n",
       "          [ 2.4518e-02,  2.0297e-02],\n",
       "          [ 2.5338e-02,  2.0122e-02],\n",
       "          ...,\n",
       "          [ 6.2058e-03,  2.0375e-04],\n",
       "          [ 1.1813e-04, -5.0666e-02],\n",
       "          [ 2.5041e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4597e-02,  2.0493e-02],\n",
       "          [ 2.5786e-03,  3.4082e-04],\n",
       "          [ 2.5823e-03,  3.4106e-04],\n",
       "          ...,\n",
       "          [ 2.9295e-04,  7.5659e-04],\n",
       "          [ 5.0408e-04,  6.0823e-05],\n",
       "          [ 8.5895e-04, -4.9602e-02]],\n",
       "\n",
       "         [[ 1.5153e-03, -1.4695e-02],\n",
       "          [ 2.7496e-06,  4.8932e-04],\n",
       "          [-4.5409e-03,  4.1145e-03],\n",
       "          ...,\n",
       "          [ 4.3620e-04,  8.4202e-04],\n",
       "          [ 4.8374e-04,  2.7192e-04],\n",
       "          [ 5.9080e-05, -1.2094e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0904e-05,  7.9475e-04],\n",
       "          [ 1.0717e-03,  1.4534e-03],\n",
       "          [ 1.4664e-03,  6.7360e-04],\n",
       "          ...,\n",
       "          [ 1.4609e-03,  1.4954e-03],\n",
       "          [-1.2504e-05,  1.5023e-03],\n",
       "          [-1.0842e-03, -2.2072e-02]],\n",
       "\n",
       "         [[ 3.0905e-05,  7.9488e-04],\n",
       "          [-2.3026e-05,  3.5873e-04],\n",
       "          [ 7.4518e-04,  7.1625e-04],\n",
       "          ...,\n",
       "          [ 1.5905e-03,  1.5058e-03],\n",
       "          [ 2.5488e-03,  2.5395e-03],\n",
       "          [-4.1797e-03, -5.0174e-02]],\n",
       "\n",
       "         [[ 2.3080e-03,  2.2494e-04],\n",
       "          [ 2.3815e-03,  1.0526e-05],\n",
       "          [ 2.3582e-03,  1.7601e-06],\n",
       "          ...,\n",
       "          [ 2.0586e-03, -6.5141e-05],\n",
       "          [ 2.9100e-02, -9.2546e-03],\n",
       "          [ 5.6333e-04,  1.8094e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4458e-02,  1.9568e-02],\n",
       "          [ 2.4613e-02,  2.0334e-02],\n",
       "          [ 2.5261e-02,  2.0161e-02],\n",
       "          ...,\n",
       "          [ 6.2058e-03,  2.0273e-04],\n",
       "          [ 1.1748e-04, -5.0829e-02],\n",
       "          [ 2.5041e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4565e-02,  2.0483e-02],\n",
       "          [ 2.5776e-03,  3.4081e-04],\n",
       "          [ 2.5820e-03,  3.4101e-04],\n",
       "          ...,\n",
       "          [ 2.3572e-04,  7.4079e-04],\n",
       "          [ 4.9424e-04,  6.6117e-05],\n",
       "          [ 1.2999e-03, -4.8108e-02]],\n",
       "\n",
       "         [[ 1.7852e-03, -1.8144e-02],\n",
       "          [ 2.7521e-06,  4.8897e-04],\n",
       "          [-4.8954e-03,  4.3132e-03],\n",
       "          ...,\n",
       "          [ 6.8888e-04,  6.8120e-04],\n",
       "          [ 4.6029e-04,  1.2685e-04],\n",
       "          [-1.6094e-04, -4.8943e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0832e-05,  7.9465e-04],\n",
       "          [ 9.4570e-04,  1.1929e-03],\n",
       "          [ 1.4739e-03,  6.7490e-04],\n",
       "          ...,\n",
       "          [ 1.5453e-03,  1.5056e-03],\n",
       "          [-1.2863e-05,  1.4952e-03],\n",
       "          [-1.4205e-03, -2.9275e-02]],\n",
       "\n",
       "         [[ 3.0799e-05,  7.9492e-04],\n",
       "          [-9.9298e-04,  4.5181e-04],\n",
       "          [ 7.5691e-04,  7.1780e-04],\n",
       "          ...,\n",
       "          [ 1.5873e-03,  1.5066e-03],\n",
       "          [ 2.1237e-03,  2.1005e-03],\n",
       "          [-4.2082e-03, -5.0303e-02]],\n",
       "\n",
       "         [[ 2.3321e-03,  1.9094e-04],\n",
       "          [ 2.3694e-03,  1.0259e-05],\n",
       "          [ 2.3196e-03, -2.1601e-06],\n",
       "          ...,\n",
       "          [ 2.0526e-03, -6.2894e-05],\n",
       "          [ 2.1738e-02, -7.0804e-03],\n",
       "          [ 5.6366e-04,  1.8062e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4427e-02,  1.9576e-02],\n",
       "          [ 2.4550e-02,  2.0326e-02],\n",
       "          [ 2.4952e-02,  2.0220e-02],\n",
       "          ...,\n",
       "          [ 6.2052e-03,  2.0340e-04],\n",
       "          [ 1.2635e-04, -5.0829e-02],\n",
       "          [ 2.5040e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4629e-02,  2.0496e-02],\n",
       "          [ 2.5807e-03,  3.4123e-04],\n",
       "          [ 2.5815e-03,  3.4065e-04],\n",
       "          ...,\n",
       "          [ 1.7438e-04,  6.8558e-04],\n",
       "          [ 4.9274e-04,  6.7178e-05],\n",
       "          [ 1.1568e-03, -4.7301e-02]],\n",
       "\n",
       "         [[ 3.2641e-03, -3.2339e-02],\n",
       "          [ 2.7684e-06,  4.8889e-04],\n",
       "          [-5.1014e-03,  4.4312e-03],\n",
       "          ...,\n",
       "          [ 6.5774e-04,  4.8464e-04],\n",
       "          [ 4.6804e-04,  9.2360e-05],\n",
       "          [-3.1536e-04, -3.9718e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0831e-05,  7.9453e-04],\n",
       "          [ 8.9821e-04,  1.0620e-03],\n",
       "          [ 1.4758e-03,  6.7476e-04],\n",
       "          ...,\n",
       "          [ 1.5743e-03,  1.5084e-03],\n",
       "          [-1.2767e-05,  1.4823e-03],\n",
       "          [-2.0802e-03, -4.3663e-02]],\n",
       "\n",
       "         [[ 3.0763e-05,  7.9483e-04],\n",
       "          [-2.8655e-03,  6.8785e-04],\n",
       "          [ 8.8196e-04,  7.0903e-04],\n",
       "          ...,\n",
       "          [ 1.5873e-03,  1.5030e-03],\n",
       "          [ 1.9846e-03,  1.9718e-03],\n",
       "          [-4.2944e-03, -5.0313e-02]],\n",
       "\n",
       "         [[ 2.3321e-03,  1.4256e-04],\n",
       "          [ 2.3508e-03,  9.7217e-06],\n",
       "          [ 2.2168e-03, -1.0467e-05],\n",
       "          ...,\n",
       "          [ 2.0389e-03, -6.3129e-05],\n",
       "          [ 1.8112e-02, -6.1647e-03],\n",
       "          [ 5.6299e-04,  1.8078e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4396e-02,  1.9559e-02],\n",
       "          [ 2.4582e-02,  2.0329e-02],\n",
       "          [ 2.4672e-02,  2.0304e-02],\n",
       "          ...,\n",
       "          [ 6.2071e-03,  2.0287e-04],\n",
       "          [ 1.4551e-04, -5.0706e-02],\n",
       "          [ 2.5041e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4598e-02,  2.0487e-02],\n",
       "          [ 2.5781e-03,  3.4049e-04],\n",
       "          [ 2.5800e-03,  3.4076e-04],\n",
       "          ...,\n",
       "          [ 1.4430e-04,  5.9944e-04],\n",
       "          [ 4.9291e-04,  6.5379e-05],\n",
       "          [ 6.5529e-04, -4.8490e-02]],\n",
       "\n",
       "         [[ 8.0815e-03, -6.0335e-02],\n",
       "          [ 2.8346e-06,  4.8860e-04],\n",
       "          [-4.9694e-03,  4.3551e-03],\n",
       "          ...,\n",
       "          [ 5.5218e-04,  3.7035e-04],\n",
       "          [ 4.7245e-04,  8.3030e-05],\n",
       "          [-1.0284e-03, -6.6269e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0935e-05,  7.9426e-04],\n",
       "          [ 9.0818e-04,  9.3213e-04],\n",
       "          [ 1.4741e-03,  6.7360e-04],\n",
       "          ...,\n",
       "          [ 1.5850e-03,  1.5066e-03],\n",
       "          [-1.0065e-05,  1.4568e-03],\n",
       "          [-2.8715e-03, -6.0376e-02]],\n",
       "\n",
       "         [[ 3.0799e-05,  7.9475e-04],\n",
       "          [-5.6371e-03,  1.2150e-03],\n",
       "          [ 1.0518e-03,  6.9771e-04],\n",
       "          ...,\n",
       "          [ 1.5873e-03,  1.5047e-03],\n",
       "          [ 1.9649e-03,  1.9933e-03],\n",
       "          [-4.3351e-03, -5.0448e-02]],\n",
       "\n",
       "         [[ 2.2864e-03,  9.5830e-05],\n",
       "          [ 2.3074e-03,  8.4770e-06],\n",
       "          [ 1.9764e-03, -2.8302e-05],\n",
       "          ...,\n",
       "          [ 2.0469e-03, -6.5154e-05],\n",
       "          [ 1.6966e-02, -6.2017e-03],\n",
       "          [ 5.6397e-04,  1.8089e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4396e-02,  1.9563e-02],\n",
       "          [ 2.4551e-02,  2.0342e-02],\n",
       "          [ 2.4515e-02,  2.0338e-02],\n",
       "          ...,\n",
       "          [ 6.2065e-03,  2.0218e-04],\n",
       "          [ 1.6898e-04, -5.0706e-02],\n",
       "          [ 2.5040e-04, -5.0787e-02]],\n",
       "\n",
       "         [[ 2.4630e-02,  2.0512e-02],\n",
       "          [ 2.5796e-03,  3.4013e-04],\n",
       "          [ 2.5789e-03,  3.4137e-04],\n",
       "          ...,\n",
       "          [ 1.8967e-04,  4.8500e-04],\n",
       "          [ 4.9655e-04,  5.5322e-05],\n",
       "          [ 3.4684e-04, -4.9963e-02]],\n",
       "\n",
       "         [[ 1.7470e-02, -4.2496e-02],\n",
       "          [ 3.2199e-06,  4.8539e-04],\n",
       "          [-4.3001e-03,  3.9386e-03],\n",
       "          ...,\n",
       "          [ 4.3743e-04,  3.3617e-04],\n",
       "          [ 4.7181e-04,  8.1416e-05],\n",
       "          [-4.0335e-03, -2.1195e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.1396e-05,  7.9229e-04],\n",
       "          [ 9.8767e-04,  7.0956e-04],\n",
       "          [ 1.4705e-03,  6.7637e-04],\n",
       "          ...,\n",
       "          [ 1.5913e-03,  1.5072e-03],\n",
       "          [-1.7740e-06,  1.4052e-03],\n",
       "          [-3.0814e-03, -6.3334e-02]],\n",
       "\n",
       "         [[ 3.0834e-05,  7.9450e-04],\n",
       "          [-6.7748e-03,  2.2498e-03],\n",
       "          [ 1.1846e-03,  6.9150e-04],\n",
       "          ...,\n",
       "          [ 1.5894e-03,  1.5045e-03],\n",
       "          [ 2.0409e-03,  2.2147e-03],\n",
       "          [-4.4227e-03, -5.0499e-02]],\n",
       "\n",
       "         [[ 2.0761e-03,  6.6067e-05],\n",
       "          [ 2.1502e-03,  5.4862e-06],\n",
       "          [ 1.3046e-03, -6.5122e-05],\n",
       "          ...,\n",
       "          [ 2.0398e-03, -6.7924e-05],\n",
       "          [ 1.8152e-02, -7.0855e-03],\n",
       "          [ 5.6241e-04,  1.8052e-04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].xy_span, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.7690e-06,  2.9478e-04],\n",
       "          [ 1.2625e-05,  5.8200e-04],\n",
       "          [ 3.0870e-05,  7.6201e-04],\n",
       "          ...,\n",
       "          [-1.8396e+02,  3.3434e+01],\n",
       "          [ 1.6789e-03, -1.4900e-02],\n",
       "          [ 4.3383e-02,  4.9127e-01]],\n",
       "\n",
       "         [[ 2.8519e-05,  1.2633e-03],\n",
       "          [-1.0259e+02, -7.3275e+02],\n",
       "          [-2.1281e+04, -1.3405e+04],\n",
       "          ...,\n",
       "          [-2.3014e+02,  9.1666e+01],\n",
       "          [ 1.4750e+02, -5.3414e+01],\n",
       "          [ 5.4040e-02,  5.2744e-01]],\n",
       "\n",
       "         [[-4.8327e-03, -5.2142e-02],\n",
       "          [-1.1189e+03, -8.9470e+03],\n",
       "          [-5.0777e-01,  3.1053e-01],\n",
       "          ...,\n",
       "          [-1.6174e+04,  3.0767e+04],\n",
       "          [ 3.5371e+04,  2.5503e+04],\n",
       "          [ 8.4016e-01,  4.5734e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2560e+04, -5.3135e+04],\n",
       "          [-2.2019e-01, -1.4267e-02],\n",
       "          [ 1.2299e+02, -1.5941e+02],\n",
       "          ...,\n",
       "          [-8.0105e+03, -1.1956e+04],\n",
       "          [ 1.1123e+04,  6.1592e+04],\n",
       "          [ 5.7689e-01,  7.7937e+00]],\n",
       "\n",
       "         [[ 9.4936e+04, -1.2096e+05],\n",
       "          [ 6.3080e+00, -7.2979e-01],\n",
       "          [ 3.2303e+01, -4.0782e+01],\n",
       "          ...,\n",
       "          [-7.4856e+03, -8.1465e+03],\n",
       "          [-1.8573e+01, -2.6576e+01],\n",
       "          [ 7.9225e-03, -6.4733e-02]],\n",
       "\n",
       "         [[ 2.3738e+02, -1.2393e+01],\n",
       "          [ 1.3163e+04, -2.7452e+03],\n",
       "          [ 1.1677e+04, -4.7461e+03],\n",
       "          ...,\n",
       "          [-2.7897e+02,  9.9425e+01],\n",
       "          [-7.0975e-01,  3.3995e-02],\n",
       "          [-1.4067e+05, -9.5050e+04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9384e-06,  2.9496e-04],\n",
       "          [ 1.3062e-05,  5.8242e-04],\n",
       "          [ 3.2659e-05,  7.6154e-04],\n",
       "          ...,\n",
       "          [-2.3376e+02,  4.2805e+01],\n",
       "          [ 1.7740e-03, -1.3106e-02],\n",
       "          [ 4.5131e-02,  5.2468e-01]],\n",
       "\n",
       "         [[ 2.8976e-05,  1.2640e-03],\n",
       "          [-2.0418e+02, -6.8547e+02],\n",
       "          [-2.4394e+04, -1.1948e+04],\n",
       "          ...,\n",
       "          [-4.4995e+02,  3.1876e+02],\n",
       "          [ 5.6316e+02, -2.1152e+02],\n",
       "          [ 6.3797e-02,  5.6433e-01]],\n",
       "\n",
       "         [[-7.4464e-03, -7.9439e-02],\n",
       "          [-1.8164e+03, -1.4645e+04],\n",
       "          [-5.5887e-01,  3.3454e-01],\n",
       "          ...,\n",
       "          [-2.9116e+02,  2.5036e+04],\n",
       "          [ 1.7590e+04,  6.6707e+04],\n",
       "          [-1.8997e+00,  2.1676e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1855e+04, -7.2254e+04],\n",
       "          [-4.2151e-01, -7.3739e-01],\n",
       "          [ 1.2967e+02, -1.7746e+02],\n",
       "          ...,\n",
       "          [ 1.4989e+03,  1.6364e+03],\n",
       "          [ 1.1715e+04,  7.3695e+04],\n",
       "          [ 6.0354e-01,  8.2172e+00]],\n",
       "\n",
       "         [[ 9.8959e+04, -1.8342e+05],\n",
       "          [ 6.9383e+00, -6.9372e-01],\n",
       "          [ 3.4387e+01, -4.5001e+01],\n",
       "          ...,\n",
       "          [-1.2307e+04, -1.2503e+04],\n",
       "          [-3.5314e+01, -5.0802e+01],\n",
       "          [ 8.3243e-03, -5.2817e-02]],\n",
       "\n",
       "         [[ 2.6101e+02, -1.2024e+01],\n",
       "          [ 1.5003e+04, -2.6328e+03],\n",
       "          [ 1.4349e+04, -4.5917e+03],\n",
       "          ...,\n",
       "          [-3.4341e+02,  1.6305e+02],\n",
       "          [-1.1143e+00,  6.4414e-02],\n",
       "          [-6.0636e+04,  8.1439e+04]]],\n",
       "\n",
       "\n",
       "        [[[ 3.1194e-06,  2.9491e-04],\n",
       "          [ 1.3394e-05,  5.8152e-04],\n",
       "          [ 3.3056e-05,  7.5963e-04],\n",
       "          ...,\n",
       "          [-2.6162e+02,  4.7805e+01],\n",
       "          [ 1.8729e-03, -1.1170e-02],\n",
       "          [ 4.6533e-02,  5.5525e-01]],\n",
       "\n",
       "         [[ 3.0467e-05,  1.2602e-03],\n",
       "          [-2.5742e+02, -5.4546e+02],\n",
       "          [-2.3728e+04, -8.8331e+03],\n",
       "          ...,\n",
       "          [-7.0856e+02,  5.5161e+02],\n",
       "          [ 1.0691e+03, -4.2232e+02],\n",
       "          [ 7.3913e-02,  5.9612e-01]],\n",
       "\n",
       "         [[-6.7460e-03, -7.0425e-02],\n",
       "          [-1.7219e+03, -1.4010e+04],\n",
       "          [-5.3048e-01,  3.1119e-01],\n",
       "          ...,\n",
       "          [ 1.8339e+04,  1.5503e+04],\n",
       "          [-4.6365e+05,  2.8185e+05],\n",
       "          [-1.6927e+01,  8.5184e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.9875e+03, -6.3895e+04],\n",
       "          [-6.2756e-01, -1.6935e+00],\n",
       "          [ 1.3354e+02, -1.9098e+02],\n",
       "          ...,\n",
       "          [ 3.0099e+04,  3.7427e+04],\n",
       "          [ 9.0493e+03,  6.3210e+04],\n",
       "          [ 4.7380e-01,  6.4348e+00]],\n",
       "\n",
       "         [[ 6.8126e+04, -1.7326e+05],\n",
       "          [ 5.9569e+00, -5.3453e-01],\n",
       "          [ 3.3997e+01, -4.7854e+01],\n",
       "          ...,\n",
       "          [-1.3736e+04, -1.2782e+04],\n",
       "          [-4.8607e+01, -7.1191e+01],\n",
       "          [ 8.5897e-03, -3.9900e-02]],\n",
       "\n",
       "         [[ 2.2611e+02, -1.0651e+01],\n",
       "          [ 1.3418e+04, -2.0059e+03],\n",
       "          [ 1.3519e+04, -3.5375e+03],\n",
       "          ...,\n",
       "          [-3.3603e+02,  2.2155e+02],\n",
       "          [-1.4757e+00,  9.1673e-02],\n",
       "          [ 7.7961e+05,  7.9132e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3396e-06,  2.9411e-04],\n",
       "          [ 1.3904e-05,  5.7949e-04],\n",
       "          [ 3.1881e-05,  7.5597e-04],\n",
       "          ...,\n",
       "          [-2.5823e+02,  4.6867e+01],\n",
       "          [ 1.9657e-03, -9.1054e-03],\n",
       "          [ 4.7633e-02,  5.8210e-01]],\n",
       "\n",
       "         [[ 3.1613e-05,  1.2568e-03],\n",
       "          [-2.4832e+02, -3.6637e+02],\n",
       "          [-1.9687e+04, -5.2768e+03],\n",
       "          ...,\n",
       "          [-9.3020e+02,  6.6315e+02],\n",
       "          [ 1.0205e+03, -4.2886e+02],\n",
       "          [ 7.2847e-02,  6.2807e-01]],\n",
       "\n",
       "         [[-3.5730e-03, -3.6006e-02],\n",
       "          [-9.6202e+02, -7.9245e+03],\n",
       "          [-4.3565e-01,  2.4692e-01],\n",
       "          ...,\n",
       "          [ 1.7732e+04,  1.0732e+04],\n",
       "          [-1.1301e+06,  5.1735e+05],\n",
       "          [-3.3695e+01,  1.4647e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3777e+03, -3.7130e+04],\n",
       "          [-7.3720e-01, -2.6046e+00],\n",
       "          [ 1.3432e+02, -1.9943e+02],\n",
       "          ...,\n",
       "          [ 6.4494e+04,  7.6001e+04],\n",
       "          [ 5.1015e+03,  3.9508e+04],\n",
       "          [ 2.7605e-01,  3.7710e+00]],\n",
       "\n",
       "         [[ 3.0724e+04, -1.0515e+05],\n",
       "          [ 3.9313e+00, -3.4535e-01],\n",
       "          [ 3.1605e+01, -4.9378e+01],\n",
       "          ...,\n",
       "          [-9.8107e+03, -8.1156e+03],\n",
       "          [-4.8494e+01, -7.3382e+01],\n",
       "          [ 8.7083e-03, -2.6594e-02]],\n",
       "\n",
       "         [[ 1.5331e+02, -7.6898e+00],\n",
       "          [ 9.3987e+03, -1.2138e+03],\n",
       "          [ 9.9177e+03, -2.1732e+03],\n",
       "          ...,\n",
       "          [-2.6385e+02,  2.4780e+02],\n",
       "          [-1.6310e+00,  1.0321e-01],\n",
       "          [ 1.3011e+06,  9.9244e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.5123e-06,  2.9316e-04],\n",
       "          [ 1.4476e-05,  5.7687e-04],\n",
       "          [ 3.1405e-05,  7.5170e-04],\n",
       "          ...,\n",
       "          [-2.2511e+02,  4.0656e+01],\n",
       "          [ 2.0565e-03, -7.1180e-03],\n",
       "          [ 4.8385e-02,  6.0436e-01]],\n",
       "\n",
       "         [[ 3.2866e-05,  1.2512e-03],\n",
       "          [-1.9498e+02, -2.0533e+02],\n",
       "          [-1.3984e+04, -2.3886e+03],\n",
       "          ...,\n",
       "          [-9.9471e+02,  6.0521e+02],\n",
       "          [ 5.0093e+02, -2.2533e+02],\n",
       "          [ 6.4380e-02,  6.5900e-01]],\n",
       "\n",
       "         [[-1.0371e-03, -9.0334e-03],\n",
       "          [-3.1984e+02, -2.6676e+03],\n",
       "          [-3.0978e-01,  1.6505e-01],\n",
       "          ...,\n",
       "          [ 5.6098e+03,  7.7640e+03],\n",
       "          [-9.8973e+05,  4.1589e+05],\n",
       "          [-2.7479e+01,  1.1586e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4735e+02, -1.4264e+04],\n",
       "          [-6.8003e-01, -3.1513e+00],\n",
       "          [ 1.3202e+02, -2.0227e+02],\n",
       "          ...,\n",
       "          [ 7.7641e+04,  8.6590e+04],\n",
       "          [ 2.1286e+03,  1.8074e+04],\n",
       "          [ 1.2566e-01,  1.6731e+00]],\n",
       "\n",
       "         [[ 8.9237e+03, -4.1614e+04],\n",
       "          [ 1.9008e+00, -2.0239e-01],\n",
       "          [ 2.8340e+01, -4.9556e+01],\n",
       "          ...,\n",
       "          [-3.5628e+03, -2.2361e+03],\n",
       "          [-3.5005e+01, -5.5481e+01],\n",
       "          [ 8.7581e-03, -1.4294e-02]],\n",
       "\n",
       "         [[ 8.2673e+01, -4.1647e+00],\n",
       "          [ 5.2108e+03, -5.8282e+02],\n",
       "          [ 5.7241e+03, -1.0703e+03],\n",
       "          ...,\n",
       "          [-1.6407e+02,  2.2899e+02],\n",
       "          [-1.5358e+00,  8.8735e-02],\n",
       "          [ 6.8844e+05,  4.2265e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.7792e-06,  2.9138e-04],\n",
       "          [ 1.4763e-05,  5.7314e-04],\n",
       "          [ 3.1831e-05,  7.4546e-04],\n",
       "          ...,\n",
       "          [-1.7359e+02,  3.1100e+01],\n",
       "          [ 2.1354e-03, -5.0755e-03],\n",
       "          [ 4.8763e-02,  6.2278e-01]],\n",
       "\n",
       "         [[ 3.3878e-05,  1.2395e-03],\n",
       "          [-1.2723e+02, -9.3820e+01],\n",
       "          [-8.5338e+03, -6.4633e+02],\n",
       "          ...,\n",
       "          [-8.2631e+02,  4.2923e+02],\n",
       "          [ 1.3261e+02, -6.4037e+01],\n",
       "          [ 5.9283e-02,  6.8429e-01]],\n",
       "\n",
       "         [[-5.5213e-05,  1.3094e-03],\n",
       "          [-6.3134e+01, -5.3529e+02],\n",
       "          [-1.9426e-01,  8.9827e-02],\n",
       "          ...,\n",
       "          [ 2.4055e+01,  3.8853e+03],\n",
       "          [-3.7848e+05,  1.5311e+05],\n",
       "          [-1.0156e+01,  4.6558e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.5063e+01, -3.6353e+03],\n",
       "          [-4.9575e-01, -3.1580e+00],\n",
       "          [ 1.2682e+02, -1.9872e+02],\n",
       "          ...,\n",
       "          [ 6.1168e+04,  6.4197e+04],\n",
       "          [ 6.5144e+02,  6.0786e+03],\n",
       "          [ 5.0918e-02,  5.9891e-01]],\n",
       "\n",
       "         [[ 1.6277e+03, -1.0828e+04],\n",
       "          [ 5.2570e-01, -1.2531e-01],\n",
       "          [ 2.5182e+01, -4.8481e+01],\n",
       "          ...,\n",
       "          [ 4.9063e+02,  8.8024e+02],\n",
       "          [-1.8235e+01, -3.1224e+01],\n",
       "          [ 8.6282e-03, -1.9026e-03]],\n",
       "\n",
       "         [[ 3.5292e+01, -1.6679e+00],\n",
       "          [ 2.2772e+03, -2.2242e+02],\n",
       "          [ 2.6231e+03, -4.3046e+02],\n",
       "          ...,\n",
       "          [-9.3672e+01,  1.7237e+02],\n",
       "          [-1.2259e+00,  5.7929e-02],\n",
       "          [ 1.4106e+05,  6.8010e+04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].xy, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.5929e-03, -1.9439e-02, -2.5148e-02,  2.9689e+01, -1.2987e+05,\n",
       "          -2.8933e+05,  1.1755e+04, -4.8269e+03,  3.3611e+00, -1.7513e+01],\n",
       "         [-4.6210e-02,  2.4601e+04,  4.4352e+04, -4.6145e+06,  4.4776e+05,\n",
       "           1.7772e+04,  1.7153e+06, -1.0875e+04, -1.2746e+04, -1.1271e+01],\n",
       "         [-4.2359e+00, -4.1039e+05, -1.5054e+01,  1.1609e+03,  7.2113e+02,\n",
       "           8.5706e+02, -1.9199e+05, -9.8811e+05, -8.3486e+06,  1.3348e+02],\n",
       "         [-2.7597e+02,  1.3785e+07, -3.2767e+03, -4.1206e+06,  7.7053e+06,\n",
       "          -2.8513e+05,  9.4396e+05, -2.7273e+06, -3.4591e+05,  6.3457e+06],\n",
       "         [-2.9543e+01,  3.7607e+06,  8.4513e+02,  2.4682e+04, -4.9731e+04,\n",
       "          -7.9421e+05, -1.6371e+06,  1.0038e+03,  3.8161e+05,  4.0798e+06],\n",
       "         [-2.5515e+03,  1.4116e+05,  1.5623e+05, -9.3903e+02,  2.2606e+04,\n",
       "          -2.2185e+06, -3.1641e+07, -1.3682e+07,  4.2782e+05, -1.2824e+06],\n",
       "         [-2.7264e+03,  3.1825e+06,  5.2365e+05, -3.0224e+03,  3.5915e+05,\n",
       "           2.2643e+06, -1.7545e+07, -1.3051e+06,  1.3003e+06, -7.9899e+02],\n",
       "         [-4.4279e+05,  9.7958e+01,  1.3311e+03, -2.8405e+03,  1.5438e+03,\n",
       "          -7.4630e+05,  6.1733e+07,  7.2416e+05, -1.1366e+06, -1.8504e+02],\n",
       "         [ 1.4773e+06, -8.6488e+01,  3.2139e+02,  5.6329e+01,  7.4593e+03,\n",
       "          -1.2307e+06,  4.3435e+03,  3.0449e+05,  6.8911e+02,  2.8955e+01],\n",
       "         [-7.2813e+02, -3.0157e+04,  4.4575e+04,  1.8790e+04,  1.0051e+04,\n",
       "           7.6874e+03,  2.2029e+05,  2.4343e+04,  3.5892e+01, -3.3908e+06]],\n",
       "\n",
       "        [[-9.5849e-03, -1.9399e-02, -2.5062e-02,  3.2972e+01,  4.9168e+04,\n",
       "          -2.1246e+05, -9.7530e+03, -6.4575e+03,  3.1963e+00, -2.0434e+01],\n",
       "         [-4.6130e-02,  2.0814e+04, -7.2928e+04, -1.9910e+06,  9.6586e+05,\n",
       "           1.2266e+05,  3.7235e+06, -1.8658e+04, -5.3971e+04, -1.4699e+01],\n",
       "         [-6.2439e+00, -7.4698e+05, -1.7712e+01,  2.8574e+03,  3.8098e+02,\n",
       "           9.1113e+02, -1.7287e+05, -2.6893e+06, -2.6407e+07,  9.8996e+02],\n",
       "         [-4.3051e+02, -4.1446e+05, -3.5959e+03, -1.0887e+07,  4.3750e+06,\n",
       "          -1.6966e+05,  2.1859e+06, -3.3352e+06, -2.6763e+06,  7.8599e+06],\n",
       "         [-1.7412e+01,  3.9341e+06,  1.0319e+03,  3.4954e+04, -2.1872e+04,\n",
       "          -1.0920e+06, -1.5016e+06,  9.6677e+02,  6.0198e+05,  1.0126e+07],\n",
       "         [-6.4141e+03, -3.5966e+05,  2.5905e+05, -9.7556e+02,  2.1564e+04,\n",
       "          -1.6753e+07, -1.1667e+08, -2.7003e+08,  7.0343e+05, -6.8387e+05],\n",
       "         [-7.8160e+03,  5.0233e+06,  9.4669e+05, -3.4086e+03,  7.0746e+05,\n",
       "           5.6648e+06, -2.5589e+07, -6.5739e+06, -5.9521e+05, -9.0081e+02],\n",
       "         [-7.8639e+05,  1.6551e+02,  1.6533e+03, -2.7834e+03, -1.5269e+05,\n",
       "          -1.1698e+05,  2.0305e+08,  8.3876e+05, -1.5315e+06, -1.9984e+02],\n",
       "         [ 6.0148e+05, -1.0270e+02,  2.6470e+02,  4.8841e+00,  8.6558e+03,\n",
       "          -1.8535e+06,  5.0216e+03,  5.3464e+05,  1.3260e+03,  2.8096e+01],\n",
       "         [-8.9439e+02, -4.4041e+04,  2.3792e+04,  1.8929e+04,  1.1313e+04,\n",
       "          -1.7685e+04,  2.9375e+05,  3.6196e+04,  5.3534e+01, -7.6651e+06]],\n",
       "\n",
       "        [[-9.5575e-03, -1.9318e-02, -2.4912e-02,  2.9861e+01,  1.8094e+05,\n",
       "          -1.1421e+05, -3.4038e+04, -7.5452e+03,  3.0035e+00, -2.3310e+01],\n",
       "         [-4.5953e-02,  1.4751e+04, -1.6760e+05,  2.4710e+06,  1.2339e+06,\n",
       "           2.4160e+05,  5.2988e+06, -3.5309e+04, -1.1230e+05, -1.7789e+01],\n",
       "         [-5.6473e+00, -7.7626e+05, -1.7432e+01,  3.6367e+03, -5.5795e+02,\n",
       "           8.5728e+02, -7.9671e+04, -4.5428e+06, -2.9310e+07,  3.3159e+03],\n",
       "         [-4.0252e+02, -1.6476e+07, -2.8868e+03, -1.2711e+07,  9.8553e+05,\n",
       "          -6.1542e+04,  2.2262e+06, -1.4413e+06, -6.3079e+06, -6.9939e+06],\n",
       "         [ 1.4987e+01,  2.2400e+06,  1.1950e+03,  4.5303e+04,  1.3604e+04,\n",
       "          -1.1551e+06, -5.4544e+05,  9.1582e+02,  7.6419e+04,  8.9950e+06],\n",
       "         [-1.1926e+04, -1.7431e+06,  3.1561e+05, -9.9593e+02,  2.3159e+04,\n",
       "          -3.5489e+07, -3.5131e+08, -1.4958e+08,  3.5637e+05,  4.0190e+05],\n",
       "         [-1.5874e+04,  5.5602e+06,  1.3070e+06, -4.6040e+03,  9.6558e+05,\n",
       "           1.1007e+07, -2.0440e+07, -1.2290e+07, -1.7920e+06, -7.3368e+02],\n",
       "         [-8.2835e+05,  2.3452e+02,  1.9561e+03, -3.2780e+03, -6.5332e+05,\n",
       "           1.5525e+06, -1.0879e+08,  3.5284e+05, -1.4251e+06, -1.5268e+02],\n",
       "         [-3.9192e+05, -1.0528e+02,  1.9596e+02, -8.6613e+01,  9.3767e+03,\n",
       "          -1.7982e+06,  5.7191e+03,  6.5902e+05,  1.8575e+03,  2.7004e+01],\n",
       "         [-9.3458e+02, -4.6677e+04,  7.3931e+02,  1.6401e+04,  1.1574e+04,\n",
       "          -6.7430e+04,  3.0436e+05,  4.4385e+04,  6.8215e+01, -2.5986e+06]],\n",
       "\n",
       "        [[-9.5104e-03, -1.9198e-02, -2.4704e-02,  2.2050e+01,  2.1315e+05,\n",
       "          -3.7966e+04, -5.3128e+04, -7.7338e+03,  2.7866e+00, -2.6085e+01],\n",
       "         [-4.5681e-02,  8.5712e+03, -2.0755e+05,  3.7325e+06,  9.6108e+05,\n",
       "           3.1504e+05,  4.1600e+06, -5.9595e+04, -1.1344e+05, -2.0388e+01],\n",
       "         [-3.1534e+00, -4.7109e+05, -1.4680e+01,  2.6171e+03, -1.9272e+03,\n",
       "           7.1620e+02,  2.7220e+04, -3.9590e+06,  1.0040e+07,  5.2887e+03],\n",
       "         [-2.2627e+02, -1.6533e+07, -1.7112e+03, -9.3887e+06, -6.1504e+05,\n",
       "          -5.9838e+03,  1.4461e+06,  2.2110e+06, -4.9697e+06, -1.4076e+07],\n",
       "         [ 6.0163e+01,  5.9048e+05,  1.3099e+03,  5.4326e+04,  5.1886e+04,\n",
       "          -8.7743e+05,  9.1973e+05,  8.4849e+02, -3.5641e+05,  1.8202e+06],\n",
       "         [-1.6655e+04, -3.6649e+06,  2.7132e+05, -1.0014e+03,  3.1112e+04,\n",
       "           1.8815e+07, -1.0943e+08,  7.8181e+08, -3.9918e+05,  1.0201e+06],\n",
       "         [-2.3772e+04,  3.8296e+06,  1.3706e+06, -7.0592e+03,  6.0009e+05,\n",
       "           1.6414e+07, -2.7063e+06,  1.6754e+06, -1.7200e+06, -4.2889e+02],\n",
       "         [-5.5011e+05,  2.7883e+02,  2.2177e+03, -4.5476e+03, -1.7227e+06,\n",
       "           2.5257e+06, -1.4434e+08, -6.2128e+05, -9.4535e+05, -7.9139e+01],\n",
       "         [-6.6102e+05, -9.7831e+01,  1.2659e+02, -1.9712e+02,  9.4687e+03,\n",
       "          -1.0049e+06,  5.9184e+03,  5.5662e+05,  1.8877e+03,  2.5700e+01],\n",
       "         [-7.7364e+02, -3.7578e+04, -1.3884e+04,  1.1796e+04,  1.0831e+04,\n",
       "          -1.2922e+05,  2.3476e+05,  4.4653e+04,  7.3393e+01,  6.9756e+06]],\n",
       "\n",
       "        [[-9.4437e-03, -1.9038e-02, -2.4449e-02,  1.3244e+01,  1.6678e+05,\n",
       "          -1.1524e+02, -6.1176e+04, -6.9734e+03,  2.5497e+00, -2.8700e+01],\n",
       "         [-4.5316e-02,  3.8969e+03, -1.9122e+05,  2.0820e+06,  4.8566e+05,\n",
       "           2.9505e+05, -4.1733e+04, -7.8727e+04, -5.4063e+04, -2.3382e+01],\n",
       "         [-1.1502e+00, -1.6889e+05, -1.0796e+01,  1.1077e+03, -3.2264e+03,\n",
       "           5.4725e+02,  8.1151e+04, -1.5338e+06,  3.7530e+07,  4.1146e+03],\n",
       "         [-7.6815e+01, -7.6094e+06, -7.6380e+02, -4.7648e+06, -7.0317e+05,\n",
       "           7.5689e+03,  6.6316e+05,  4.4973e+06, -1.3347e+06, -5.3028e+06],\n",
       "         [ 9.8765e+01, -2.6685e+03,  1.3565e+03,  6.0664e+04,  8.7274e+04,\n",
       "          -4.3097e+05,  1.9670e+06,  7.7838e+02, -1.7030e+05, -1.0488e+06],\n",
       "         [-1.7578e+04, -4.9811e+06,  1.4691e+05, -9.9433e+02,  2.7192e+04,\n",
       "           1.1513e+08, -2.0724e+06,  1.0376e+08, -6.2918e+05,  8.6064e+05],\n",
       "         [-2.6728e+04,  7.3946e+05,  1.0821e+06, -1.0456e+04, -8.3189e+05,\n",
       "           1.8386e+07,  7.8182e+06,  3.4611e+05, -1.0062e+06, -1.7403e+02],\n",
       "         [-2.3638e+05,  2.8073e+02,  2.4192e+03, -6.2654e+03, -3.2798e+06,\n",
       "           6.4179e+05, -1.2694e+07, -1.3466e+06, -4.5419e+05, -2.0793e+01],\n",
       "         [-3.9752e+05, -8.7491e+01,  6.8100e+01, -2.9479e+02,  8.8957e+03,\n",
       "          -1.6585e+05,  5.1686e+03,  3.0489e+05,  1.3883e+03,  2.4210e+01],\n",
       "         [-4.9067e+02, -2.3643e+04, -1.8417e+04,  6.0219e+03,  9.3762e+03,\n",
       "          -1.7643e+05,  1.1486e+05,  3.6573e+04,  6.6462e+01,  5.7043e+06]],\n",
       "\n",
       "        [[-9.3580e-03, -1.8839e-02, -2.4152e-02,  6.4639e+00,  9.7264e+04,\n",
       "           9.1731e+03, -5.7321e+04, -5.5434e+03,  2.2973e+00, -3.1104e+01],\n",
       "         [-4.4858e-02,  1.2064e+03, -1.4170e+05,  6.0740e+05,  1.7799e+05,\n",
       "           1.9895e+05, -4.2275e+06, -7.8233e+04, -1.1307e+04, -2.6836e+01],\n",
       "         [-3.6143e-01, -3.5989e+04, -7.1745e+00,  2.8585e+02, -4.0773e+03,\n",
       "           4.0155e+02,  7.3455e+04, -1.3250e+05,  2.2685e+07,  1.5714e+03],\n",
       "         [-1.6080e+01, -1.8915e+06, -2.7910e+02, -1.7167e+06, -3.5407e+05,\n",
       "           5.8912e+03,  2.3101e+05,  3.9425e+06, -2.4321e+04,  2.9439e+05],\n",
       "         [ 1.1687e+02, -4.8255e+04,  1.3243e+03,  6.3352e+04,  1.1457e+05,\n",
       "          -8.9890e+04,  1.9951e+06,  7.1341e+02, -1.8504e+04, -7.2801e+05],\n",
       "         [-1.3998e+04, -4.7874e+06,  2.5094e+04, -9.7696e+02,  1.5395e+03,\n",
       "           9.8517e+07,  2.7332e+07,  9.0529e+05, -3.3327e+05,  4.2291e+05],\n",
       "         [-2.2768e+04, -1.6386e+06,  6.3350e+05, -1.3318e+04, -2.9869e+06,\n",
       "           1.4761e+07,  9.4738e+06, -3.5779e+05, -4.0049e+05, -4.1272e+01],\n",
       "         [-6.6598e+04,  2.4367e+02,  2.5486e+03, -7.4481e+03, -4.7200e+06,\n",
       "          -3.5793e+06,  1.4951e+05, -1.3174e+06, -1.5951e+05,  8.6503e+00],\n",
       "         [-1.3466e+05, -7.8520e+01,  3.2781e+01, -3.4675e+02,  7.7545e+03,\n",
       "           1.8362e+05,  3.7683e+03,  9.0484e+04,  7.3772e+02,  2.2565e+01],\n",
       "         [-2.4119e+02, -1.2067e+04, -1.7593e+04,  2.8471e+01,  7.5848e+03,\n",
       "          -1.8617e+05,  3.0959e+03,  2.4069e+04,  5.0825e+01,  1.3987e+06]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].z, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.6306e-07, -1.4564e-04],\n",
       "          [ 3.4349e-06, -2.8780e-04],\n",
       "          [ 5.3318e-06, -3.7772e-04],\n",
       "          ...,\n",
       "          [ 1.4208e+02,  7.4042e+00],\n",
       "          [ 2.2587e-04, -1.2729e-02],\n",
       "          [ 3.4964e-03,  4.1944e-01]],\n",
       "\n",
       "         [[ 7.7804e-06, -6.2545e-04],\n",
       "          [ 6.9774e+01,  4.3305e+02],\n",
       "          [ 1.4471e+04,  7.9223e+03],\n",
       "          ...,\n",
       "          [ 1.2257e+02,  4.2405e+01],\n",
       "          [-9.5283e+01, -2.7220e+01],\n",
       "          [ 2.2521e-03,  4.5070e-01]],\n",
       "\n",
       "         [[ 7.5919e-04,  3.5642e-02],\n",
       "          [ 1.5949e+02,  6.0033e+03],\n",
       "          [ 3.5278e-01, -2.1639e-01],\n",
       "          ...,\n",
       "          [ 6.7460e+03,  2.0245e+04],\n",
       "          [-2.7308e+04,  1.6909e+04],\n",
       "          [-5.0284e-01,  4.1006e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.1712e+03,  4.7226e+04],\n",
       "          [-6.4907e-02,  8.2994e-03],\n",
       "          [ 4.6767e+01,  5.7105e+01],\n",
       "          ...,\n",
       "          [-5.9401e+03, -7.0062e+03],\n",
       "          [ 3.5211e+03,  3.6339e+04],\n",
       "          [ 1.7485e-01,  4.5951e+00]],\n",
       "\n",
       "         [[ 6.9321e+04,  1.0750e+05],\n",
       "          [ 5.5554e+00,  3.2701e-01],\n",
       "          [ 1.5232e+01,  1.4665e+01],\n",
       "          ...,\n",
       "          [-5.3614e+03, -4.7725e+03],\n",
       "          [-1.3294e+01, -1.5581e+01],\n",
       "          [-3.6375e-03, -5.5307e-02]],\n",
       "\n",
       "         [[ 2.0812e+02,  7.2063e-02],\n",
       "          [ 1.1642e+04,  1.2494e+03],\n",
       "          [ 1.0336e+04,  2.1583e+03],\n",
       "          ...,\n",
       "          [-2.4190e+02,  4.5652e+01],\n",
       "          [-6.1027e-01,  2.7359e-03],\n",
       "          [-1.3460e+05, -8.8040e+04]]],\n",
       "\n",
       "\n",
       "        [[[ 8.0893e-07, -1.4573e-04],\n",
       "          [ 3.5533e-06, -2.8801e-04],\n",
       "          [ 4.6934e-06, -3.7750e-04],\n",
       "          ...,\n",
       "          [ 1.8055e+02,  9.4797e+00],\n",
       "          [ 2.4922e-04, -1.1197e-02],\n",
       "          [ 3.6373e-03,  4.4797e-01]],\n",
       "\n",
       "         [[ 7.9048e-06, -6.2577e-04],\n",
       "          [ 1.3887e+02,  4.0511e+02],\n",
       "          [ 1.6588e+04,  7.0617e+03],\n",
       "          ...,\n",
       "          [ 2.5088e+02,  1.3962e+02],\n",
       "          [-3.6379e+02, -1.0777e+02],\n",
       "          [-2.5405e-03,  4.8323e-01]],\n",
       "\n",
       "         [[ 1.1342e-03,  5.3956e-02],\n",
       "          [ 2.5891e+02,  9.8268e+03],\n",
       "          [ 3.8406e-01, -2.3053e-01],\n",
       "          ...,\n",
       "          [-3.2063e+03,  1.7380e+04],\n",
       "          [-1.5061e+04,  3.7737e+04],\n",
       "          [ 1.2687e+00,  1.2961e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.6563e+03,  6.4219e+04],\n",
       "          [-1.2757e-01,  5.0908e-01],\n",
       "          [ 4.9308e+01,  6.3570e+01],\n",
       "          ...,\n",
       "          [ 8.4341e+02,  9.6192e+02],\n",
       "          [ 3.6899e+03,  4.3480e+04],\n",
       "          [ 1.8285e-01,  4.8498e+00]],\n",
       "\n",
       "         [[ 7.2259e+04,  1.6302e+05],\n",
       "          [ 6.1074e+00,  3.0723e-01],\n",
       "          [ 1.6330e+01,  1.6127e+01],\n",
       "          ...,\n",
       "          [-8.8147e+03, -7.3244e+03],\n",
       "          [-2.5284e+01, -2.9773e+01],\n",
       "          [-3.9452e-03, -4.5086e-02]],\n",
       "\n",
       "         [[ 2.2885e+02,  3.7342e-01],\n",
       "          [ 1.3270e+04,  1.1981e+03],\n",
       "          [ 1.2702e+04,  2.0863e+03],\n",
       "          ...,\n",
       "          [-2.9760e+02,  7.4796e+01],\n",
       "          [-9.6110e-01,  1.6388e-02],\n",
       "          [-5.8022e+04,  7.5433e+04]]],\n",
       "\n",
       "\n",
       "        [[[ 8.5795e-07, -1.4571e-04],\n",
       "          [ 3.6432e-06, -2.8757e-04],\n",
       "          [ 5.4717e-06, -3.7656e-04],\n",
       "          ...,\n",
       "          [ 2.0207e+02,  1.0587e+01],\n",
       "          [ 2.6030e-04, -9.5446e-03],\n",
       "          [ 3.7504e-03,  4.7406e-01]],\n",
       "\n",
       "         [[ 8.3085e-06, -6.2388e-04],\n",
       "          [ 1.7509e+02,  3.2236e+02],\n",
       "          [ 1.6136e+04,  5.2204e+03],\n",
       "          ...,\n",
       "          [ 4.2267e+02,  2.2985e+02],\n",
       "          [-6.9060e+02, -2.1516e+02],\n",
       "          [-7.8045e-03,  5.1165e-01]],\n",
       "\n",
       "         [[ 1.0362e-03,  4.7905e-02],\n",
       "          [ 2.4545e+02,  9.4006e+03],\n",
       "          [ 3.6139e-01, -2.1573e-01],\n",
       "          ...,\n",
       "          [-1.4450e+04,  1.1347e+04],\n",
       "          [ 2.9717e+05,  1.4629e+05],\n",
       "          [ 1.0977e+01,  4.5451e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.1022e+03,  5.6789e+04],\n",
       "          [-1.9327e-01,  1.1699e+00],\n",
       "          [ 5.0779e+01,  6.8412e+01],\n",
       "          ...,\n",
       "          [ 2.1371e+04,  2.1932e+04],\n",
       "          [ 2.8275e+03,  3.7294e+04],\n",
       "          [ 1.4101e-01,  3.8033e+00]],\n",
       "\n",
       "         [[ 4.9745e+04,  1.5399e+05],\n",
       "          [ 5.2333e+00,  2.3107e-01],\n",
       "          [ 1.5526e+01,  1.7071e+01],\n",
       "          ...,\n",
       "          [-9.8381e+03, -7.4878e+03],\n",
       "          [-3.4806e+01, -4.1718e+01],\n",
       "          [-4.2955e-03, -3.4005e-02]],\n",
       "\n",
       "         [[ 1.9852e+02,  1.7825e+00],\n",
       "          [ 1.1868e+04,  9.1264e+02],\n",
       "          [ 1.1969e+04,  1.6045e+03],\n",
       "          ...,\n",
       "          [-2.9101e+02,  1.0161e+02],\n",
       "          [-1.2746e+00,  2.8717e-02],\n",
       "          [ 7.4600e+05,  7.3296e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 9.1758e-07, -1.4531e-04],\n",
       "          [ 3.7813e-06, -2.8657e-04],\n",
       "          [ 6.8660e-06, -3.7476e-04],\n",
       "          ...,\n",
       "          [ 1.9945e+02,  1.0380e+01],\n",
       "          [ 2.5723e-04, -7.7814e-03],\n",
       "          [ 3.8390e-03,  4.9699e-01]],\n",
       "\n",
       "         [[ 8.6183e-06, -6.2224e-04],\n",
       "          [ 1.6890e+02,  2.1652e+02],\n",
       "          [ 1.3389e+04,  3.1185e+03],\n",
       "          ...,\n",
       "          [ 5.9520e+02,  2.5710e+02],\n",
       "          [-6.5925e+02, -2.1849e+02],\n",
       "          [-6.1744e-03,  5.3883e-01]],\n",
       "\n",
       "         [[ 5.8604e-04,  2.4807e-02],\n",
       "          [ 1.3713e+02,  5.3172e+03],\n",
       "          [ 2.9399e-01, -1.7613e-01],\n",
       "          ...,\n",
       "          [-1.3157e+04,  7.2429e+03],\n",
       "          [ 7.2887e+05,  2.6504e+05],\n",
       "          [ 2.1811e+01,  7.6796e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7362e+03,  3.3001e+04],\n",
       "          [-2.2925e-01,  1.7985e+00],\n",
       "          [ 5.1078e+01,  7.1440e+01],\n",
       "          ...,\n",
       "          [ 4.6082e+04,  4.4529e+04],\n",
       "          [ 1.5749e+03,  2.3310e+04],\n",
       "          [ 7.7574e-02,  2.2365e+00]],\n",
       "\n",
       "         [[ 2.2435e+04,  9.3454e+04],\n",
       "          [ 3.4361e+00,  1.4130e-01],\n",
       "          [ 1.3288e+01,  1.7534e+01],\n",
       "          ...,\n",
       "          [-7.0266e+03, -4.7544e+03],\n",
       "          [-3.4725e+01, -4.3001e+01],\n",
       "          [-4.6455e-03, -2.2591e-02]],\n",
       "\n",
       "         [[ 1.3487e+02,  2.3011e+00],\n",
       "          [ 8.3127e+03,  5.5204e+02],\n",
       "          [ 8.7840e+03,  9.8154e+02],\n",
       "          ...,\n",
       "          [-2.2835e+02,  1.1372e+02],\n",
       "          [-1.4096e+00,  3.4229e-02],\n",
       "          [ 1.2450e+06,  9.1925e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 9.6433e-07, -1.4484e-04],\n",
       "          [ 3.9361e-06, -2.8527e-04],\n",
       "          [ 7.9951e-06, -3.7264e-04],\n",
       "          ...,\n",
       "          [ 1.7387e+02,  9.0040e+00],\n",
       "          [ 2.4379e-04, -6.0831e-03],\n",
       "          [ 3.8998e-03,  5.1600e-01]],\n",
       "\n",
       "         [[ 8.9566e-06, -6.1945e-04],\n",
       "          [ 1.3262e+02,  1.2135e+02],\n",
       "          [ 9.5110e+03,  1.4116e+03],\n",
       "          ...,\n",
       "          [ 6.7235e+02,  2.1274e+02],\n",
       "          [-3.2359e+02, -1.1480e+02],\n",
       "          [-4.6434e-05,  5.6395e-01]],\n",
       "\n",
       "         [[ 2.2592e-04,  6.7052e-03],\n",
       "          [ 4.5594e+01,  1.7899e+03],\n",
       "          [ 2.0597e-01, -1.2556e-01],\n",
       "          ...,\n",
       "          [-4.5547e+03,  4.4799e+03],\n",
       "          [ 6.3894e+05,  2.1247e+05],\n",
       "          [ 1.7796e+01,  6.1304e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5363e+02,  1.2678e+04],\n",
       "          [-2.1350e-01,  2.1750e+00],\n",
       "          [ 5.0203e+01,  7.2457e+01],\n",
       "          ...,\n",
       "          [ 5.5561e+04,  5.0730e+04],\n",
       "          [ 6.4672e+02,  1.0664e+04],\n",
       "          [ 2.9276e-02,  1.0036e+00]],\n",
       "\n",
       "         [[ 6.5160e+03,  3.6986e+04],\n",
       "          [ 1.6360e+00,  7.3475e-02],\n",
       "          [ 1.0606e+01,  1.7533e+01],\n",
       "          ...,\n",
       "          [-2.5517e+03, -1.3100e+03],\n",
       "          [-2.5064e+01, -3.2514e+01],\n",
       "          [-5.0033e-03, -1.2037e-02]],\n",
       "\n",
       "         [[ 7.2875e+01,  1.5929e+00],\n",
       "          [ 4.6085e+03,  2.6473e+02],\n",
       "          [ 5.0743e+03,  4.7784e+02],\n",
       "          ...,\n",
       "          [-1.4191e+02,  1.0520e+02],\n",
       "          [-1.3274e+00,  2.8144e-02],\n",
       "          [ 6.5876e+05,  3.9148e+05]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0366e-06, -1.4396e-04],\n",
       "          [ 4.0138e-06, -2.8342e-04],\n",
       "          [ 8.5869e-06, -3.6953e-04],\n",
       "          ...,\n",
       "          [ 1.3408e+02,  6.8876e+00],\n",
       "          [ 2.2509e-04, -4.3377e-03],\n",
       "          [ 3.9302e-03,  5.3172e-01]],\n",
       "\n",
       "         [[ 9.2291e-06, -6.1362e-04],\n",
       "          [ 8.6537e+01,  5.5447e+01],\n",
       "          [ 5.8042e+03,  3.8197e+02],\n",
       "          ...,\n",
       "          [ 5.7963e+02,  1.3428e+02],\n",
       "          [-8.5663e+01, -3.2627e+01],\n",
       "          [ 3.5581e-03,  5.8460e-01]],\n",
       "\n",
       "         [[ 8.7239e-05, -2.3992e-04],\n",
       "          [ 9.0013e+00,  3.5917e+02],\n",
       "          [ 1.2567e-01, -7.8505e-02],\n",
       "          ...,\n",
       "          [-4.2135e+02,  1.9874e+03],\n",
       "          [ 2.4438e+05,  7.8184e+04],\n",
       "          [ 6.6057e+00,  2.6086e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.2908e+01,  3.2310e+03],\n",
       "          [-1.5704e-01,  2.1792e+00],\n",
       "          [ 4.8222e+01,  7.1185e+01],\n",
       "          ...,\n",
       "          [ 4.3795e+04,  3.7610e+04],\n",
       "          [ 1.9468e+02,  3.5867e+03],\n",
       "          [ 5.1891e-03,  3.7435e-01]],\n",
       "\n",
       "         [[ 1.1885e+03,  9.6240e+03],\n",
       "          [ 4.1750e-01,  3.7018e-02],\n",
       "          [ 8.3363e+00,  1.7115e+01],\n",
       "          ...,\n",
       "          [ 3.5143e+02,  5.1567e+02],\n",
       "          [-1.3054e+01, -1.8303e+01],\n",
       "          [-5.3718e-03, -1.4013e-03]],\n",
       "\n",
       "         [[ 3.1149e+01,  7.0915e-01],\n",
       "          [ 2.0137e+03,  1.0064e+02],\n",
       "          [ 2.3299e+03,  1.8564e+02],\n",
       "          ...,\n",
       "          [-8.1032e+01,  7.9292e+01],\n",
       "          [-1.0592e+00,  1.4817e-02],\n",
       "          [ 1.3498e+05,  6.2994e+04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].xy_span, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb = PanelScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0inf = PanelX0Inferer(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, weight = x0inf.pred_x0(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = DetectorLoss(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(pred, weight, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1992.9351, -48231.3086]) tensor(9565749.) tensor([-10153.3057, -51757.7969])\n",
      "tensor([  1226.1810, 174080.7344]) tensor(9659683.) tensor([ -7615.5068, 139768.6719])\n",
      "tensor([ -3007.3140, 235681.5781]) tensor(-9004462.) tensor([ -7731.5322, 189454.4219])\n",
      "tensor([ -2213.5059, 650494.8125]) tensor(-17420022.) tensor([-10464.6641, 526583.2500])\n",
      "tensor([224155.2188, 715894.6250]) tensor(23537044.) tensor([ 22406.3477, 489141.1250])\n",
      "tensor([22927.8379, 22679.4043]) tensor(5778611.) tensor([-4169.8223,  7665.2588])\n",
      "tensor([-4861.8901, 85214.9531]) tensor(-6015730.) tensor([-8422.4629, 50227.6172])\n",
      "tensor([ 58665.3203, 442562.1875]) tensor(-16101539.) tensor([ -1088.2104, 288401.4062])\n"
     ]
    }
   ],
   "source": [
    "for d in volume.get_detectors():\n",
    "    for p in d.panels:\n",
    "        print(p.xy.grad, p.z.grad, p.xy_span.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VolumeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from __future__ import annotations\n",
    "from fastcore.all import Path\n",
    "from typing import Callable, Iterator, Optional, List, Any, Tuple, Union\n",
    "from fastprogress.fastprogress import ConsoleProgressBar, NBProgressBar, ProgressBar\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from tomopt.optimisation.callbacks.cyclic_callbacks import CyclicCallback\n",
    "from tomopt.optimisation.callbacks.eval_metric import EvalMetric\n",
    "from tomopt.optimisation.wrapper.volume_wrapper import FitParams\n",
    "\n",
    "PartialOpt = Callable[[Iterator[nn.Parameter]], torch.optim.Optimizer]\n",
    "\n",
    "class AbsVolumeWrapper(metaclass=ABCMeta):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "        partial_scatter_inferer: Callable[[MuonBatch, Volume], ScatterBatch] = ScatterBatch,\n",
    "        partial_x0_inferer: Callable[[ScatterBatch, bool], X0Inferer] = X0Inferer\n",
    "    ):\n",
    "        self.volume, self.loss_func, self.default_pred, self.mu_generator = volume, loss_func, default_pred, mu_generator\n",
    "        self.partial_scatter_inferer, self.partial_x0_inferer = partial_scatter_inferer, partial_x0_inferer\n",
    "        self._build_opt(**partial_opts)\n",
    "        self.parameters = self.volume.parameters\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _build_opt(\n",
    "        self, **kwargs\n",
    "    ) -> None:\n",
    "        r'''\n",
    "        self.opts = {'res_opt': res_opt((l.resolution for l in self.volume.get_detectors())),\n",
    "                     'eff_opt': eff_opt((l.efficiency for l in self.volume.get_detectors()))}\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def get_detectors(self) -> List[DetectorLayer]:\n",
    "        return self.volume.get_detectors()\n",
    "\n",
    "    def save(self, name: str) -> None:\n",
    "        torch.save({\"volume\": self.volume.state_dict(), **{k:v.state_dict() for k,v in self.opts.items()}}, str(name))\n",
    "\n",
    "    def load(self, name: str) -> None:\n",
    "        state = torch.load(name, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.volume.load_state_dict(state[\"volume\"])\n",
    "        for k,v in state.items():\n",
    "            if '_opt' in k: self.opts[k].load_state_dict(v)\n",
    "\n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "        partial_scatter_inferer: Callable[[MuonBatch, Volume], ScatterBatch] = ScatterBatch,\n",
    "        partial_x0_inferer: Callable[[ScatterBatch, bool], X0Inferer] = X0Inferer\n",
    "    ) -> VolumeWrapper:\n",
    "        vw = cls(volume=volume, partial_opts=partial_opts, loss_func=loss_func, default_pred=default_pred, mu_generator=mu_generator, partial_scatter_inferer=partial_scatter_inferer, partial_x0_inferer=partial_x0_inferer)\n",
    "        vw.load(name)\n",
    "        return vw\n",
    "\n",
    "    def get_param_count(self, trainable: bool = True) -> int:\n",
    "        r\"\"\"\n",
    "        Return number of parameters in detector.\n",
    "\n",
    "        Arguments:\n",
    "            trainable: if true (default) only count trainable parameters\n",
    "\n",
    "        Returns:\n",
    "            Number of (trainable) parameters in detector\n",
    "        \"\"\"\n",
    "\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad or not trainable)\n",
    "\n",
    "    def _scan_volume(self) -> None:\n",
    "        # Scan volume with muon batches\n",
    "        self.fit_params.wpreds, self.fit_params.weights = [], []\n",
    "        if self.fit_params.state != \"test\":\n",
    "            muon_bar = progress_bar(range(self.fit_params.n_mu_per_volume // self.fit_params.mu_bs), display=False, leave=False)\n",
    "        else:\n",
    "            muon_bar = progress_bar(range(self.fit_params.n_mu_per_volume // self.fit_params.mu_bs), parent=self.fit_params.passive_bar)\n",
    "        for _ in muon_bar:\n",
    "            self.fit_params.mu = MuonBatch(self.mu_generator(self.fit_params.mu_bs), init_z=self.volume.h)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_mu_batch_begin()\n",
    "            self.volume(self.fit_params.mu)\n",
    "            self.fit_params.sb = self.partial_scatter_inferer(self.fit_params.mu, self.volume)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_scatter_end()\n",
    "            inferer = self.partial_x0_inferer(self.fit_params.sb, self.default_pred)\n",
    "            pred, wgt = inferer.pred_x0(inc_default=False)\n",
    "            self.fit_params.wpreds.append(pred * wgt)\n",
    "            self.fit_params.weights.append(wgt)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_mu_batch_end()\n",
    "\n",
    "        # Predict volume based on all muon batches\n",
    "        for c in self.fit_params.cbs:\n",
    "            c.on_x0_pred_begin()\n",
    "        wgt = torch.stack(self.fit_params.weights, dim=0).sum(0)\n",
    "        pred = torch.stack(self.fit_params.wpreds, dim=0).sum(0) / wgt\n",
    "        if self.fit_params.use_default_pred:\n",
    "            pred, wgt = inferer.add_default_pred(pred, wgt)\n",
    "        self.fit_params.weight = wgt\n",
    "        self.fit_params.pred = pred\n",
    "\n",
    "        for c in self.fit_params.cbs:\n",
    "            c.on_x0_pred_end()\n",
    "\n",
    "        # Compute loss for volume\n",
    "        if self.fit_params.state != \"test\" and self.loss_func is not None:\n",
    "            loss = self.loss_func(pred_x0=self.fit_params.pred, pred_weight=self.fit_params.weight, volume=self.volume)\n",
    "            if self.fit_params.loss_val is None:\n",
    "                self.fit_params.loss_val = loss\n",
    "            else:\n",
    "                self.fit_params.loss_val = self.fit_params.loss_val + loss\n",
    "            print(jacobian(self.fit_params.loss_val, self.volume.get_detectors()[0].panels[0].xy_span, create_graph=True))\n",
    "\n",
    "    def _scan_volumes(self, passives: PassiveYielder) -> None:\n",
    "        if self.fit_params.state == \"test\":\n",
    "            self.fit_params.passive_bar = master_bar(passives)\n",
    "        for i, passive in enumerate(self.fit_params.passive_bar if self.fit_params.state == \"test\" else passives):\n",
    "            self.fit_params.volume_id = i\n",
    "            if self.fit_params.state != \"test\" and i % self.fit_params.passive_bs == 0:  # Volume batch start\n",
    "                self.fit_params.loss_val = None\n",
    "                for c in self.fit_params.cbs:\n",
    "                    c.on_volume_batch_begin()\n",
    "\n",
    "            self.volume.load_rad_length(passive)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_volume_begin()\n",
    "            self._scan_volume()\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_volume_end()\n",
    "\n",
    "            if self.fit_params.state != \"test\" and (i + 1) % self.fit_params.passive_bs == 0:  # Volume batch end\n",
    "                if self.fit_params.loss_val is not None:\n",
    "                    self.fit_params.mean_loss = self.fit_params.loss_val / self.fit_params.passive_bs\n",
    "                for c in self.fit_params.cbs:\n",
    "                    c.on_volume_batch_end()\n",
    "\n",
    "                if self.fit_params.state == \"train\":\n",
    "                    # Compute update step\n",
    "                    for o in self.opts.values():\n",
    "                        o.zero_grad()\n",
    "                    for c in self.fit_params.cbs:\n",
    "                        c.on_backwards_begin()\n",
    "                    self.fit_params.mean_loss.backward()\n",
    "                    for c in self.fit_params.cbs:\n",
    "                        c.on_backwards_end()        \n",
    "                    for o in self.opts.values():\n",
    "                        o.step()\n",
    "                    for d in self.volume.get_detectors():\n",
    "                        d.conform_detector()\n",
    "                        \n",
    "#                     for d in self.volume.get_detectors():\n",
    "#                         for p in d.panels:\n",
    "#                             print('xy', p.xy.data, p.xy.grad)\n",
    "#                             print('z', p.z.data, p.z.grad)\n",
    "#                     for d in self.volume.get_detectors():\n",
    "#                         for p in d.panels:\n",
    "#                             print('xy_span', p.xy_span.data, p.xy_span.grad)\n",
    "\n",
    "                if len(passives) - (i + 1) < self.fit_params.passive_bs:\n",
    "                    break\n",
    "\n",
    "    def _fit_epoch(self) -> None:\n",
    "        def run_epoch(passives: PassiveYielder) -> None:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_epoch_begin()\n",
    "            self._scan_volumes(passives)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_epoch_end()\n",
    "\n",
    "        self.fit_params.epoch += 1\n",
    "        # Training\n",
    "        self.volume.train()\n",
    "        self.fit_params.state = \"train\"\n",
    "        run_epoch(self.fit_params.trn_passives)\n",
    "\n",
    "        # Validation\n",
    "        if self.fit_params.val_passives is not None:\n",
    "            self.volume.eval()\n",
    "            self.fit_params.state = \"valid\"\n",
    "            run_epoch(self.fit_params.val_passives)\n",
    "\n",
    "    @staticmethod\n",
    "    def _sort_cbs(cbs: List[Callback]) -> Tuple[List[CyclicCallback], Optional[MetricLogger], Optional[List[EvalMetric]]]:\n",
    "        cyclic_cbs, metric_log, metric_cbs = [], None, []\n",
    "        for c in cbs:\n",
    "            if isinstance(c, CyclicCallback):\n",
    "                cyclic_cbs.append(c)  # CBs that might prevent a wrapper from stopping training due to a hyper-param cycle\n",
    "            if isinstance(c, MetricLogger):\n",
    "                metric_log = c  # CB that logs losses and eval_metrics\n",
    "            if isinstance(c, EvalMetric):\n",
    "                metric_cbs.append(c)  # CB that computes additional performance metrics\n",
    "        return cyclic_cbs, metric_log, metric_cbs\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        n_epochs: int,\n",
    "        passive_bs: int,\n",
    "        n_mu_per_volume: int,\n",
    "        mu_bs: int,\n",
    "        trn_passives: PassiveYielder,\n",
    "        val_passives: Optional[PassiveYielder],\n",
    "        cbs: Optional[List[Callback]] = None,\n",
    "        cb_savepath: Path = Path(\"train_weights\"),\n",
    "    ) -> List[Callback]:\n",
    "\n",
    "        if cbs is None:\n",
    "            cbs = []\n",
    "        cyclic_cbs, metric_log, metric_cbs = self._sort_cbs(cbs)\n",
    "\n",
    "        self.fit_params = FitParams(\n",
    "            cbs=cbs,\n",
    "            cyclic_cbs=cyclic_cbs,\n",
    "            metric_log=metric_log,\n",
    "            metric_cbs=metric_cbs,\n",
    "            stop=False,\n",
    "            n_epochs=n_epochs,\n",
    "            mu_bs=mu_bs,\n",
    "            n_mu_per_volume=n_mu_per_volume,\n",
    "            cb_savepath=Path(cb_savepath),\n",
    "            trn_passives=trn_passives,\n",
    "            val_passives=val_passives,\n",
    "            passive_bs=passive_bs,\n",
    "        )\n",
    "        self.fit_params.cb_savepath.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.set_wrapper(self)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_train_begin()\n",
    "            self.fit_params.epoch_bar = progress_bar(range(self.fit_params.n_epochs))\n",
    "            for e in self.fit_params.epoch_bar:\n",
    "                self._fit_epoch()\n",
    "                if self.fit_params.stop:\n",
    "                    break\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_train_end()\n",
    "        finally:\n",
    "            self.fit_params = None\n",
    "            torch.cuda.empty_cache()\n",
    "        return cbs\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        passives: PassiveYielder,\n",
    "        n_mu_per_volume: int,\n",
    "        mu_bs: int,\n",
    "        use_default_pred: bool = False,\n",
    "        pred_cb: PredHandler = PredHandler(),\n",
    "        cbs: Optional[List[Callback]] = None,\n",
    "        cb_savepath: Path = Path(\"train_weights\"),\n",
    "    ) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        if cbs is None:\n",
    "            cbs = []\n",
    "        cbs.append(pred_cb)\n",
    "        passives.shuffle = False\n",
    "\n",
    "        self.fit_params = FitParams(\n",
    "            n_mu_per_volume=n_mu_per_volume,\n",
    "            mu_bs=mu_bs,\n",
    "            cbs=cbs,\n",
    "            tst_passives=passives,\n",
    "            state=\"test\",\n",
    "            cb_savepath=cb_savepath,\n",
    "            use_default_pred=use_default_pred,\n",
    "        )\n",
    "        try:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.set_wrapper(self)\n",
    "            self.volume.eval()\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_pred_begin()\n",
    "            self._scan_volumes(self.fit_params.tst_passives)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_pred_end()\n",
    "        finally:\n",
    "            self.fit_params = None\n",
    "            cbs.pop()  # Remove pred_cb to avoid mutating cbs\n",
    "            torch.cuda.empty_cache()\n",
    "        return pred_cb.get_preds()\n",
    "\n",
    "    def get_opt_lr(self, opt:str) -> float:\n",
    "        return self.opts[opt].param_groups[0][\"lr\"]\n",
    "\n",
    "    def set_opt_lr(self, lr: float, opt:str) -> None:\n",
    "        self.opts[opt].param_groups[0][\"lr\"] = lr\n",
    "\n",
    "    def get_opt_mom(self, opt:str) -> float:\n",
    "        if \"betas\" in self.opts[opt].param_groups[0]:\n",
    "            return self.opts[opt].param_groups[0][\"betas\"][0]\n",
    "        else:\n",
    "            return self.opts[opt].param_groups[0][\"momentum\"]\n",
    "\n",
    "    def set_opt_mom(self, mom: float, opt:str) -> None:\n",
    "        if \"betas\" in self.opts[opt].param_groups[0]:\n",
    "            self.opts[opt].param_groups[0][\"betas\"] = (mom, self.opts[opt].param_groups[0][\"betas\"][1])\n",
    "        else:\n",
    "            self.opts[opt].param_groups[0][\"momentum\"] = mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeWrapper(AbsVolumeWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        res_opt: PartialOpt,\n",
    "        eff_opt: PartialOpt,\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ):\n",
    "        super().__init__(volume=volume, partial_opts={'res_opt':res_opt, 'eff_opt':eff_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                         mu_generator=mu_generator, partial_scatter_inferer=ScatterBatch, partial_x0_inferer=X0Inferer)\n",
    "\n",
    "    def _build_opt(\n",
    "        self, res_opt: PartialOpt, eff_opt: PartialOpt\n",
    "    ) -> None:\n",
    "        self.opts = {'res_opt': res_opt((l.resolution for l in self.volume.get_detectors())),\n",
    "                     'eff_opt': eff_opt((l.efficiency for l in self.volume.get_detectors()))}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ) -> VolumeWrapper:\n",
    "        return super().from_save(name, partial_opts={'res_opt':res_opt, 'eff_opt':eff_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                                 mu_generator=mu_generator, partial_scatter_inferer=ScatterBatch, partial_x0_inferer=X0Inferer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PanelVolumeWrapper(AbsVolumeWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        xy_pos_opt: PartialOpt,\n",
    "        z_pos_opt: PartialOpt,\n",
    "        xy_span_opt: PartialOpt,\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ):\n",
    "        super().__init__(volume=volume, partial_opts={'xy_pos_opt':xy_pos_opt, 'z_pos_opt':z_pos_opt, 'xy_span_opt':xy_span_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                         mu_generator=mu_generator, partial_scatter_inferer=PanelScatterBatch, partial_x0_inferer=PanelX0Inferer)\n",
    "\n",
    "    def _build_opt(\n",
    "        self, xy_pos_opt: PartialOpt, z_pos_opt: PartialOpt, xy_span_opt: PartialOpt\n",
    "    ) -> None:\n",
    "        self.opts = {'xy_pos_opt': xy_pos_opt((p.xy for l in self.volume.get_detectors() for p in l.panels)),\n",
    "                     'z_pos_opt': z_pos_opt((p.z for l in self.volume.get_detectors() for p in l.panels)),\n",
    "                     'xy_span_opt': xy_span_opt((p.xy_span for l in self.volume.get_detectors() for p in l.panels))}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ) -> VolumeWrapper:\n",
    "        return super().from_save(name, partial_opts={'xyz_opt':xyz_opt, 'xy_span_opt':xy_span_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                                 mu_generator=mu_generator, partial_scatter_inferer=PanelScatterBatch, partial_x0_inferer=PanelX0Inferer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelDetectorLoss(nn.Module):\n",
    "    def __init__(self, cost_coef: Optional[float] = None):\n",
    "        super().__init__()\n",
    "        self.cost_coef = cost_coef\n",
    "        self.sub_losses: Dict[str, Tensor] = {}  # Store subcomponents in dict for telemetry\n",
    "\n",
    "    def _compute_cost_coef(self, cost: Tensor, inference: Tensor) -> None:\n",
    "        self.cost_coef = inference.detach() / cost.detach()\n",
    "\n",
    "    def forward(self, pred_x0: Tensor, pred_weight: Tensor, volume: Volume) -> Tensor:\n",
    "        true_x0 = volume.get_rad_cube()\n",
    "        inference = torch.mean(pred_x0 - true_x0).pow(2)\n",
    "        self.sub_losses[\"error\"] = inference\n",
    "        cost = volume.get_cost()\n",
    "        if self.cost_coef is None:\n",
    "            self._compute_cost_coef(cost, inference)\n",
    "        self.sub_losses[\"cost\"] = self.cost_coef * cost\n",
    "        return self.sub_losses[\"error\"] + self.sub_losses[\"cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython.display import display\n",
    "    \n",
    "from tomopt.optimisation.callbacks.callback import Callback\n",
    "\n",
    "class MetricLogger(Callback):\n",
    "    r\"\"\"\n",
    "    Provides live feedback during training showing a variety of metrics to help highlight problems or test hyper-parameters without completing a full training.\n",
    "    If `show_plots` is false, will instead print training and validation losses at the end of each epoch.\n",
    "    The full history is available as a dictionary by calling `MetricLogger.get_loss_history`.\n",
    "    \"\"\"\n",
    "\n",
    "    tk_sz = 16\n",
    "    tk_col = \"black\"\n",
    "    lbl_sz = 24\n",
    "    lbl_col = \"black\"\n",
    "    leg_sz = 16\n",
    "    cat_palette = \"tab10\"\n",
    "    style = {\"style\": \"whitegrid\", \"rc\": {\"patch.edgecolor\": \"none\"}}\n",
    "    h_mid = 8\n",
    "    w_mid = h_mid * 16 / 9\n",
    "\n",
    "    def __init__(self, show_plots: bool = IN_NOTEBOOK):\n",
    "        self.show_plots = show_plots\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        self.loss_vals: Dict[str, List[float]] = {\"Training\": [], \"Validation\": []}\n",
    "        self.sub_losses: Dict[str, List[float]] = defaultdict(list)\n",
    "        self.best_loss: float = math.inf\n",
    "        self.val_epoch_results: Optional[Tuple[float, Optional[float]]] = None\n",
    "        self.metric_cbs: List[EvalMetric] = []\n",
    "        self.n_trn_batches = len(self.wrapper.fit_params.trn_passives) // self.wrapper.fit_params.passive_bs\n",
    "\n",
    "        self.metric_vals: List[List[float]] = [[] for _ in self.wrapper.fit_params.metric_cbs]\n",
    "        self.main_metric_idx: Optional[int] = None\n",
    "        self.lock_to_metric: bool = False\n",
    "        if len(self.wrapper.fit_params.metric_cbs) > 0:\n",
    "            self.main_metric_idx = 0\n",
    "            for i, c in enumerate(self.wrapper.fit_params.metric_cbs):\n",
    "                if c.main_metric:\n",
    "                    self.main_metric_idx = i\n",
    "                    self.lock_to_metric = True\n",
    "                    break\n",
    "        self._prep_plots()\n",
    "        self.display = display(self.fig, display_id=True)\n",
    "        \n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        return self.fig.add_gridspec(3 + (self.main_metric_idx is None), 1)\n",
    "\n",
    "    def _prep_plots(self) -> None:\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.fig = plt.figure(figsize=(self.w_mid, self.w_mid), constrained_layout=True)\n",
    "                self.grid_spec = self._build_grid_spec()\n",
    "                self.loss_ax = self.fig.add_subplot(self.grid_spec[:3, :])\n",
    "                self.sub_loss_ax = self.fig.add_subplot(self.grid_spec[3:4, :])\n",
    "                if self.main_metric_idx is not None:\n",
    "                    self.metric_ax = self.fig.add_subplot(self.grid_spec[4:5, :])\n",
    "                for ax in [self.loss_ax, self.sub_loss_ax]:\n",
    "                    ax.tick_params(axis=\"x\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    ax.tick_params(axis=\"y\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                self.sub_loss_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                self.loss_ax.set_ylabel(\"Loss\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                self.sub_loss_ax.set_ylabel(\"Loss Composition\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                if self.main_metric_idx is not None:\n",
    "                    self.metric_ax.tick_params(axis=\"x\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    self.metric_ax.tick_params(axis=\"y\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    self.metric_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                    self.metric_ax.set_ylabel(self.wrapper.fit_params.metric_cbs[self.main_metric_idx].name, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "    def on_train_begin(self) -> None:\n",
    "        r\"\"\"\n",
    "        Prepare for new training\n",
    "        \"\"\"\n",
    "\n",
    "        super().on_train_begin()\n",
    "        self._reset()\n",
    "\n",
    "    def on_epoch_begin(self) -> None:\n",
    "        r\"\"\"\n",
    "        Prepare to track new loss\n",
    "        \"\"\"\n",
    "\n",
    "        self.tmp_loss, self.batch_cnt, self.volume_cnt = 0, 0, 0\n",
    "        self.tmp_sub_losses: Dict[str, float] = defaultdict(float)\n",
    "\n",
    "    def on_volume_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"valid\" and self.wrapper.loss_func is not None and hasattr(self.wrapper.loss_func, \"sub_losses\"):\n",
    "            for k, v in self.wrapper.loss_func.sub_losses.items():\n",
    "                self.tmp_sub_losses[k] += v.data.item()\n",
    "            self.volume_cnt += 1\n",
    "\n",
    "    def on_backwards_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"train\":\n",
    "            self.loss_vals[\"Training\"].append(self.wrapper.fit_params.mean_loss.data.item())\n",
    "\n",
    "    def on_volume_batch_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"valid\":\n",
    "            self.tmp_loss += self.wrapper.fit_params.mean_loss.data.item()\n",
    "            self.batch_cnt += 1\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        r\"\"\"\n",
    "        If validation epoch finished, record validation losses, compute info and update plots\n",
    "        \"\"\"\n",
    "\n",
    "        if self.wrapper.fit_params.state == \"valid\":\n",
    "            self.loss_vals[\"Validation\"].append(self.tmp_loss / self.batch_cnt)\n",
    "            for k, v in self.tmp_sub_losses.items():\n",
    "                self.sub_losses[k].append(v / (self.loss_vals[\"Validation\"][-1] * self.volume_cnt))  # Fractional components\n",
    "\n",
    "            for i, c in enumerate(self.wrapper.fit_params.metric_cbs):\n",
    "                self.metric_vals[i].append(c.get_metric())\n",
    "            if self.loss_vals[\"Validation\"][-1] <= self.best_loss:\n",
    "                self.best_loss = self.loss_vals[\"Validation\"][-1]\n",
    "\n",
    "            if self.show_plots:\n",
    "                self.update_plot()\n",
    "                self.display.update(self.fig)\n",
    "            else:\n",
    "                self.print_losses()\n",
    "\n",
    "            m = None\n",
    "            if self.lock_to_metric:\n",
    "                m = self.metric_vals[self.main_metric_idx][-1]\n",
    "                if not self.wrapper.fit_params.metric_cbs[self.main_metric_idx].lower_metric_better:\n",
    "                    m *= -1\n",
    "            self.val_epoch_results = self.loss_vals[\"Validation\"][-1], m\n",
    "\n",
    "    def print_losses(self) -> None:\n",
    "        r\"\"\"\n",
    "        Print training and validation losses for the last epoch\n",
    "        \"\"\"\n",
    "\n",
    "        p = f'Epoch {len(self.loss_vals[\"Validation\"])}: '\n",
    "        p += f'Training = {np.mean(self.loss_vals[\"Training\"][-self.n_trn_batches:]):.2E} | '\n",
    "        p += f'Validation = {self.loss_vals[\"Validation\"][-1]:.2E}'\n",
    "        for m, v in zip(self.wrapper.fit_params.metric_cbs, self.metric_vals):\n",
    "            p += f\" {m.name} = {v[-1]:.2E}\"\n",
    "        print(p)\n",
    "\n",
    "    def update_plot(self) -> None:\n",
    "        r\"\"\"\n",
    "        Updates the plot(s).\n",
    "        \"\"\"\n",
    "\n",
    "        # Loss\n",
    "        self.loss_ax.clear()\n",
    "        self.sub_loss_ax.clear()\n",
    "        with sns.axes_style(**self.style), sns.color_palette(self.cat_palette):\n",
    "            self.loss_ax.plot(\n",
    "                (1 / self.n_trn_batches)\n",
    "                + np.linspace(0, len(self.loss_vals[\"Validation\"]), self.n_trn_batches * len(self.loss_vals[\"Validation\"]), endpoint=False),\n",
    "                self.loss_vals[\"Training\"],\n",
    "                label=\"Training\",\n",
    "            )\n",
    "            x = range(1, len(self.loss_vals[\"Validation\"]) + 1)\n",
    "            self.loss_ax.plot(x, self.loss_vals[\"Validation\"], label=\"Validation\")\n",
    "            keys = sorted([k for k in self.sub_losses])\n",
    "            self.sub_loss_ax.stackplot(x, *[self.sub_losses[k] for k in keys], labels=keys)\n",
    "            self.loss_ax.plot([1 / self.n_trn_batches, x[-1]], [self.best_loss, self.best_loss], label=f\"Best = {self.best_loss:.3E}\", linestyle=\"--\")\n",
    "            self.loss_ax.legend(loc=\"upper right\", fontsize=0.8 * self.leg_sz)\n",
    "            self.sub_loss_ax.legend(loc=\"upper left\", fontsize=0.8 * self.leg_sz)\n",
    "            for ax in [self.loss_ax, self.sub_loss_ax]:\n",
    "                ax.grid(True, which=\"both\")\n",
    "                ax.set_xlim(1 / self.n_trn_batches, x[-1])\n",
    "            self.sub_loss_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "            self.loss_ax.set_ylabel(\"Loss\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "            self.sub_loss_ax.set_ylabel(\"Loss Composition\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "        if len(self.loss_vals[\"Validation\"]) > 1:\n",
    "            # Metrics\n",
    "            if self.main_metric_idx is not None:\n",
    "                self.metric_ax.clear()\n",
    "                with sns.axes_style(**self.style), sns.color_palette(self.cat_palette) as palette:\n",
    "                    x = range(self.n_trn_batches, self.n_trn_batches * len(self.loss_vals[\"Validation\"]) + 1, self.n_trn_batches)\n",
    "                    y = self.metric_vals[self.main_metric_idx]\n",
    "                    self.metric_ax.plot(x, y, color=palette[1])\n",
    "                    best = np.nanmin(y) if self.wrapper.fit_params.metric_cbs[self.main_metric_idx].lower_metric_better else np.nanmax(y)\n",
    "                    self.metric_ax.plot([1, x[-1]], [best, best], label=f\"Best = {best:.3E}\", linestyle=\"--\", color=palette[2])\n",
    "                    self.metric_ax.legend(loc=\"upper left\", fontsize=0.8 * self.leg_sz)\n",
    "                    self.metric_ax.grid(True, which=\"both\")\n",
    "                    self.metric_ax.set_xlim(1 / self.n_trn_batches, x[-1])\n",
    "                    self.metric_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                    self.metric_ax.set_ylabel(self.wrapper.fit_params.metric_cbs[self.main_metric_idx].name, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "    def on_train_end(self) -> None:\n",
    "        plt.clf()  # prevent plot be shown twice\n",
    "        self.metric_cbs = self.wrapper.fit_params.metric_cbs  # Copy referenece since fit_params gets set to None at end of training\n",
    "\n",
    "    def get_loss_history(self) -> Tuple[Dict[str, List[float]], Dict[str, List[float]]]:\n",
    "        r\"\"\"\n",
    "        Get the current history of losses and metrics\n",
    "\n",
    "        Returns:\n",
    "            history: tuple of ordered dictionaries: first with losses, second with validation metrics\n",
    "        \"\"\"\n",
    "\n",
    "        history: Tuple[Dict[str, List[float]], Dict[str, List[float]]] = ({}, {})\n",
    "        history[0][\"Training\"] = self.loss_vals[\"Training\"]\n",
    "        history[0][\"Validation\"] = self.loss_vals[\"Validation\"]\n",
    "        for v, c in zip(self.metric_vals, self.metric_cbs):\n",
    "            history[1][c.name] = v\n",
    "        return history\n",
    "\n",
    "    def get_results(self, loaded_best: bool) -> Dict[str, float]:\n",
    "        if loaded_best:\n",
    "            if self.lock_to_metric:\n",
    "                idx = (\n",
    "                    np.nanargmin(self.metric_vals[self.main_metric_idx])\n",
    "                    if self.metric_cbs[self.main_metric_idx].lower_metric_better\n",
    "                    else np.nanargmax(self.metric_vals[self.main_metric_idx])\n",
    "                )\n",
    "            else:\n",
    "                idx = np.nanargmin(self.loss_vals[\"Validation\"])\n",
    "        else:\n",
    "            idx = -1\n",
    "\n",
    "        results = {}\n",
    "        results[\"loss\"] = self.loss_vals[\"Validation\"][idx]\n",
    "        if len(self.metric_cbs) > 0:\n",
    "            for c, v in zip(self.metric_cbs, np.array(self.metric_vals)[:, idx]):\n",
    "                results[c.name] = v\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerMetricLogger(MetricLogger):\n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        self.n_dets = len(self.wrapper.get_detectors())\n",
    "        return self.fig.add_gridspec(5 + (self.main_metric_idx is None), self.n_dets)\n",
    "    \n",
    "    def _set_axes_labels(self) -> None:\n",
    "        for i in range(self.n_dets):\n",
    "            self.eff_axes[i].set_xlabel(f\"Det. {i}\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        self.res_axes[0].set_ylabel(\"Resolution\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        self.eff_axes[0].set_ylabel(\"Efficiency\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "    \n",
    "    def _prep_plots(self) -> None:\n",
    "        super()._prep_plots()\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.res_axes = [self.fig.add_subplot(self.grid_spec[-2:-1, i : i + 1]) for i in range(self.n_dets)]\n",
    "                self.eff_axes = [self.fig.add_subplot(self.grid_spec[-1:, i : i + 1]) for i in range(self.n_dets)]\n",
    "                self.res_cbar_ax = self.fig.add_axes([1.0, 0.04, 0.03, 0.31])\n",
    "                self.eff_cbar_ax = self.fig.add_axes([1.1, 0.04, 0.03, 0.31])\n",
    "                \n",
    "                \n",
    "    def update_plot(self) -> None:\n",
    "        super().update_plot()\n",
    "        with sns.axes_style(**self.style):\n",
    "            dets = self.wrapper.get_detectors()\n",
    "            res = np.array([l.resolution.data.cpu().numpy() for l in dets])\n",
    "            eff = np.array([l.efficiency.data.cpu().numpy() for l in dets])\n",
    "            res_min, res_max = res.min(), res.max()\n",
    "            eff_min, eff_max = eff.min(), eff.max()\n",
    "\n",
    "            for i, l in enumerate(dets):\n",
    "                self.res_axes[i].clear()\n",
    "                self.eff_axes[i].clear()\n",
    "                sns.heatmap(\n",
    "                    res[i],\n",
    "                    ax=self.res_axes[i],\n",
    "                    cmap=\"viridis\",\n",
    "                    square=True,\n",
    "                    cbar=(i == 0),\n",
    "                    vmin=res_min,\n",
    "                    vmax=res_max,\n",
    "                    cbar_ax=self.res_cbar_ax if i == 0 else None,\n",
    "                )\n",
    "                sns.heatmap(\n",
    "                    eff[i],\n",
    "                    ax=self.eff_axes[i],\n",
    "                    cmap=\"plasma\",\n",
    "                    square=True,\n",
    "                    cbar=(i == 0),\n",
    "                    vmin=eff_min,\n",
    "                    vmax=eff_max,\n",
    "                    cbar_ax=self.eff_cbar_ax if i == 0 else None,\n",
    "                )\n",
    "            self._set_axes_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "class PanelMetricLogger(MetricLogger):\n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        self.n_dets = len(self.wrapper.get_detectors())\n",
    "        return self.fig.add_gridspec(5 + (self.main_metric_idx is None), 3)\n",
    "    \n",
    "    def _set_axes_labels(self) -> None:\n",
    "        for ax, x in zip(self.below_det,['x','y','x']):\n",
    "            ax.set_xlabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        for i, (ax, x) in enumerate(zip(self.above_det,['z','z','y'])):\n",
    "            if i == 0:\n",
    "                x = 'Above, ' + x\n",
    "            ax.set_ylabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col) \n",
    "        for i, (ax, x) in enumerate(zip(self.below_det,['z','z','y'])):\n",
    "            if i == 0:\n",
    "                x = 'Below, ' + x\n",
    "            ax.set_ylabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "        for ax, det in zip((self.above_det,self.below_det), self.wrapper.get_detectors()):\n",
    "            lw,z = det.lw.detach().cpu(), det.z.detach().cpu()\n",
    "            ax[0].set_xlim(0, lw[0])\n",
    "            ax[1].set_xlim(0, lw[1])\n",
    "            ax[2].set_xlim(0,lw[0])\n",
    "            ax[0].set_ylim(z-det.size,z)\n",
    "            ax[1].set_ylim(z-det.size,z)\n",
    "            ax[2].set_ylim(0,lw[1])\n",
    "            ax[2].set_aspect('equal', 'box')\n",
    "    \n",
    "    def _prep_plots(self) -> None:\n",
    "        super()._prep_plots()\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.above_det = [self.fig.add_subplot(self.grid_spec[-2:-1, i : i + 1]) for i in range(3)]\n",
    "                self.below_det = [self.fig.add_subplot(self.grid_spec[-1:, i : i + 1]) for i in range(3)]\n",
    "                \n",
    "                    \n",
    "                self._set_axes_labels()\n",
    "                \n",
    "                \n",
    "    def update_plot(self) -> None:\n",
    "        super().update_plot()\n",
    "        with sns.axes_style(**self.style), sns.color_palette(self.cat_palette) as palette:\n",
    "            for axes, det in zip([self.above_det, self.below_det],self.wrapper.get_detectors()):\n",
    "                loc, span = [], []\n",
    "                for p in det.panels:\n",
    "                    loc.append(np.concatenate((p.xy.detach().cpu().numpy(),p.z.detach().cpu().numpy()[None])))\n",
    "                    span.append(p.xy_span.detach().cpu().numpy())\n",
    "                loc, span = np.array(loc), np.array(span)\n",
    "                    \n",
    "                for ax in axes: ax.clear()\n",
    "                for p in range(len(loc)):\n",
    "                    axes[0].add_line(mlines.Line2D((loc[p,0]-(span[p,0]/2),loc[p,0]+(span[p,0]/2)), (loc[p,2],loc[p,2]), color=palette[p]))  # xz\n",
    "                    axes[1].add_line(mlines.Line2D((loc[p,1]-(span[p,1]/2),loc[p,1]+(span[p,1]/2)), (loc[p,2],loc[p,2]), color=palette[p]))  # yz\n",
    "                    axes[2].add_patch(patches.Rectangle((loc[p,0]-(span[p,0]/2), loc[p,1]-(span[p,1]/2)), span[p,0], span[p,1],linewidth=1, edgecolor=palette[p], facecolor='none'))  # xy\n",
    "                                \n",
    "            self._set_axes_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = PanelVolumeWrapper(volume=volume, xy_pos_opt=partial(torch.optim.SGD, lr=2e-2), z_pos_opt=partial(torch.optim.SGD, lr=2e-4), xy_span_opt=partial(torch.optim.SGD, lr=2e-2),\n",
    "                             loss_func=PanelDetectorLoss(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = PanelMetricLogger(show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = wrapper.fit(25, n_mu_per_volume=1000, mu_bs=100, passive_bs=1, trn_passives=trn_passives, val_passives=trn_passives, cbs=[ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=1.0, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at xy=tensor([0.5000, 0.5000]), z=0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
