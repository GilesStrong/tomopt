{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.core import *\n",
    "from tomopt.optimisation import *\n",
    "from tomopt.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-edc514db5f58>:4: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:23.)\n",
      "  x = torch.linspace(-10, 100*100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96045328e0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def area_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/1000)**2\n",
    "\n",
    "x = torch.linspace(-10, 100*100)\n",
    "plt.plot(x, area_cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([0.5,0.5], requires_grad=True)\n",
    "s = torch.tensor([0.5,1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = torch.distributions.Normal(c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5353], grad_fn=<ProdBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(torch.exp(gauss.log_prob(Tensor([[0.5,0.5], [1,1]])))/torch.exp(gauss.log_prob(Tensor([0.5,0.5]))),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorPanel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        res: float,\n",
    "        eff: float,\n",
    "        init_xyz:Tuple[float,float,float],\n",
    "        init_xy_span: Tuple[float,float],\n",
    "        area_cost_func: Callable[[Tensor], Tensor],\n",
    "        device: torch.device = DEVICE\n",
    "    ):\n",
    "        if res <= 0:\n",
    "            raise ValueError(f'Resolution must be positive')\n",
    "        if eff <= 0:\n",
    "            raise ValueError(f'Efficiency must be positive')\n",
    "            \n",
    "        super().__init__()\n",
    "        self.area_cost_func, self.device = area_cost_func, device\n",
    "        self.register_buffer('resolution', torch.tensor(float(res), requires_grad=True, device=self.device))\n",
    "        self.register_buffer('efficiency', torch.tensor(float(eff), requires_grad=True, device=self.device))\n",
    "        self.xy = nn.Parameter(torch.tensor(init_xyz[:2], device=self.device))\n",
    "        self.z = nn.Parameter(torch.tensor(init_xyz[2], device=self.device))\n",
    "        self.xy_span = nn.Parameter(torch.tensor(init_xy_span, device=self.device))\n",
    "        self.realistic_validation = False\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'''{self.__class__} located at xy={self.xy.data}, z={self.z.data}, and xy span {self.xy_span.data}'''\n",
    "    \n",
    "    def get_xy_mask(self, xy: Tensor) -> Tensor:\n",
    "        xy_low = self.xy-(self.xy_span/2)\n",
    "        xy_high = self.xy+(self.xy_span/2)\n",
    "        return (xy[:,0] >= xy_low[0]) * (xy[:,0] < xy_high[0]) * (xy[:,1] >= xy_low[1]) * (xy[:,1] < xy_high[1])\n",
    "    \n",
    "    def get_gauss(self) -> torch.distributions.Normal:\n",
    "        try:\n",
    "            gauss = torch.distributions.Normal(self.xy, self.xy_span)  # maybe upscale span?\n",
    "        except ValueError:\n",
    "            print(f'Invalid parameters for Gaussian: loc={self.xy}, scale={self.xy_span}'); assert False\n",
    "    \n",
    "    def get_resolution(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training or not self.realistic_validation:\n",
    "            g = self.get_gauss()\n",
    "            res = self.resolution*torch.exp(g.log_prob(xy))/torch.exp(g.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            res = torch.zeros((len(xy),2), device=self.device)  # Zero detection outside detector\n",
    "            res[mask] = self.resolution\n",
    "        return res\n",
    "    \n",
    "    def get_efficiency(self, xy:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "        if self.training or not self.realistic_validation:\n",
    "            g = self.get_gauss()\n",
    "            scale = torch.exp(g.log_prob(xy))/torch.exp(g.log_prob(self.xy))  # Maybe detach the normalisation?\n",
    "            eff = self.efficiency*torch.prod(scale, dim=-1)  # Maybe weight product by xy distance?\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.get_xy_mask(xy)\n",
    "            eff = torch.zeros(len(xy), device=self.device)  # Zero detection outside detector\n",
    "            eff[mask] = self.efficiency\n",
    "        return eff\n",
    "        \n",
    "    def get_hits(self, mu: MuonBatch) -> Dict[str, Tensor]:\n",
    "        mask = mu.get_xy_mask(self.xy-(self.xy_span/2), self.xy+(self.xy_span/2))  # Muons in panel\n",
    "        \n",
    "        xy0 = self.xy-(self.xy_span/2)  # Low-left of voxel\n",
    "        rel_xy = mu.xy - xy0\n",
    "        res = self.get_resolution(mu.xy, mask)        \n",
    "        rel_xy = rel_xy + (torch.randn((len(mu), 2), device=self.device) / res)\n",
    "        \n",
    "        if not self.training and self.realistic_validation:  # Prevent reco hit from exiting panel\n",
    "            span = self.xy_span.detach().cpu().numpy()\n",
    "            rel_xy[mask] = torch.stack([torch.clamp(rel_xy[mask][:,0], 0, span[0]),\n",
    "                                        torch.clamp(rel_xy[mask][:,1], 0, span[1])], dim=-1)  \n",
    "        reco_xy = xy0 + rel_xy\n",
    "\n",
    "        hits = {\n",
    "            \"reco_xy\": reco_xy,\n",
    "            \"gen_xy\": mu.xy.detach().clone(),\n",
    "            \"z\": self.z.expand_as(mu.x)[:, None],\n",
    "        }\n",
    "        return hits\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        return self.area_cost_func(self.xy_span.prod())\n",
    "    \n",
    "    def clamp_params(self, xyz_low:Tuple[float,float,float], xyz_high:Tuple[float,float,float]) -> None:\n",
    "        with torch.no_grad():\n",
    "            eps = np.random.uniform(0, 1e-5)  # prevent hits at same z due to clamping\n",
    "            torch.clamp_(self.x, min=xyz_low[0], max=xyz_high[0])\n",
    "            torch.clamp_(self.y, min=xyz_low[1], max=xyz_high[1])\n",
    "            torch.clamp_(self.z, min=xyz_low[2]+eps, max=xyz_high[2]-eps)\n",
    "            torch.clamp_(self.xy_span[0], min=1e-7, max=xyz_high[0])\n",
    "            torch.clamp_(self.xy_span[1], min=1e-7, max=xyz_high[1])\n",
    "    \n",
    "    @property\n",
    "    def x(self) -> Tensor:\n",
    "        return self.xy[0]\n",
    "    \n",
    "    @property\n",
    "    def y(self) -> Tensor:\n",
    "        return self.xy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.volume.layer import Layer\n",
    "\n",
    "class DetectorLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pos: str,\n",
    "        lw: Tensor,\n",
    "        z: float,\n",
    "        size: float,\n",
    "        panels: nn.ModuleList,\n",
    "        device: torch.device = DEVICE,\n",
    "    ):\n",
    "        super().__init__(lw=lw, z=z, size=size, device=device)\n",
    "        if isinstance(panels, list):\n",
    "            panels = nn.ModuleList(panels)\n",
    "        self.pos, self.panels = pos, panels\n",
    "    \n",
    "    def get_panel_zorder(self) -> List[int]:\n",
    "        return np.argsort([p.z.detach().cpu().item() for p in self.panels])[::-1]\n",
    "        \n",
    "    def check_panels(self) -> None:\n",
    "        lw = self.lw.detach().cpu().numpy()\n",
    "        z = self.z.detach().cpu()[0]\n",
    "        for p in self.panels:\n",
    "            p.clamp_params(xyz_low=(0,0,z-self.size), xyz_high=(lw[0],lw[1],z))\n",
    "                \n",
    "    def forward(self, mu: MuonBatch) -> None:\n",
    "        self.check_panels()\n",
    "        for i in self.get_panel_zorder():\n",
    "            self.scatter_and_propagate(mu, mu.z-self.panels[i].z)  # Move to panel\n",
    "            mu.append_hits(self.panels[i].get_hits(mu), self.pos)\n",
    "        self.scatter_and_propagate(mu, mu.z-(self.z-self.size))  # Move to bottom of layer\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        for i, p in enumerate(self.panels):\n",
    "            cost = p.get_cost() if i == 0 else cost + p.get_cost()\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = nn.ModuleList([DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,0.95], init_xy_span=[0.5,0.5], area_cost_func=area_cost),\n",
    "                        DetectorPanel(res=1e4, eff=0.5, init_xyz=[0.5,0.5,1.], init_xy_span=[0.5,0.5], area_cost_func=area_cost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reco_xy': tensor([[0.8973, 0.4073],\n",
       "         [0.5250, 0.7608],\n",
       "         [0.7982, 0.6155],\n",
       "         [0.9392, 0.0487],\n",
       "         [0.5976, 0.9449],\n",
       "         [0.4083, 0.6498],\n",
       "         [0.7201, 0.1791],\n",
       "         [0.9437, 0.7921],\n",
       "         [0.5835, 0.9122],\n",
       "         [0.0061, 0.0390],\n",
       "         [0.7063, 0.5499],\n",
       "         [0.8658, 0.8051],\n",
       "         [0.5079, 0.4265],\n",
       "         [0.6317, 0.1085],\n",
       "         [0.5844, 0.0932],\n",
       "         [0.2250, 0.9164],\n",
       "         [0.0533, 0.0522],\n",
       "         [0.7400, 0.4314],\n",
       "         [0.7084, 0.7277],\n",
       "         [0.2627, 0.5234],\n",
       "         [0.8171, 0.0421],\n",
       "         [0.7113, 0.0053],\n",
       "         [0.3516, 0.2912],\n",
       "         [0.8202, 0.1743],\n",
       "         [0.3227, 0.9718],\n",
       "         [0.8886, 0.7544],\n",
       "         [0.0496, 0.1481],\n",
       "         [0.1770, 0.1612],\n",
       "         [0.6630, 0.9790],\n",
       "         [0.7614, 0.8689],\n",
       "         [0.3946, 0.6670],\n",
       "         [0.6121, 0.1009],\n",
       "         [0.0380, 0.9333],\n",
       "         [0.4453, 0.7579],\n",
       "         [0.9807, 0.0821],\n",
       "         [0.0452, 0.7657],\n",
       "         [0.6163, 0.7916],\n",
       "         [0.5007, 0.4061],\n",
       "         [0.0020, 0.3119],\n",
       "         [0.9451, 0.5747],\n",
       "         [0.0151, 0.4770],\n",
       "         [0.2290, 0.8903],\n",
       "         [0.5300, 0.8781],\n",
       "         [0.3258, 0.0619],\n",
       "         [0.8981, 0.9191],\n",
       "         [0.9622, 0.3591],\n",
       "         [0.4825, 0.6333],\n",
       "         [0.1008, 0.9502],\n",
       "         [0.4043, 0.7221],\n",
       "         [0.9990, 0.8442],\n",
       "         [0.8619, 0.6109],\n",
       "         [0.8221, 0.3990],\n",
       "         [0.1519, 0.7356],\n",
       "         [0.8969, 0.9153],\n",
       "         [0.7459, 0.2227],\n",
       "         [0.2458, 0.9150],\n",
       "         [0.2089, 0.0700],\n",
       "         [0.4067, 0.3109],\n",
       "         [0.1391, 0.6088],\n",
       "         [0.5445, 0.2467],\n",
       "         [0.6018, 0.1898],\n",
       "         [0.2975, 0.4845],\n",
       "         [0.0333, 0.6616],\n",
       "         [0.0668, 0.7232],\n",
       "         [0.4202, 0.9714],\n",
       "         [0.4071, 0.6916],\n",
       "         [0.8631, 0.3785],\n",
       "         [0.7122, 0.1024],\n",
       "         [0.3439, 0.4764],\n",
       "         [0.0915, 0.8873],\n",
       "         [0.6305, 0.9024],\n",
       "         [0.2557, 0.1517],\n",
       "         [0.3240, 0.6713],\n",
       "         [0.1883, 0.8008],\n",
       "         [0.8695, 0.3077],\n",
       "         [0.0560, 0.0598],\n",
       "         [0.8508, 0.9581],\n",
       "         [0.4543, 0.6233],\n",
       "         [0.7713, 0.1839],\n",
       "         [0.0928, 0.6615],\n",
       "         [0.2951, 0.1592],\n",
       "         [0.2651, 0.9657],\n",
       "         [0.7442, 0.4399],\n",
       "         [0.9500, 0.1655],\n",
       "         [0.0725, 0.0653],\n",
       "         [0.8681, 0.9722],\n",
       "         [0.6509, 0.2170],\n",
       "         [0.7020, 0.0665],\n",
       "         [0.4679, 0.7731],\n",
       "         [0.2633, 0.2329],\n",
       "         [0.9108, 0.5782],\n",
       "         [0.6638, 0.0843],\n",
       "         [0.2713, 0.7872],\n",
       "         [0.4051, 0.8215],\n",
       "         [0.9838, 0.6887],\n",
       "         [0.0535, 0.7671],\n",
       "         [0.8252, 0.3498],\n",
       "         [0.7643, 0.3919],\n",
       "         [0.0849, 0.8917],\n",
       "         [0.7120, 0.1405]], grad_fn=<AddBackward0>),\n",
       " 'gen_xy': tensor([[0.8973, 0.4071],\n",
       "         [0.5250, 0.7606],\n",
       "         [0.7984, 0.6154],\n",
       "         [0.9390, 0.0484],\n",
       "         [0.5976, 0.9450],\n",
       "         [0.4081, 0.6498],\n",
       "         [0.7201, 0.1792],\n",
       "         [0.9436, 0.7921],\n",
       "         [0.5837, 0.9124],\n",
       "         [0.0061, 0.0390],\n",
       "         [0.7061, 0.5498],\n",
       "         [0.8658, 0.8052],\n",
       "         [0.5078, 0.4265],\n",
       "         [0.6318, 0.1088],\n",
       "         [0.5845, 0.0932],\n",
       "         [0.2250, 0.9162],\n",
       "         [0.0532, 0.0521],\n",
       "         [0.7399, 0.4315],\n",
       "         [0.7083, 0.7276],\n",
       "         [0.2628, 0.5234],\n",
       "         [0.8171, 0.0423],\n",
       "         [0.7114, 0.0055],\n",
       "         [0.3516, 0.2910],\n",
       "         [0.8201, 0.1743],\n",
       "         [0.3228, 0.9716],\n",
       "         [0.8885, 0.7546],\n",
       "         [0.0495, 0.1483],\n",
       "         [0.1770, 0.1612],\n",
       "         [0.6630, 0.9790],\n",
       "         [0.7613, 0.8689],\n",
       "         [0.3948, 0.6670],\n",
       "         [0.6122, 0.1011],\n",
       "         [0.0379, 0.9331],\n",
       "         [0.4454, 0.7579],\n",
       "         [0.9807, 0.0820],\n",
       "         [0.0453, 0.7657],\n",
       "         [0.6164, 0.7912],\n",
       "         [0.5008, 0.4060],\n",
       "         [0.0016, 0.3117],\n",
       "         [0.9452, 0.5749],\n",
       "         [0.0151, 0.4769],\n",
       "         [0.2291, 0.8904],\n",
       "         [0.5300, 0.8783],\n",
       "         [0.3258, 0.0618],\n",
       "         [0.8981, 0.9192],\n",
       "         [0.9623, 0.3592],\n",
       "         [0.4825, 0.6331],\n",
       "         [0.1007, 0.9503],\n",
       "         [0.4043, 0.7220],\n",
       "         [0.9990, 0.8440],\n",
       "         [0.8620, 0.6108],\n",
       "         [0.8220, 0.3988],\n",
       "         [0.1519, 0.7357],\n",
       "         [0.8968, 0.9152],\n",
       "         [0.7460, 0.2227],\n",
       "         [0.2459, 0.9148],\n",
       "         [0.2089, 0.0699],\n",
       "         [0.4068, 0.3108],\n",
       "         [0.1390, 0.6087],\n",
       "         [0.5447, 0.2466],\n",
       "         [0.6018, 0.1900],\n",
       "         [0.2976, 0.4843],\n",
       "         [0.0333, 0.6616],\n",
       "         [0.0667, 0.7231],\n",
       "         [0.4202, 0.9716],\n",
       "         [0.4071, 0.6915],\n",
       "         [0.8632, 0.3785],\n",
       "         [0.7122, 0.1022],\n",
       "         [0.3439, 0.4765],\n",
       "         [0.0915, 0.8874],\n",
       "         [0.6304, 0.9023],\n",
       "         [0.2557, 0.1518],\n",
       "         [0.3239, 0.6711],\n",
       "         [0.1884, 0.8008],\n",
       "         [0.8694, 0.3077],\n",
       "         [0.0562, 0.0599],\n",
       "         [0.8509, 0.9582],\n",
       "         [0.4544, 0.6231],\n",
       "         [0.7714, 0.1842],\n",
       "         [0.0929, 0.6613],\n",
       "         [0.2952, 0.1595],\n",
       "         [0.2650, 0.9656],\n",
       "         [0.7442, 0.4399],\n",
       "         [0.9500, 0.1653],\n",
       "         [0.0725, 0.0652],\n",
       "         [0.8678, 0.9721],\n",
       "         [0.6508, 0.2169],\n",
       "         [0.7020, 0.0666],\n",
       "         [0.4680, 0.7730],\n",
       "         [0.2633, 0.2330],\n",
       "         [0.9107, 0.5782],\n",
       "         [0.6636, 0.0844],\n",
       "         [0.2712, 0.7871],\n",
       "         [0.4052, 0.8214],\n",
       "         [0.9840, 0.6885],\n",
       "         [0.0534, 0.7670],\n",
       "         [0.8253, 0.3498],\n",
       "         [0.7644, 0.3920],\n",
       "         [0.0849, 0.8916],\n",
       "         [0.7120, 0.1403]]),\n",
       " 'z': tensor([[0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500],\n",
       "         [0.9500]], grad_fn=<UnsqueezeBackward0>)}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panels[0].get_hits(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DetectorLayer(pos='above', lw=Tensor([1,1]), z=1, size=0.1, panels=panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2500e-07, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.get_panel_zorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 1.0, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tomopt.muon.muon_batch.MuonBatch.__init__.<locals>.<lambda>()>,\n",
       "            {'above': defaultdict(list,\n",
       "                         {'reco_xy': [tensor([[0.4105, 0.9506],\n",
       "                                   [0.2919, 0.3622],\n",
       "                                   [0.6097, 0.5324],\n",
       "                                   [0.3960, 0.9511],\n",
       "                                   [0.4734, 0.2135],\n",
       "                                   [0.1821, 0.1797],\n",
       "                                   [0.6343, 0.7598],\n",
       "                                   [0.9894, 0.0986],\n",
       "                                   [0.3118, 0.5467],\n",
       "                                   [0.3436, 0.1743],\n",
       "                                   [0.2483, 0.4557],\n",
       "                                   [0.6879, 0.9161],\n",
       "                                   [0.7130, 0.9538],\n",
       "                                   [0.6582, 0.4397],\n",
       "                                   [0.9477, 0.0879],\n",
       "                                   [0.1584, 0.6740],\n",
       "                                   [0.5655, 0.8490],\n",
       "                                   [0.2552, 0.0717],\n",
       "                                   [0.3635, 0.8581],\n",
       "                                   [0.7045, 0.3347],\n",
       "                                   [0.1003, 0.2389],\n",
       "                                   [0.3417, 0.4565],\n",
       "                                   [0.8449, 0.2267],\n",
       "                                   [0.0660, 0.6455],\n",
       "                                   [0.8500, 0.6194],\n",
       "                                   [0.7842, 0.7211],\n",
       "                                   [0.4739, 0.5327],\n",
       "                                   [0.6932, 0.2235],\n",
       "                                   [0.3338, 0.6829],\n",
       "                                   [0.2110, 0.8792],\n",
       "                                   [0.5363, 0.8921],\n",
       "                                   [0.0552, 0.0051],\n",
       "                                   [0.4365, 0.6344],\n",
       "                                   [0.5468, 0.8888],\n",
       "                                   [0.4728, 0.7597],\n",
       "                                   [0.9559, 0.2005],\n",
       "                                   [0.7959, 0.2880],\n",
       "                                   [0.6420, 0.7157],\n",
       "                                   [0.5596, 0.5857],\n",
       "                                   [0.3902, 0.2725],\n",
       "                                   [0.5727, 0.6037],\n",
       "                                   [0.4979, 0.3518],\n",
       "                                   [0.6194, 0.2951],\n",
       "                                   [0.6050, 0.7405],\n",
       "                                   [0.5563, 0.7752],\n",
       "                                   [0.5956, 0.6213],\n",
       "                                   [0.5110, 0.3527],\n",
       "                                   [0.5537, 0.7282],\n",
       "                                   [0.1036, 0.9353],\n",
       "                                   [0.5337, 0.5712],\n",
       "                                   [0.3718, 0.0646],\n",
       "                                   [0.6946, 0.0558],\n",
       "                                   [0.5369, 0.2629],\n",
       "                                   [0.3955, 0.2663],\n",
       "                                   [0.7776, 0.1121],\n",
       "                                   [0.3436, 0.7151],\n",
       "                                   [0.9529, 0.6989],\n",
       "                                   [0.3294, 0.1123],\n",
       "                                   [0.0480, 0.1328],\n",
       "                                   [0.6558, 0.9855],\n",
       "                                   [0.1195, 0.6209],\n",
       "                                   [0.6337, 0.5741],\n",
       "                                   [0.3076, 0.5861],\n",
       "                                   [0.1454, 0.1196],\n",
       "                                   [0.4453, 0.1859],\n",
       "                                   [0.7762, 0.5541],\n",
       "                                   [0.0500, 0.4922],\n",
       "                                   [0.7794, 0.9601],\n",
       "                                   [0.3628, 0.8950],\n",
       "                                   [0.3882, 0.3553],\n",
       "                                   [0.6496, 0.4450],\n",
       "                                   [0.0427, 0.7969],\n",
       "                                   [0.3153, 0.2731],\n",
       "                                   [0.1757, 0.4509],\n",
       "                                   [0.1085, 0.3031],\n",
       "                                   [0.7125, 0.6625],\n",
       "                                   [0.9791, 0.1916],\n",
       "                                   [0.1540, 0.2015],\n",
       "                                   [0.3962, 0.7410],\n",
       "                                   [0.3217, 0.6257],\n",
       "                                   [0.2108, 0.5961],\n",
       "                                   [0.9939, 0.1838],\n",
       "                                   [0.8980, 0.0849],\n",
       "                                   [0.9524, 0.5375],\n",
       "                                   [0.6734, 0.2265],\n",
       "                                   [0.5479, 0.7058],\n",
       "                                   [0.7486, 0.0205],\n",
       "                                   [0.3244, 0.7832],\n",
       "                                   [0.0111, 0.5040],\n",
       "                                   [0.9592, 0.7962],\n",
       "                                   [0.9002, 0.1298],\n",
       "                                   [0.7008, 0.3084],\n",
       "                                   [0.5270, 0.3324],\n",
       "                                   [0.4545, 0.5100],\n",
       "                                   [0.3229, 0.2103],\n",
       "                                   [0.1702, 0.8478],\n",
       "                                   [0.9118, 0.2579],\n",
       "                                   [0.6509, 0.4614],\n",
       "                                   [0.3190, 0.8559],\n",
       "                                   [0.4793, 0.2923]], grad_fn=<AddBackward0>),\n",
       "                           tensor([[0.4061, 0.9426],\n",
       "                                   [0.2956, 0.3599],\n",
       "                                   [0.6101, 0.5335],\n",
       "                                   [0.3983, 0.9443],\n",
       "                                   [0.4790, 0.2114],\n",
       "                                   [0.1769, 0.1890],\n",
       "                                   [0.6317, 0.7535],\n",
       "                                   [0.9869, 0.0912],\n",
       "                                   [0.3147, 0.5422],\n",
       "                                   [0.3409, 0.1797],\n",
       "                                   [0.2501, 0.4523],\n",
       "                                   [0.6823, 0.9172],\n",
       "                                   [0.7168, 0.9431],\n",
       "                                   [0.6624, 0.4389],\n",
       "                                   [0.9441, 0.0839],\n",
       "                                   [0.1674, 0.6723],\n",
       "                                   [0.5733, 0.8460],\n",
       "                                   [0.2653, 0.0722],\n",
       "                                   [0.3665, 0.8574],\n",
       "                                   [0.7008, 0.3350],\n",
       "                                   [0.1048, 0.2557],\n",
       "                                   [0.3366, 0.4536],\n",
       "                                   [0.8477, 0.2383],\n",
       "                                   [0.0627, 0.6452],\n",
       "                                   [0.8499, 0.6142],\n",
       "                                   [0.7842, 0.7132],\n",
       "                                   [0.4692, 0.5422],\n",
       "                                   [0.6950, 0.2273],\n",
       "                                   [0.3336, 0.6834],\n",
       "                                   [0.2157, 0.8798],\n",
       "                                   [0.5381, 0.8983],\n",
       "                                   [0.0472, 0.0097],\n",
       "                                   [0.4348, 0.6412],\n",
       "                                   [0.5431, 0.8877],\n",
       "                                   [0.4721, 0.7633],\n",
       "                                   [0.9637, 0.1953],\n",
       "                                   [0.7988, 0.2884],\n",
       "                                   [0.6411, 0.7159],\n",
       "                                   [0.5589, 0.5884],\n",
       "                                   [0.3842, 0.2708],\n",
       "                                   [0.5699, 0.5988],\n",
       "                                   [0.4946, 0.3428],\n",
       "                                   [0.6175, 0.2854],\n",
       "                                   [0.6130, 0.7398],\n",
       "                                   [0.5583, 0.7690],\n",
       "                                   [0.5899, 0.6181],\n",
       "                                   [0.5228, 0.3515],\n",
       "                                   [0.5407, 0.7204],\n",
       "                                   [0.1050, 0.9369],\n",
       "                                   [0.5386, 0.5722],\n",
       "                                   [0.3733, 0.0593],\n",
       "                                   [0.6873, 0.0492],\n",
       "                                   [0.5377, 0.2707],\n",
       "                                   [0.4010, 0.2666],\n",
       "                                   [0.7755, 0.1130],\n",
       "                                   [0.3353, 0.7170],\n",
       "                                   [0.9547, 0.6983],\n",
       "                                   [0.3305, 0.1035],\n",
       "                                   [0.0501, 0.1285],\n",
       "                                   [0.6544, 0.9909],\n",
       "                                   [0.1218, 0.6200],\n",
       "                                   [0.6346, 0.5670],\n",
       "                                   [0.3082, 0.5891],\n",
       "                                   [0.1489, 0.1136],\n",
       "                                   [0.4368, 0.1828],\n",
       "                                   [0.7791, 0.5585],\n",
       "                                   [0.0521, 0.4874],\n",
       "                                   [0.7788, 0.9564],\n",
       "                                   [0.3612, 0.8948],\n",
       "                                   [0.3877, 0.3497],\n",
       "                                   [0.6575, 0.4461],\n",
       "                                   [0.0498, 0.8063],\n",
       "                                   [0.3131, 0.2759],\n",
       "                                   [0.1749, 0.4528],\n",
       "                                   [0.1051, 0.2971],\n",
       "                                   [0.7143, 0.6666],\n",
       "                                   [0.9849, 0.1911],\n",
       "                                   [0.1609, 0.2016],\n",
       "                                   [0.3950, 0.7370],\n",
       "                                   [0.3186, 0.6277],\n",
       "                                   [0.2033, 0.5946],\n",
       "                                   [0.9940, 0.1781],\n",
       "                                   [0.8983, 0.0780],\n",
       "                                   [0.9543, 0.5450],\n",
       "                                   [0.6708, 0.2315],\n",
       "                                   [0.5602, 0.7125],\n",
       "                                   [0.7533, 0.0227],\n",
       "                                   [0.3154, 0.7844],\n",
       "                                   [0.0203, 0.5038],\n",
       "                                   [0.9615, 0.7908],\n",
       "                                   [0.9100, 0.1219],\n",
       "                                   [0.7135, 0.3184],\n",
       "                                   [0.5203, 0.3259],\n",
       "                                   [0.4556, 0.5099],\n",
       "                                   [0.3284, 0.2017],\n",
       "                                   [0.1664, 0.8514],\n",
       "                                   [0.9214, 0.2508],\n",
       "                                   [0.6427, 0.4677],\n",
       "                                   [0.3217, 0.8554],\n",
       "                                   [0.4783, 0.2863]], grad_fn=<AddBackward0>)],\n",
       "                          'gen_xy': [tensor([[0.4104, 0.9505],\n",
       "                                   [0.2920, 0.3623],\n",
       "                                   [0.6098, 0.5324],\n",
       "                                   [0.3961, 0.9509],\n",
       "                                   [0.4735, 0.2132],\n",
       "                                   [0.1820, 0.1795],\n",
       "                                   [0.6345, 0.7599],\n",
       "                                   [0.9895, 0.0986],\n",
       "                                   [0.3118, 0.5467],\n",
       "                                   [0.3434, 0.1742],\n",
       "                                   [0.2482, 0.4556],\n",
       "                                   [0.6879, 0.9161],\n",
       "                                   [0.7130, 0.9538],\n",
       "                                   [0.6582, 0.4399],\n",
       "                                   [0.9478, 0.0877],\n",
       "                                   [0.1583, 0.6741],\n",
       "                                   [0.5658, 0.8492],\n",
       "                                   [0.2552, 0.0718],\n",
       "                                   [0.3634, 0.8580],\n",
       "                                   [0.7043, 0.3349],\n",
       "                                   [0.1001, 0.2390],\n",
       "                                   [0.3416, 0.4565],\n",
       "                                   [0.8449, 0.2266],\n",
       "                                   [0.0662, 0.6455],\n",
       "                                   [0.8499, 0.6195],\n",
       "                                   [0.7841, 0.7212],\n",
       "                                   [0.4740, 0.5328],\n",
       "                                   [0.6934, 0.2235],\n",
       "                                   [0.3337, 0.6827],\n",
       "                                   [0.2112, 0.8791],\n",
       "                                   [0.5362, 0.8924],\n",
       "                                   [0.0552, 0.0050],\n",
       "                                   [0.4362, 0.6344],\n",
       "                                   [0.5470, 0.8887],\n",
       "                                   [0.4730, 0.7596],\n",
       "                                   [0.9560, 0.2007],\n",
       "                                   [0.7960, 0.2881],\n",
       "                                   [0.6421, 0.7157],\n",
       "                                   [0.5598, 0.5858],\n",
       "                                   [0.3902, 0.2726],\n",
       "                                   [0.5729, 0.6037],\n",
       "                                   [0.4978, 0.3519],\n",
       "                                   [0.6194, 0.2950],\n",
       "                                   [0.6051, 0.7403],\n",
       "                                   [0.5564, 0.7751],\n",
       "                                   [0.5955, 0.6212],\n",
       "                                   [0.5109, 0.3527],\n",
       "                                   [0.5537, 0.7282],\n",
       "                                   [0.1035, 0.9353],\n",
       "                                   [0.5337, 0.5712],\n",
       "                                   [0.3718, 0.0643],\n",
       "                                   [0.6945, 0.0558],\n",
       "                                   [0.5369, 0.2631],\n",
       "                                   [0.3955, 0.2662],\n",
       "                                   [0.7777, 0.1120],\n",
       "                                   [0.3436, 0.7149],\n",
       "                                   [0.9528, 0.6991],\n",
       "                                   [0.3292, 0.1123],\n",
       "                                   [0.0480, 0.1329],\n",
       "                                   [0.6557, 0.9855],\n",
       "                                   [0.1196, 0.6211],\n",
       "                                   [0.6337, 0.5740],\n",
       "                                   [0.3076, 0.5861],\n",
       "                                   [0.1455, 0.1194],\n",
       "                                   [0.4452, 0.1858],\n",
       "                                   [0.7764, 0.5542],\n",
       "                                   [0.0502, 0.4922],\n",
       "                                   [0.7794, 0.9598],\n",
       "                                   [0.3629, 0.8948],\n",
       "                                   [0.3883, 0.3552],\n",
       "                                   [0.6496, 0.4449],\n",
       "                                   [0.0427, 0.7970],\n",
       "                                   [0.3152, 0.2730],\n",
       "                                   [0.1756, 0.4508],\n",
       "                                   [0.1086, 0.3032],\n",
       "                                   [0.7126, 0.6623],\n",
       "                                   [0.9789, 0.1915],\n",
       "                                   [0.1540, 0.2016],\n",
       "                                   [0.3960, 0.7410],\n",
       "                                   [0.3216, 0.6257],\n",
       "                                   [0.2110, 0.5962],\n",
       "                                   [0.9938, 0.1840],\n",
       "                                   [0.8978, 0.0848],\n",
       "                                   [0.9522, 0.5375],\n",
       "                                   [0.6733, 0.2264],\n",
       "                                   [0.5479, 0.7058],\n",
       "                                   [0.7486, 0.0203],\n",
       "                                   [0.3243, 0.7833],\n",
       "                                   [0.0114, 0.5039],\n",
       "                                   [0.9591, 0.7960],\n",
       "                                   [0.9001, 0.1298],\n",
       "                                   [0.7006, 0.3083],\n",
       "                                   [0.5271, 0.3325],\n",
       "                                   [0.4544, 0.5100],\n",
       "                                   [0.3229, 0.2102],\n",
       "                                   [0.1703, 0.8478],\n",
       "                                   [0.9117, 0.2579],\n",
       "                                   [0.6509, 0.4613],\n",
       "                                   [0.3190, 0.8559],\n",
       "                                   [0.4793, 0.2923]]),\n",
       "                           tensor([[0.4060, 0.9428],\n",
       "                                   [0.2956, 0.3601],\n",
       "                                   [0.6100, 0.5336],\n",
       "                                   [0.3983, 0.9442],\n",
       "                                   [0.4789, 0.2113],\n",
       "                                   [0.1770, 0.1889],\n",
       "                                   [0.6316, 0.7536],\n",
       "                                   [0.9865, 0.0911],\n",
       "                                   [0.3147, 0.5422],\n",
       "                                   [0.3409, 0.1798],\n",
       "                                   [0.2500, 0.4523],\n",
       "                                   [0.6822, 0.9172],\n",
       "                                   [0.7168, 0.9432],\n",
       "                                   [0.6623, 0.4388],\n",
       "                                   [0.9442, 0.0840],\n",
       "                                   [0.1671, 0.6722],\n",
       "                                   [0.5733, 0.8459],\n",
       "                                   [0.2651, 0.0720],\n",
       "                                   [0.3666, 0.8573],\n",
       "                                   [0.7009, 0.3350],\n",
       "                                   [0.1048, 0.2559],\n",
       "                                   [0.3368, 0.4536],\n",
       "                                   [0.8477, 0.2383],\n",
       "                                   [0.0628, 0.6450],\n",
       "                                   [0.8501, 0.6142],\n",
       "                                   [0.7840, 0.7131],\n",
       "                                   [0.4691, 0.5422],\n",
       "                                   [0.6950, 0.2273],\n",
       "                                   [0.3338, 0.6834],\n",
       "                                   [0.2158, 0.8798],\n",
       "                                   [0.5381, 0.8984],\n",
       "                                   [0.0472, 0.0101],\n",
       "                                   [0.4348, 0.6413],\n",
       "                                   [0.5431, 0.8878],\n",
       "                                   [0.4721, 0.7634],\n",
       "                                   [0.9638, 0.1952],\n",
       "                                   [0.7987, 0.2883],\n",
       "                                   [0.6410, 0.7160],\n",
       "                                   [0.5588, 0.5885],\n",
       "                                   [0.3843, 0.2708],\n",
       "                                   [0.5700, 0.5987],\n",
       "                                   [0.4947, 0.3428],\n",
       "                                   [0.6174, 0.2855],\n",
       "                                   [0.6130, 0.7397],\n",
       "                                   [0.5584, 0.7688],\n",
       "                                   [0.5900, 0.6180],\n",
       "                                   [0.5228, 0.3517],\n",
       "                                   [0.5407, 0.7204],\n",
       "                                   [0.1052, 0.9368],\n",
       "                                   [0.5386, 0.5724],\n",
       "                                   [0.3732, 0.0594],\n",
       "                                   [0.6874, 0.0493],\n",
       "                                   [0.5377, 0.2707],\n",
       "                                   [0.4013, 0.2664],\n",
       "                                   [0.7755, 0.1130],\n",
       "                                   [0.3354, 0.7173],\n",
       "                                   [0.9547, 0.6981],\n",
       "                                   [0.3305, 0.1033],\n",
       "                                   [0.0499, 0.1285],\n",
       "                                   [0.6544, 0.9911],\n",
       "                                   [0.1217, 0.6199],\n",
       "                                   [0.6346, 0.5670],\n",
       "                                   [0.3083, 0.5891],\n",
       "                                   [0.1487, 0.1138],\n",
       "                                   [0.4367, 0.1828],\n",
       "                                   [0.7790, 0.5584],\n",
       "                                   [0.0523, 0.4874],\n",
       "                                   [0.7787, 0.9565],\n",
       "                                   [0.3611, 0.8947],\n",
       "                                   [0.3876, 0.3498],\n",
       "                                   [0.6574, 0.4462],\n",
       "                                   [0.0497, 0.8060],\n",
       "                                   [0.3131, 0.2760],\n",
       "                                   [0.1748, 0.4529],\n",
       "                                   [0.1050, 0.2971],\n",
       "                                   [0.7143, 0.6665],\n",
       "                                   [0.9848, 0.1910],\n",
       "                                   [0.1609, 0.2015],\n",
       "                                   [0.3949, 0.7369],\n",
       "                                   [0.3183, 0.6276],\n",
       "                                   [0.2034, 0.5946],\n",
       "                                   [0.9940, 0.1781],\n",
       "                                   [0.8985, 0.0778],\n",
       "                                   [0.9540, 0.5450],\n",
       "                                   [0.6709, 0.2315],\n",
       "                                   [0.5601, 0.7126],\n",
       "                                   [0.7534, 0.0227],\n",
       "                                   [0.3154, 0.7845],\n",
       "                                   [0.0204, 0.5037],\n",
       "                                   [0.9615, 0.7910],\n",
       "                                   [0.9099, 0.1219],\n",
       "                                   [0.7132, 0.3183],\n",
       "                                   [0.5203, 0.3258],\n",
       "                                   [0.4556, 0.5098],\n",
       "                                   [0.3284, 0.2017],\n",
       "                                   [0.1665, 0.8515],\n",
       "                                   [0.9215, 0.2507],\n",
       "                                   [0.6427, 0.4677],\n",
       "                                   [0.3217, 0.8554],\n",
       "                                   [0.4783, 0.2864]])],\n",
       "                          'z': [tensor([[1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000],\n",
       "                                   [1.0000]], grad_fn=<UnsqueezeBackward0>),\n",
       "                           tensor([[0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500],\n",
       "                                   [0.9500]], grad_fn=<UnsqueezeBackward0>)]})})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muons.hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    n_panels = 4\n",
    "    layers.append(DetectorLayer(pos='above', lw=lwh[:2], z=1, size=2*size,\n",
    "                                panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,1-(i*(2*size)/n_panels)], init_xy_span=[0.5,0.5],\n",
    "                                                      area_cost_func=area_cost) for i in range(n_panels)]))\n",
    "    for z in [0.8,0.7,0.6,0.5,0.4,0.3]:\n",
    "        layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "    layers.append(DetectorLayer(pos='below', lw=lwh[:2], z=0.2, size=2*size,\n",
    "                                panels=[DetectorPanel(res=init_res, eff=init_eff,\n",
    "                                                      init_xyz=[0.5,0.5,0.2-(i*(2*size)/n_panels)], init_xy_span=[0.5,0.5],\n",
    "                                                      area_cost_func=area_cost) for i in range(n_panels)]))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volume(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        if isinstance(layers, list):\n",
    "            layers = nn.ModuleList(layers)\n",
    "        self.layers = layers\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Layer:\n",
    "        return self.layers[idx]\n",
    "\n",
    "    def get_detectors(self) -> List[DetectorLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, DetectorLayer)]\n",
    "\n",
    "    def get_passives(self) -> List[PassiveLayer]:\n",
    "        return [l for l in self.layers if isinstance(l, PassiveLayer)]\n",
    "\n",
    "    def get_rad_cube(self) -> Tensor:\n",
    "        vols = list(reversed(self.get_passives()))  # reversed to match lookup_xyz_coords: layer zero = bottom layer\n",
    "        if len(vols) == 0:\n",
    "            raise ValueError(\"self.layers contains no passive layers\")\n",
    "        return torch.stack([v.rad_length for v in vols if v.rad_length is not None], dim=0)\n",
    "\n",
    "    def lookup_passive_xyz_coords(self, xyz: Tensor) -> Tensor:\n",
    "        r\"\"\"Assume same size for all layers for now and no intermedeate detector layers\"\"\"\n",
    "        if len(xyz.shape) == 1:\n",
    "            xyz = xyz[None, :]\n",
    "\n",
    "        if n := (\n",
    "            ((xyz[:, :2] > self.lw) + (xyz[:, :2] < 0)).sum(1) + (xyz[:, 2] < self.get_passive_z_range()[0]) + ((xyz[:, 2] > self.get_passive_z_range()[1]))\n",
    "        ).sum():\n",
    "            raise ValueError(f\"{n} Coordinates outside passive volume\")\n",
    "        xyz[:, 2] = xyz[:, 2] - self.get_passive_z_range()[0]\n",
    "        return torch.floor(xyz / self.size).long()\n",
    "\n",
    "    def load_rad_length(self, rad_length_func: Callable[..., Tensor]) -> None:\n",
    "        for p in self.get_passives():\n",
    "            p.load_rad_length(rad_length_func)\n",
    "\n",
    "    def forward(self, mu: MuonBatch) -> None:  # Expand to take volume as input, too\n",
    "        for l in self.layers:\n",
    "            l(mu)\n",
    "            mu.snapshot_xyz()\n",
    "\n",
    "    def get_cost(self) -> Tensor:\n",
    "        cost = None\n",
    "        for l in self.layers:\n",
    "            if hasattr(l, \"get_cost\"):\n",
    "                if cost is None:\n",
    "                    cost = l.get_cost()\n",
    "                else:\n",
    "                    cost = cost + l.get_cost()\n",
    "        if cost is None:\n",
    "            cost = torch.zeros((1))\n",
    "        return cost\n",
    "\n",
    "    @property\n",
    "    def lw(self) -> Tensor:\n",
    "        return self.get_passives()[-1].lw\n",
    "\n",
    "    @property\n",
    "    def passive_size(self) -> float:\n",
    "        return self.get_passives()[-1].size  # Same size for each passive layer\n",
    "\n",
    "    @property\n",
    "    def h(self) -> float:\n",
    "        return self.layers[0].z\n",
    "\n",
    "    def get_passive_z_range(self) -> Tuple[Tensor, Tensor]:\n",
    "        ps = self.get_passives()\n",
    "        return ps[-1].z-self.passive_size, ps[0].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 1.0, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "  (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "  (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.8000])\n",
      "tensor([0.7000])\n",
      "tensor([0.6000])\n",
      "tensor([0.5000])\n",
      "tensor([0.4000])\n",
      "tensor([0.3000])\n",
      "tensor([0.2000])\n"
     ]
    }
   ],
   "source": [
    "for l in volume: print(l.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2000]), tensor([0.8000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.get_passive_z_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "  (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "  (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "  (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[-1].panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 1.0, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume[0].panels.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 1.0, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.949999988079071, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8999999761581421, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.8500000238418579, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.20000000298023224, and xy span tensor([0.5000, 0.5000])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.15000000596046448, and xy span tensor([0.5000, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.10000000149011612, and xy span tensor([0.5000, 0.5000])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.5000, 0.5000]), 0.05000000074505806, and xy span tensor([0.5000, 0.5000])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# volume.train()\n",
    "volume.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons.xy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0393, 0.0758, 1.0000],\n",
       "         [0.0424, 0.1248, 1.0000],\n",
       "         [0.3631, 0.4371, 1.0000],\n",
       "         [0.3716, 0.8420, 1.0000],\n",
       "         [0.7583, 0.8932, 1.0000],\n",
       "         [0.1628, 0.4199, 1.0000],\n",
       "         [0.1050, 0.4609, 1.0000],\n",
       "         [0.7382, 0.3814, 1.0000],\n",
       "         [0.3947, 0.2170, 1.0000],\n",
       "         [0.2892, 0.7125, 1.0000],\n",
       "         [0.2274, 0.5666, 1.0000],\n",
       "         [0.5710, 0.1090, 1.0000],\n",
       "         [0.8584, 0.7712, 1.0000],\n",
       "         [0.0193, 0.8131, 1.0000],\n",
       "         [0.7143, 0.7251, 1.0000],\n",
       "         [0.6240, 0.6755, 1.0000],\n",
       "         [0.7764, 0.0469, 1.0000],\n",
       "         [0.3105, 0.9771, 1.0000],\n",
       "         [0.7764, 0.1731, 1.0000],\n",
       "         [0.6560, 0.3483, 1.0000],\n",
       "         [0.4374, 0.1890, 1.0000],\n",
       "         [0.0404, 0.6701, 1.0000],\n",
       "         [0.0374, 0.2099, 1.0000],\n",
       "         [0.5822, 0.2528, 1.0000],\n",
       "         [0.4495, 0.4885, 1.0000],\n",
       "         [0.2049, 0.0861, 1.0000],\n",
       "         [0.4150, 0.7278, 1.0000],\n",
       "         [0.9980, 0.8645, 1.0000],\n",
       "         [0.2597, 0.6903, 1.0000],\n",
       "         [0.4910, 0.3766, 1.0000],\n",
       "         [0.2283, 0.7010, 1.0000],\n",
       "         [0.1791, 0.4738, 1.0000],\n",
       "         [0.5663, 0.3815, 1.0000],\n",
       "         [0.7241, 0.0664, 1.0000],\n",
       "         [0.4004, 0.6307, 1.0000],\n",
       "         [0.1597, 0.6184, 1.0000],\n",
       "         [0.7612, 0.1756, 1.0000],\n",
       "         [0.6360, 0.3726, 1.0000],\n",
       "         [0.5755, 0.8492, 1.0000],\n",
       "         [0.9871, 0.6349, 1.0000],\n",
       "         [0.5142, 0.5588, 1.0000],\n",
       "         [0.3247, 0.7503, 1.0000],\n",
       "         [0.6900, 0.7568, 1.0000],\n",
       "         [0.4110, 0.4971, 1.0000],\n",
       "         [0.1367, 0.2229, 1.0000],\n",
       "         [0.6098, 0.6447, 1.0000],\n",
       "         [0.2301, 0.7937, 1.0000],\n",
       "         [0.7110, 0.7065, 1.0000],\n",
       "         [0.4259, 0.1598, 1.0000],\n",
       "         [0.5507, 0.7950, 1.0000],\n",
       "         [0.7791, 0.6578, 1.0000],\n",
       "         [0.4211, 0.2070, 1.0000],\n",
       "         [0.7305, 0.8545, 1.0000],\n",
       "         [0.4803, 0.3949, 1.0000],\n",
       "         [0.2407, 0.6892, 1.0000],\n",
       "         [0.7082, 0.2788, 1.0000],\n",
       "         [0.7748, 0.3336, 1.0000],\n",
       "         [0.8082, 0.7599, 1.0000],\n",
       "         [0.5729, 0.7863, 1.0000],\n",
       "         [0.9255, 0.6705, 1.0000],\n",
       "         [0.1629, 0.2173, 1.0000],\n",
       "         [0.6486, 0.3545, 1.0000],\n",
       "         [0.4097, 0.9787, 1.0000],\n",
       "         [0.7682, 0.2612, 1.0000],\n",
       "         [0.5435, 0.1553, 1.0000],\n",
       "         [0.9564, 0.0580, 1.0000],\n",
       "         [0.3280, 0.1903, 1.0000],\n",
       "         [0.5870, 0.3829, 1.0000],\n",
       "         [0.0531, 0.5627, 1.0000],\n",
       "         [0.2406, 0.5539, 1.0000],\n",
       "         [0.8710, 0.7265, 1.0000],\n",
       "         [0.6557, 0.7529, 1.0000],\n",
       "         [0.3741, 0.6425, 1.0000],\n",
       "         [0.9532, 0.8782, 1.0000],\n",
       "         [0.3882, 0.1185, 1.0000],\n",
       "         [0.0925, 0.3081, 1.0000],\n",
       "         [0.5690, 0.4409, 1.0000],\n",
       "         [0.8799, 0.5664, 1.0000],\n",
       "         [0.0448, 0.3084, 1.0000],\n",
       "         [0.8507, 0.4019, 1.0000],\n",
       "         [0.5956, 0.5192, 1.0000],\n",
       "         [0.2219, 0.7650, 1.0000],\n",
       "         [0.1639, 0.4731, 1.0000],\n",
       "         [0.1501, 0.6320, 1.0000]], grad_fn=<CatBackward>),\n",
       " tensor([[0.0382, 0.0846, 0.9500],\n",
       "         [0.0485, 0.1263, 0.9500],\n",
       "         [0.3672, 0.4364, 0.9500],\n",
       "         [0.3675, 0.8456, 0.9500],\n",
       "         [0.7590, 0.8974, 0.9500],\n",
       "         [0.1625, 0.4123, 0.9500],\n",
       "         [0.1079, 0.4710, 0.9500],\n",
       "         [0.7373, 0.3815, 0.9500],\n",
       "         [0.3895, 0.2177, 0.9500],\n",
       "         [0.2958, 0.7183, 0.9500],\n",
       "         [0.2390, 0.5637, 0.9500],\n",
       "         [0.5655, 0.1121, 0.9500],\n",
       "         [0.8607, 0.7689, 0.9500],\n",
       "         [0.0257, 0.8139, 0.9500],\n",
       "         [0.7010, 0.7282, 0.9500],\n",
       "         [0.6241, 0.6774, 0.9500],\n",
       "         [0.7743, 0.0583, 0.9500],\n",
       "         [0.3128, 0.9752, 0.9500],\n",
       "         [0.7771, 0.1742, 0.9500],\n",
       "         [0.6571, 0.3493, 0.9500],\n",
       "         [0.4359, 0.1912, 0.9500],\n",
       "         [0.0372, 0.6754, 0.9500],\n",
       "         [0.0439, 0.1985, 0.9500],\n",
       "         [0.5784, 0.2433, 0.9500],\n",
       "         [0.4491, 0.4787, 0.9500],\n",
       "         [0.1968, 0.0921, 0.9500],\n",
       "         [0.4110, 0.7239, 0.9500],\n",
       "         [0.9913, 0.8515, 0.9500],\n",
       "         [0.2641, 0.6872, 0.9500],\n",
       "         [0.4918, 0.3797, 0.9500],\n",
       "         [0.2239, 0.7146, 0.9500],\n",
       "         [0.1737, 0.4725, 0.9500],\n",
       "         [0.5653, 0.3785, 0.9500],\n",
       "         [0.7184, 0.0729, 0.9500],\n",
       "         [0.3977, 0.6275, 0.9500],\n",
       "         [0.1653, 0.6103, 0.9500],\n",
       "         [0.7526, 0.1816, 0.9500],\n",
       "         [0.6360, 0.3759, 0.9500],\n",
       "         [0.5683, 0.8509, 0.9500],\n",
       "         [0.9842, 0.6354, 0.9500],\n",
       "         [0.5082, 0.5639, 0.9500],\n",
       "         [0.3213, 0.7531, 0.9500],\n",
       "         [0.6905, 0.7643, 0.9500],\n",
       "         [0.4216, 0.5026, 0.9500],\n",
       "         [0.1352, 0.2216, 0.9500],\n",
       "         [0.6045, 0.6437, 0.9500],\n",
       "         [0.2402, 0.7993, 0.9500],\n",
       "         [0.7086, 0.7055, 0.9500],\n",
       "         [0.4255, 0.1619, 0.9500],\n",
       "         [0.5461, 0.7898, 0.9500],\n",
       "         [0.7833, 0.6517, 0.9500],\n",
       "         [0.4251, 0.2073, 0.9500],\n",
       "         [0.7311, 0.8554, 0.9500],\n",
       "         [0.4869, 0.3980, 0.9500],\n",
       "         [0.2449, 0.6948, 0.9500],\n",
       "         [0.7035, 0.2898, 0.9500],\n",
       "         [0.7726, 0.3352, 0.9500],\n",
       "         [0.8152, 0.7610, 0.9500],\n",
       "         [0.5816, 0.7812, 0.9500],\n",
       "         [0.9195, 0.6634, 0.9500],\n",
       "         [0.1577, 0.2232, 0.9500],\n",
       "         [0.6420, 0.3541, 0.9500],\n",
       "         [0.4107, 0.9742, 0.9500],\n",
       "         [0.7633, 0.2603, 0.9500],\n",
       "         [0.5441, 0.1643, 0.9500],\n",
       "         [0.9583, 0.0620, 0.9500],\n",
       "         [0.3250, 0.1917, 0.9500],\n",
       "         [0.5943, 0.3746, 0.9500],\n",
       "         [0.0486, 0.5624, 0.9500],\n",
       "         [0.2384, 0.5460, 0.9500],\n",
       "         [0.8793, 0.7262, 0.9500],\n",
       "         [0.6617, 0.7445, 0.9500],\n",
       "         [0.3681, 0.6476, 0.9500],\n",
       "         [0.9592, 0.8771, 0.9500],\n",
       "         [0.3791, 0.1140, 0.9500],\n",
       "         [0.0993, 0.3121, 0.9500],\n",
       "         [0.5748, 0.4411, 0.9500],\n",
       "         [0.8714, 0.5707, 0.9500],\n",
       "         [0.0490, 0.3020, 0.9500],\n",
       "         [0.8459, 0.4030, 0.9500],\n",
       "         [0.6002, 0.5186, 0.9500],\n",
       "         [0.2107, 0.7685, 0.9500],\n",
       "         [0.1582, 0.4814, 0.9500],\n",
       "         [0.1486, 0.6448, 0.9500]], grad_fn=<CatBackward>),\n",
       " tensor([[0.0373, 0.0955, 0.9000],\n",
       "         [0.0570, 0.1239, 0.9000],\n",
       "         [0.3681, 0.4387, 0.9000],\n",
       "         [0.3646, 0.8442, 0.9000],\n",
       "         [0.7602, 0.9028, 0.9000],\n",
       "         [0.1545, 0.4076, 0.9000],\n",
       "         [0.1156, 0.4794, 0.9000],\n",
       "         [0.7403, 0.3837, 0.9000],\n",
       "         [0.3857, 0.2220, 0.9000],\n",
       "         [0.3030, 0.7271, 0.9000],\n",
       "         [0.2534, 0.5583, 0.9000],\n",
       "         [0.5602, 0.1117, 0.9000],\n",
       "         [0.8652, 0.7709, 0.9000],\n",
       "         [0.0319, 0.8123, 0.9000],\n",
       "         [0.6866, 0.7282, 0.9000],\n",
       "         [0.6235, 0.6769, 0.9000],\n",
       "         [0.7734, 0.0658, 0.9000],\n",
       "         [0.3212, 0.9738, 0.9000],\n",
       "         [0.7728, 0.1750, 0.9000],\n",
       "         [0.6561, 0.3484, 0.9000],\n",
       "         [0.4327, 0.1894, 0.9000],\n",
       "         [0.0341, 0.6786, 0.9000],\n",
       "         [0.0515, 0.1907, 0.9000],\n",
       "         [0.5743, 0.2346, 0.9000],\n",
       "         [0.4503, 0.4673, 0.9000],\n",
       "         [0.1909, 0.1021, 0.9000],\n",
       "         [0.4095, 0.7200, 0.9000],\n",
       "         [0.9880, 0.8438, 0.9000],\n",
       "         [0.2641, 0.6857, 0.9000],\n",
       "         [0.4929, 0.3826, 0.9000],\n",
       "         [0.2199, 0.7246, 0.9000],\n",
       "         [0.1732, 0.4663, 0.9000],\n",
       "         [0.5643, 0.3760, 0.9000],\n",
       "         [0.7157, 0.0837, 0.9000],\n",
       "         [0.3952, 0.6276, 0.9000],\n",
       "         [0.1624, 0.6036, 0.9000],\n",
       "         [0.7482, 0.1863, 0.9000],\n",
       "         [0.6375, 0.3827, 0.9000],\n",
       "         [0.5615, 0.8468, 0.9000],\n",
       "         [0.9763, 0.6385, 0.9000],\n",
       "         [0.5077, 0.5697, 0.9000],\n",
       "         [0.3200, 0.7597, 0.9000],\n",
       "         [0.6919, 0.7685, 0.9000],\n",
       "         [0.4269, 0.5049, 0.9000],\n",
       "         [0.1324, 0.2190, 0.9000],\n",
       "         [0.5956, 0.6410, 0.9000],\n",
       "         [0.2460, 0.8059, 0.9000],\n",
       "         [0.7026, 0.7056, 0.9000],\n",
       "         [0.4286, 0.1615, 0.9000],\n",
       "         [0.5413, 0.7842, 0.9000],\n",
       "         [0.7871, 0.6464, 0.9000],\n",
       "         [0.4313, 0.2054, 0.9000],\n",
       "         [0.7290, 0.8592, 0.9000],\n",
       "         [0.4905, 0.4006, 0.9000],\n",
       "         [0.2489, 0.7001, 0.9000],\n",
       "         [0.6997, 0.3009, 0.9000],\n",
       "         [0.7691, 0.3375, 0.9000],\n",
       "         [0.8229, 0.7653, 0.9000],\n",
       "         [0.5899, 0.7763, 0.9000],\n",
       "         [0.9173, 0.6548, 0.9000],\n",
       "         [0.1530, 0.2252, 0.9000],\n",
       "         [0.6397, 0.3512, 0.9000],\n",
       "         [0.4103, 0.9718, 0.9000],\n",
       "         [0.7573, 0.2591, 0.9000],\n",
       "         [0.5461, 0.1742, 0.9000],\n",
       "         [0.9578, 0.0677, 0.9000],\n",
       "         [0.3169, 0.1992, 0.9000],\n",
       "         [0.6036, 0.3684, 0.9000],\n",
       "         [0.0505, 0.5604, 0.9000],\n",
       "         [0.2355, 0.5414, 0.9000],\n",
       "         [0.8817, 0.7283, 0.9000],\n",
       "         [0.6662, 0.7409, 0.9000],\n",
       "         [0.3623, 0.6493, 0.9000],\n",
       "         [0.9611, 0.8797, 0.9000],\n",
       "         [0.3739, 0.1071, 0.9000],\n",
       "         [0.1068, 0.3152, 0.9000],\n",
       "         [0.5806, 0.4424, 0.9000],\n",
       "         [0.8681, 0.5721, 0.9000],\n",
       "         [0.0560, 0.2949, 0.9000],\n",
       "         [0.8349, 0.4024, 0.9000],\n",
       "         [0.6009, 0.5203, 0.9000],\n",
       "         [0.2051, 0.7739, 0.9000],\n",
       "         [0.1543, 0.4885, 0.9000],\n",
       "         [0.1480, 0.6520, 0.9000]], grad_fn=<CatBackward>),\n",
       " tensor([[0.0380, 0.1039, 0.8500],\n",
       "         [0.0632, 0.1239, 0.8500],\n",
       "         [0.3726, 0.4402, 0.8500],\n",
       "         [0.3629, 0.8496, 0.8500],\n",
       "         [0.7627, 0.9065, 0.8500],\n",
       "         [0.1528, 0.4007, 0.8500],\n",
       "         [0.1175, 0.4896, 0.8500],\n",
       "         [0.7396, 0.3825, 0.8500],\n",
       "         [0.3839, 0.2238, 0.8500],\n",
       "         [0.3055, 0.7320, 0.8500],\n",
       "         [0.2679, 0.5554, 0.8500],\n",
       "         [0.5519, 0.1105, 0.8500],\n",
       "         [0.8689, 0.7678, 0.8500],\n",
       "         [0.0354, 0.8125, 0.8500],\n",
       "         [0.6757, 0.7280, 0.8500],\n",
       "         [0.6225, 0.6772, 0.8500],\n",
       "         [0.7751, 0.0746, 0.8500],\n",
       "         [0.3247, 0.9709, 0.8500],\n",
       "         [0.7749, 0.1743, 0.8500],\n",
       "         [0.6554, 0.3484, 0.8500],\n",
       "         [0.4321, 0.1892, 0.8500],\n",
       "         [0.0367, 0.6844, 0.8500],\n",
       "         [0.0573, 0.1790, 0.8500],\n",
       "         [0.5712, 0.2270, 0.8500],\n",
       "         [0.4508, 0.4552, 0.8500],\n",
       "         [0.1831, 0.1065, 0.8500],\n",
       "         [0.4027, 0.7157, 0.8500],\n",
       "         [0.9846, 0.8348, 0.8500],\n",
       "         [0.2670, 0.6878, 0.8500],\n",
       "         [0.4963, 0.3865, 0.8500],\n",
       "         [0.2162, 0.7398, 0.8500],\n",
       "         [0.1724, 0.4648, 0.8500],\n",
       "         [0.5649, 0.3749, 0.8500],\n",
       "         [0.7126, 0.0922, 0.8500],\n",
       "         [0.3955, 0.6247, 0.8500],\n",
       "         [0.1650, 0.6008, 0.8500],\n",
       "         [0.7374, 0.1941, 0.8500],\n",
       "         [0.6376, 0.3886, 0.8500],\n",
       "         [0.5579, 0.8459, 0.8500],\n",
       "         [0.9724, 0.6378, 0.8500],\n",
       "         [0.5033, 0.5759, 0.8500],\n",
       "         [0.3165, 0.7635, 0.8500],\n",
       "         [0.6940, 0.7739, 0.8500],\n",
       "         [0.4340, 0.5115, 0.8500],\n",
       "         [0.1290, 0.2191, 0.8500],\n",
       "         [0.5876, 0.6383, 0.8500],\n",
       "         [0.2489, 0.8078, 0.8500],\n",
       "         [0.7010, 0.7052, 0.8500],\n",
       "         [0.4308, 0.1650, 0.8500],\n",
       "         [0.5363, 0.7794, 0.8500],\n",
       "         [0.7906, 0.6422, 0.8500],\n",
       "         [0.4347, 0.2040, 0.8500],\n",
       "         [0.7288, 0.8626, 0.8500],\n",
       "         [0.4962, 0.4059, 0.8500],\n",
       "         [0.2525, 0.7038, 0.8500],\n",
       "         [0.6960, 0.3109, 0.8500],\n",
       "         [0.7645, 0.3382, 0.8500],\n",
       "         [0.8324, 0.7710, 0.8500],\n",
       "         [0.5965, 0.7694, 0.8500],\n",
       "         [0.9136, 0.6454, 0.8500],\n",
       "         [0.1477, 0.2283, 0.8500],\n",
       "         [0.6344, 0.3464, 0.8500],\n",
       "         [0.4102, 0.9668, 0.8500],\n",
       "         [0.7496, 0.2554, 0.8500],\n",
       "         [0.5492, 0.1830, 0.8500],\n",
       "         [0.9598, 0.0777, 0.8500],\n",
       "         [0.3142, 0.1995, 0.8500],\n",
       "         [0.6078, 0.3605, 0.8500],\n",
       "         [0.0462, 0.5574, 0.8500],\n",
       "         [0.2320, 0.5365, 0.8500],\n",
       "         [0.8832, 0.7268, 0.8500],\n",
       "         [0.6735, 0.7391, 0.8500],\n",
       "         [0.3548, 0.6514, 0.8500],\n",
       "         [0.9625, 0.8807, 0.8500],\n",
       "         [0.3679, 0.0990, 0.8500],\n",
       "         [0.1139, 0.3175, 0.8500],\n",
       "         [0.5875, 0.4409, 0.8500],\n",
       "         [0.8619, 0.5768, 0.8500],\n",
       "         [0.0593, 0.2867, 0.8500],\n",
       "         [0.8267, 0.4020, 0.8500],\n",
       "         [0.6036, 0.5212, 0.8500],\n",
       "         [0.1926, 0.7815, 0.8500],\n",
       "         [0.1532, 0.4992, 0.8500],\n",
       "         [0.1500, 0.6613, 0.8500]], grad_fn=<CatBackward>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = muons.get_hits(volume.lw)\n",
    "above_hits = [torch.cat([hits[\"above\"][\"reco_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "above_gen_hits = [torch.cat([hits[\"above\"][\"gen_xy\"][:, i], hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "above_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.9833e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.5531e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.2776e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00, -2.6027e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.0145e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.0449e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.4039e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  8.1292e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-9.6908e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -3.2102e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.4876e-03,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.8625e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 6.9378e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.1046e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-4.3876e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -3.7645e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.9109e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  9.0024e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-6.8953e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.4926e-03],\n",
       "         [ 0.0000e+00,  0.0000e+00]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tomopt.utils import jacobian\n",
    "jacobian(above_hits[0], volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tomopt.utils import jacobian\n",
    "jacobian(above_hits[0], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0424, 0.1248, 1.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0485, 0.1263, 0.9500], grad_fn=<SelectBackward>),\n",
       " tensor([0.0570, 0.1239, 0.9000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0632, 0.1239, 0.8500], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[1] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0393, 0.0758, 1.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0382, 0.0846, 0.9500], grad_fn=<SelectBackward>),\n",
       " tensor([0.0373, 0.0955, 0.9000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0380, 0.1039, 0.8500], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[0] for h in above_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_uncs(dets: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "    res = []\n",
    "    for l,h in zip(dets,hits):\n",
    "        r = 1 / l.get_resolution(h[:,:2])\n",
    "        res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = get_hit_uncs(volume.get_detectors()[0].panels, above_gen_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0015, 0.0014, 0.0000],\n",
       "        [0.0015, 0.0013, 0.0000],\n",
       "        [0.0010, 0.0010, 0.0000],\n",
       "        [0.0010, 0.0013, 0.0000],\n",
       "        [0.0011, 0.0014, 0.0000],\n",
       "        [0.0013, 0.0010, 0.0000],\n",
       "        [0.0014, 0.0010, 0.0000],\n",
       "        [0.0011, 0.0010, 0.0000],\n",
       "        [0.0010, 0.0012, 0.0000],\n",
       "        [0.0011, 0.0011, 0.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0015, 0.0013, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0015, 0.0013, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0015, 0.0013, 0.0000], grad_fn=<SelectBackward>),\n",
       " tensor([0.0015, 0.0013, 0.0000], grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u[1] for u in uncs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0028,  0.0000],\n",
       "         [ 0.0000,  0.0024],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0028,  0.0000],\n",
       "         [ 0.0000,  0.0020],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0006,  0.0000],\n",
       "         [ 0.0000,  0.0003],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0005,  0.0000],\n",
       "         [ 0.0000, -0.0017],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0012,  0.0000],\n",
       "         [ 0.0000, -0.0021],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0017,  0.0000],\n",
       "         [ 0.0000,  0.0003],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0022,  0.0000],\n",
       "         [ 0.0000,  0.0002],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0011,  0.0000],\n",
       "         [ 0.0000,  0.0005],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0004,  0.0000],\n",
       "         [ 0.0000,  0.0013],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0009,  0.0000],\n",
       "         [ 0.0000, -0.0009],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(uncs[0], volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(uncs[0], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "    r\"\"\"\n",
    "    hits = [muons,(x,y,z)]\n",
    "    uncs = [(unc,unc,0)]\n",
    "\n",
    "    Assume no uncertainty for z\n",
    "    \n",
    "    In eval mode:\n",
    "        Muons with <2 hits within panels have NaN trajectory.\n",
    "        Muons with >=2 hits in panels have valid trajectories\n",
    "    \"\"\"\n",
    "\n",
    "    hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "    hits = torch.where(torch.isinf(hits), torch.tensor([0.5], device=uncs.device), hits)\n",
    "    \n",
    "    stars, angles = [],[]\n",
    "    for i in range(2):  # seperate x and y resolutions\n",
    "        inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "        sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "        mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_x = mean_xz[:, :1]\n",
    "        mean_z = mean_xz[:, 1:]\n",
    "        mean_x_z = mean_xz_z[:, :1]\n",
    "        mean_z2 = mean_xz_z[:, 1:]\n",
    "        \n",
    "        stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "        angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "    xy_star = torch.cat(stars, dim=-1)\n",
    "    angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "    def _calc_xyz(z: Tensor) -> Tensor:\n",
    "        return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "\n",
    "    return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0005,  0.0095, -0.0500],\n",
       "        [ 0.0071, -0.0005, -0.0500],\n",
       "        [ 0.0029,  0.0012, -0.0500],\n",
       "        [-0.0029,  0.0021, -0.0500],\n",
       "        [ 0.0014,  0.0045, -0.0500],\n",
       "        [-0.0038, -0.0062, -0.0500],\n",
       "        [ 0.0045,  0.0094, -0.0500],\n",
       "        [ 0.0007,  0.0006, -0.0500],\n",
       "        [-0.0036,  0.0025, -0.0500],\n",
       "        [ 0.0056,  0.0067, -0.0500]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = get_muon_trajectory(above_hits, uncs); traj[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.8528e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  5.6495e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-7.6462e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.7261e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 2.2158e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.9537e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 9.1278e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.2098e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.3634e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00,  8.1916e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.9375e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  7.4818e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 5.4734e-05,  0.0000e+00],\n",
       "         [ 0.0000e+00, -4.5806e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.1245e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  9.9613e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.4848e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.3613e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.8017e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00, -5.0863e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(traj, volume.get_detectors()[0].panels[0].xy, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0085,  0.1341, -1.0000],\n",
       "        [ 0.0989, -0.0042, -1.0000],\n",
       "        [ 0.0419,  0.0134, -1.0000],\n",
       "        [-0.0430,  0.0301, -1.0000],\n",
       "        [ 0.0186,  0.0631, -1.0000],\n",
       "        [-0.0489, -0.0890, -1.0000],\n",
       "        [ 0.0624,  0.1327, -1.0000],\n",
       "        [ 0.0080,  0.0081, -1.0000],\n",
       "        [-0.0542,  0.0321, -1.0000],\n",
       "        [ 0.0814,  0.0936, -1.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(traj, volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.utils import jacobian\n",
    "\n",
    "class PanelScatterBatch(ScatterBatch):\n",
    "    @staticmethod\n",
    "    def get_muon_trajectory(hit_list: List[Tensor], unc_list: List[Tensor]) -> Tensor:\n",
    "        r\"\"\"\n",
    "        hits = [muons,(x,y,z)]\n",
    "        uncs = [(unc,unc,0)]\n",
    "\n",
    "        Assume no uncertainty for z\n",
    "\n",
    "        In eval mode:\n",
    "            Muons with <2 hits within panels have NaN trajectory.\n",
    "            Muons with >=2 hits in panels have valid trajectories\n",
    "        \"\"\"\n",
    "\n",
    "        hits, uncs = torch.stack(hit_list, dim=1), torch.stack(unc_list, dim=1)\n",
    "        hits = torch.where(torch.isinf(hits), torch.tensor([0.5], device=uncs.device), hits)\n",
    "\n",
    "        stars, angles = [],[]\n",
    "        for i in range(2):  # seperate x and y resolutions\n",
    "            inv_unc2 = uncs[:, :, i:i+1] ** -2\n",
    "            sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "            mean_xz = torch.sum(hits[:,:,[i,2]] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_xz_z = torch.sum(hits[:,:,[i,2]] * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "            mean_x = mean_xz[:, :1]\n",
    "            mean_z = mean_xz[:, 1:]\n",
    "            mean_x_z = mean_xz_z[:, :1]\n",
    "            mean_z2 = mean_xz_z[:, 1:]\n",
    "\n",
    "            stars.append((mean_x - ((mean_z * mean_x_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2)))\n",
    "            angles.append((mean_x_z - (stars[-1] * mean_z)) / mean_z2)\n",
    "\n",
    "        xy_star = torch.cat(stars, dim=-1)\n",
    "        angle = torch.cat(angles, dim=-1)\n",
    "\n",
    "        def _calc_xyz(z: Tensor) -> Tensor:\n",
    "            return torch.cat([xy_star + (angle * z), z], dim=-1)\n",
    "        \n",
    "        return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_hit_uncs(zordered_panels: List[DetectorPanel], hits: List[Tensor]) -> List[Tensor]:\n",
    "        res = []\n",
    "        for l,h in zip(zordered_panels,hits):\n",
    "            r = 1 / l.get_resolution(h[:,:2])\n",
    "            res.append(torch.cat([r, torch.zeros((len(r),1), device=r.device)], dim=-1))\n",
    "        return res\n",
    "    \n",
    "    def compute_tracks(self) -> None:\n",
    "        # reco x, reco y, gen z, must be a list to allow computation of uncertainty\n",
    "        self.above_hits = [torch.cat([self.hits[\"above\"][\"reco_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"reco_xy\"].shape[1])]\n",
    "        self.below_hits = [torch.cat([self.hits[\"below\"][\"reco_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"reco_xy\"].shape[1])]\n",
    "        self.above_gen_hits = [torch.cat([self.hits[\"above\"][\"gen_xy\"][:, i], self.hits[\"above\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"above\"][\"gen_xy\"].shape[1])]\n",
    "        self.below_gen_hits = [torch.cat([self.hits[\"below\"][\"gen_xy\"][:, i], self.hits[\"below\"][\"z\"][:, i]], dim=-1) for i in range(self.hits[\"below\"][\"gen_xy\"].shape[1])]\n",
    "        self.n_hits_above = len(self.above_hits)\n",
    "        \n",
    "        self.above_hit_uncs = self.get_hit_uncs([self.volume.get_detectors()[0].panels[i] for i in self.volume.get_detectors()[0].get_panel_zorder()], self.above_gen_hits)\n",
    "        self.below_hit_uncs = self.get_hit_uncs([self.volume.get_detectors()[1].panels[i] for i in self.volume.get_detectors()[1].get_panel_zorder()], self.below_gen_hits)\n",
    "    \n",
    "        self.track_in = self.get_muon_trajectory(self.above_hits, self.above_hit_uncs)\n",
    "        self.track_out = self.get_muon_trajectory(self.below_hits, self.below_hit_uncs)\n",
    "        \n",
    "    def _compute_unc(self, var: Tensor, hits: List[Tensor], hit_uncs: List[Tensor]) -> Tensor:\n",
    "        unc2_sum = None\n",
    "        for i, (xi, unci) in enumerate(zip(hits, hit_uncs)):\n",
    "            for j, (xj, uncj) in enumerate(zip(hits, hit_uncs)):\n",
    "                if j < i:\n",
    "                    continue\n",
    "                dv_dx_2 = torch.nan_to_num(jacobian(var, xi)).sum(2) * torch.nan_to_num(jacobian(var, xj)).sum(2) if i != j else torch.nan_to_num(jacobian(var, xi)).sum(2) ** 2  # Muons, var_xyz, hit_xyz\n",
    "                unc_2 = (dv_dx_2 * unci[:, None] * uncj[:, None]).sum(2)  # Muons, (x,y,z)\n",
    "                if unc2_sum is None:\n",
    "                    unc2_sum = unc_2\n",
    "                else:\n",
    "                    unc2_sum = unc2_sum + unc_2\n",
    "        return torch.sqrt(unc2_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb = PanelScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0380,  0.0758,  0.9924],\n",
       "         [ 0.1412,  0.1164,  0.3045],\n",
       "         [ 0.3794,  0.4462,  0.6983],\n",
       "         [ 0.2974,  0.8996, -0.3254],\n",
       "         [ 0.7778,  0.9535,  0.3463],\n",
       "         [ 0.1443,  0.3914,  0.7619],\n",
       "         [ 0.1969,  0.6612, -0.0408],\n",
       "         [ 0.7369,  0.3804,  1.2020],\n",
       "         [ 0.3343,  0.2540,  0.2020],\n",
       "         [ 0.3138,  0.7440,  0.7600]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0040, 0.0476, 0.2556],\n",
       "         [0.0155, 0.0035, 0.1481],\n",
       "         [0.0150, 0.0069, 0.2811],\n",
       "         [0.1892, 0.1350, 3.3780],\n",
       "         [0.0073, 0.0096, 0.1238],\n",
       "         [0.0284, 0.0461, 0.3765],\n",
       "         [0.0298, 0.0756, 0.4150],\n",
       "         [0.0281, 0.0194, 1.8118],\n",
       "         [0.0359, 0.0243, 0.4341],\n",
       "         [0.0347, 0.0412, 0.3132]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[:10], sb.location_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sb.get_scatter_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1412, 0.1164, 0.3045],\n",
       "         [0.3794, 0.4462, 0.6983],\n",
       "         [0.7778, 0.9535, 0.3463],\n",
       "         [0.1443, 0.3914, 0.7619],\n",
       "         [0.3343, 0.2540, 0.2020],\n",
       "         [0.3138, 0.7440, 0.7600],\n",
       "         [0.4030, 0.5150, 0.3471],\n",
       "         [0.4906, 0.1136, 0.3686],\n",
       "         [0.8807, 0.7671, 0.7020],\n",
       "         [0.6548, 0.3496, 0.7509]], grad_fn=<SliceBackward>),\n",
       " tensor([[1.5450e-02, 3.5483e-03, 1.4812e-01],\n",
       "         [1.4963e-02, 6.8762e-03, 2.8109e-01],\n",
       "         [7.3457e-03, 9.5671e-03, 1.2383e-01],\n",
       "         [2.8438e-02, 4.6067e-02, 3.7645e-01],\n",
       "         [3.5949e-02, 2.4262e-02, 4.3411e-01],\n",
       "         [3.4687e-02, 4.1247e-02, 3.1320e-01],\n",
       "         [9.6326e-02, 2.5149e-02, 3.6190e-01],\n",
       "         [4.5462e-02, 6.5991e-03, 3.4308e-01],\n",
       "         [2.4150e-01, 5.0056e-02, 3.3698e+00],\n",
       "         [3.2190e-03, 1.8774e-03, 7.0914e-01]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.location[m][:10], sb.location_unc[m][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2587e-03,  2.1600e-05,  1.1128e-02],\n",
       "        [-2.8212e-03, -8.3988e-04,  5.8679e-02],\n",
       "        [-9.4498e-04, -8.9113e-04,  1.6651e-02],\n",
       "        [ 8.6121e-03,  1.8480e-02,  1.4982e-01],\n",
       "        [ 8.8665e-03, -3.7342e-03,  9.7297e-02],\n",
       "        [ 1.3542e-02,  1.5353e-02, -1.2538e-01],\n",
       "        [-8.0925e-02,  2.2812e-02,  3.1304e-01],\n",
       "        [ 8.6717e-02, -1.6974e-02,  6.6907e-01],\n",
       "        [ 1.5867e-02, -3.9394e-03, -2.4680e-01],\n",
       "        [ 1.3780e-04, -5.5689e-04, -2.4771e-01]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location[m], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0480e+00, -8.1068e-02, -1.0538e+01],\n",
       "        [ 1.5164e-01,  4.4692e-02, -3.3668e+00],\n",
       "        [-3.0465e-02, -9.4904e-02, -4.9635e-01],\n",
       "        [-5.9639e-01, -1.0844e+00, -9.0681e+00],\n",
       "        [ 1.8299e+00, -1.3083e+00,  2.1996e+01],\n",
       "        [ 1.7954e+00,  1.9673e+00, -1.5791e+01],\n",
       "        [ 1.6779e+01, -4.4322e+00, -6.3598e+01],\n",
       "        [ 2.7368e+00, -2.7226e-01,  1.9693e+01],\n",
       "        [-4.3568e+00,  9.1424e-01,  6.0919e+01],\n",
       "        [-2.5012e-04, -1.6168e-03, -4.0312e+00]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location[m], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.7066e-03,  8.7377e-04,  8.0798e-02],\n",
       "        [ 5.5290e-04,  1.4824e-04,  1.0999e-02],\n",
       "        [-1.8807e-03, -2.3818e-03, -3.6529e-02],\n",
       "        [ 1.2615e-04,  2.6115e-04,  2.0123e-03],\n",
       "        [ 4.3739e-03,  3.1561e-03,  5.3678e-02],\n",
       "        [ 6.1646e-04,  5.1316e-04,  4.6167e-03],\n",
       "        [ 1.4226e-02,  4.1359e-03,  5.4504e-02],\n",
       "        [ 6.0665e-03,  1.3708e-03,  4.8962e-02],\n",
       "        [-4.1497e-02, -8.9591e-03, -5.9205e-01],\n",
       "        [ 3.4324e-05,  2.9087e-05,  3.1810e-02]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].z, create_graph=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.9331e-03, -7.1997e-04, -7.3721e-02],\n",
       "        [-1.3750e-04, -3.7821e-05, -2.7299e-03],\n",
       "        [-1.0834e-03, -1.3239e-03, -2.2087e-02],\n",
       "        [-2.2369e-05, -4.5645e-05, -3.5362e-04],\n",
       "        [-1.0536e-03, -8.7173e-04, -1.3098e-02],\n",
       "        [-7.7349e-04, -7.8298e-04, -6.2670e-03],\n",
       "        [-9.6263e-03, -2.6777e-03, -3.6530e-02],\n",
       "        [-6.1627e-03, -1.1890e-03, -4.8605e-02],\n",
       "        [-2.6410e-02, -5.6986e-03, -3.7688e-01],\n",
       "        [-6.8568e-06, -1.1198e-05, -1.2628e-02]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.location_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4362e-03, -2.9487e-03],\n",
       "        [-3.0535e-04, -6.5994e-05],\n",
       "        [-1.2019e-03, -3.1616e-03],\n",
       "        [-2.1887e-03, -1.0151e-04],\n",
       "        [-1.8081e-04, -1.5458e-03],\n",
       "        [-7.8812e-04, -7.6430e-04],\n",
       "        [-1.3988e-03, -7.0981e-05],\n",
       "        [-8.4328e-05, -3.3599e-03],\n",
       "        [-2.5402e-03, -1.3725e-03],\n",
       "        [-4.0934e-04, -3.8224e-04]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.dtheta_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3173e-03, -4.1891e-03],\n",
       "        [-4.2991e-04, -9.3231e-05],\n",
       "        [-1.7125e-03, -4.6655e-03],\n",
       "        [-3.1712e-03, -1.4529e-04],\n",
       "        [-2.5780e-04, -2.1602e-03],\n",
       "        [-1.0929e-03, -1.1117e-03],\n",
       "        [-1.8784e-03, -1.0012e-04],\n",
       "        [-1.1846e-04, -4.7325e-03],\n",
       "        [-3.6869e-03, -1.9360e-03],\n",
       "        [-5.7894e-04, -5.4062e-04]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.theta_in_unc[m], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5868e-03, -4.5224e-03],\n",
       "        [-2.3079e-04, -4.7993e-05],\n",
       "        [-2.2120e-03, -7.4346e-03],\n",
       "        [-4.6130e-03, -7.2566e-04],\n",
       "        [-6.7710e-04, -1.5691e-03],\n",
       "        [-3.4871e-04, -2.5507e-03],\n",
       "        [-7.7502e-05, -8.8442e-07],\n",
       "        [-2.4508e-05, -4.4675e-03],\n",
       "        [-5.4712e-03, -1.7845e-03],\n",
       "        [-5.8539e-04, -5.3997e-04]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(sb.theta_out_unc[m], volume.get_detectors()[1].panels[0].xy_span, create_graph=True).sum(2)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X0 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelX0Inferer(X0Inferer):\n",
    "    def compute_efficiency(self) -> Tensor:\n",
    "        eff = None\n",
    "        for pos, hits in enumerate([self.scatters.above_gen_hits, self.scatters.below_gen_hits]):\n",
    "            leff = None\n",
    "            layer = self.volume.get_detectors()[pos]\n",
    "            panel_idxs = layer.get_panel_zorder()\n",
    "            effs = torch.stack([layer.panels[i].get_efficiency(hits[i][self.mask,:2]) for i in panel_idxs], dim=0)\n",
    "            for r in range(2,len(effs)+1):  # Muon goes through any combination of at least 2 panels\n",
    "                c = torch.combinations(torch.arange(0,len(effs)), r=r)\n",
    "                e = effs[c].prod(1).sum(0)  \n",
    "                if leff is None:\n",
    "                    leff = e\n",
    "                else:\n",
    "                    leff = leff + e\n",
    "            if eff is None:\n",
    "                eff = leff\n",
    "            else:\n",
    "                eff = eff * leff  # Muons detected above & below passive volume\n",
    "        return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0inf = PanelX0Inferer(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2852, 3.6643, 0.3906, 1.0296, 1.8674, 1.6752, 3.0952, 1.0747, 0.5629,\n",
       "        2.7641, 1.6494, 0.3697, 3.4460, 0.4087, 2.6331, 0.3202, 2.0275, 3.9114,\n",
       "        0.6614, 3.4122, 3.2862, 1.5458, 1.5270, 3.2691, 0.6491, 3.6864, 3.9928,\n",
       "        3.5158, 2.2871, 1.5382, 2.3071, 1.5712, 1.7840, 0.7166, 3.9333, 1.5768,\n",
       "        2.6584, 2.0151, 0.5045, 0.9299, 0.6513, 0.6969, 2.1658, 1.3563, 2.4694,\n",
       "        1.8878, 1.7959, 2.3600, 0.1448, 0.5667, 1.1641, 3.4654, 1.4374, 0.5098,\n",
       "        3.6987, 0.4804, 1.1804, 0.8337], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff = x0inf.compute_efficiency(); eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5073, -1.6669,  0.5634, -0.9660, -1.6402,  0.0161, -1.4323, -0.7616,\n",
       "         0.7838,  0.0316], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].z, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4264, 0.3739, 0.3824, 0.5541, 0.7723, 0.6809, 1.0920, 0.7553, 0.5016,\n",
       "        0.5910], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(eff[:10], volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dtheta, pred_dtheta_unc = x0inf.x0_from_dtheta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dtheta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0051, 0.0009, 0.0061, 0.0069, 0.0050, 0.0081, 0.0067, 0.1616,\n",
       "         0.0227], grad_fn=<SliceBackward>),\n",
       " tensor([5.2540e-04, 5.3772e-03, 5.3359e-04, 8.8233e-03, 9.0950e-03, 5.9360e-03,\n",
       "         1.0454e-02, 1.0210e-02, 1.1809e+00, 5.2764e-02],\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dtheta[:10], pred_dtheta_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.4403e-05, -7.9586e-06], grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(pred_dtheta[0], volume.get_detectors()[0].panels[0].xy, retain_graph=True, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0359, grad_fn=<SumBackward0>),)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(pred_dtheta[0], volume.get_detectors()[0].panels[0].z, retain_graph=True, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.3084e-05,  6.3038e-04, -1.4314e-05,  3.7485e-03, -5.9408e-04,\n",
       "         2.6454e-03,  1.9823e-03,  1.3553e-02, -1.0964e-01,  1.0167e-02,\n",
       "         1.6616e-03,  3.4865e-03,  1.5810e-05, -4.2837e-04,  5.9605e-04,\n",
       "        -7.6771e-05,  2.2942e-03,  1.7144e-03, -1.2200e-04,  9.8046e-04,\n",
       "         1.3700e-03, -2.1262e-03, -1.5160e-03,  5.4065e-04,  2.4537e-04,\n",
       "        -5.5622e-04,  5.7610e-05,  7.3666e-05,  6.1238e-05,  1.7003e-03,\n",
       "         2.8187e-04,  5.9695e-04,  3.4610e-04, -1.1089e-04, -2.4601e-04,\n",
       "        -1.1429e-03, -1.4223e-03,  3.2679e-03, -4.7527e-06,  7.2124e-05,\n",
       "         5.7621e-04,  5.8155e-03,  1.8828e-03, -2.6368e-02, -8.1890e-06,\n",
       "         4.2427e-04, -3.2582e-04,  6.1623e-04, -5.1358e-04,  7.8170e-04,\n",
       "         1.5754e-02, -2.7742e-05,  1.5808e-04,  2.6442e-03, -2.1411e-03,\n",
       "        -4.4438e-04, -1.9439e-04,  3.4836e-03], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta, volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5589e-04,  5.6197e-04, -1.3701e-04,  2.3137e-03,  1.7001e-03,\n",
       "        -8.0733e-04, -3.6115e-04,  2.9244e-03, -3.1705e-01, -7.1070e-03,\n",
       "         3.8739e-04,  1.2290e-04,  1.2742e-04,  1.6321e-03, -7.6885e-04,\n",
       "        -1.4968e-04,  3.7864e-03,  2.0757e-03,  1.5855e-04, -5.5118e-04,\n",
       "        -5.9271e-03, -2.6284e-04, -3.7935e-03,  4.9820e-04, -2.6631e-04,\n",
       "        -1.4701e-03,  3.7663e-05, -1.5121e-04, -5.2529e-05,  2.5000e-03,\n",
       "        -5.5656e-04, -4.6654e-04,  1.2209e-03, -6.5011e-05,  5.7608e-04,\n",
       "        -3.4005e-04, -2.4264e-03, -2.1751e-03, -2.5123e-04, -2.3387e-04,\n",
       "         2.9894e-04, -1.6211e-03,  7.2872e-04,  1.5216e-02, -5.0343e-05,\n",
       "         1.6282e-04, -1.4988e-04,  6.0747e-04, -3.0097e-04,  2.2986e-04,\n",
       "         9.0366e-03, -1.0748e-04, -8.0702e-05,  9.1917e-04, -1.7061e-03,\n",
       "        -2.6759e-03,  5.9180e-05,  1.7397e-03], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].xy, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].z, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3446e-04, -1.3904e-04, -8.7683e-05, -1.5312e-03, -8.2908e-04,\n",
       "        -4.4795e-04, -1.9722e-04, -2.3904e-03, -2.0039e-01, -2.2970e-03,\n",
       "        -1.8973e-04, -4.5278e-04, -1.2713e-05, -1.2289e-03, -7.3206e-04,\n",
       "        -1.0841e-04, -1.8558e-03, -5.1699e-04, -3.3867e-04, -3.8818e-04,\n",
       "        -1.5760e-03, -2.3955e-04, -2.5828e-03, -1.2958e-04, -1.9220e-04,\n",
       "        -1.7095e-04, -5.7783e-06, -3.5019e-05, -2.2149e-05, -1.4603e-03,\n",
       "        -3.2370e-04, -2.1757e-04, -5.8042e-04, -3.6905e-05, -8.7204e-05,\n",
       "        -8.3374e-04, -3.0387e-03, -1.4960e-03, -1.2938e-04, -1.0764e-04,\n",
       "        -1.9816e-04, -1.5583e-03, -5.5415e-04, -7.8545e-03, -8.8612e-06,\n",
       "        -9.1484e-05, -7.5204e-05, -1.5921e-04, -2.2970e-04, -1.7498e-04,\n",
       "        -7.3237e-03, -2.1200e-05, -4.0161e-05, -8.3826e-04, -3.1613e-04,\n",
       "        -2.2824e-03, -3.2372e-05, -1.2580e-03], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred_dtheta_unc, volume.get_detectors()[0].panels[0].xy_span, create_graph=True).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, weight = x0inf.average_preds(x0_dtheta=pred_dtheta, x0_dtheta_unc=pred_dtheta_unc, x0_dxy=None, x0_dxy_unc=None, efficiency=eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 10, 10]), torch.Size([6, 10, 10]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, weight = x0inf.pred_x0(False)\n",
    "pred.shape, weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6976e-04,  4.8417e-04],\n",
       "          [-3.0355e-03, -3.3254e-04],\n",
       "          [-8.2080e-04, -1.1511e-04],\n",
       "          ...,\n",
       "          [-3.5594e-03,  7.3850e-04],\n",
       "          [-1.5934e-03, -1.8374e-03],\n",
       "          [-1.7551e-03, -2.6539e-03]],\n",
       "\n",
       "         [[ 1.5949e-04,  4.7943e-04],\n",
       "          [-1.9059e-03, -4.4576e-04],\n",
       "          [-1.0515e-03, -1.2210e-04],\n",
       "          ...,\n",
       "          [-1.7118e-03,  7.1421e-04],\n",
       "          [ 1.8921e-04,  1.1953e-03],\n",
       "          [ 1.2415e-03,  1.4055e-03]],\n",
       "\n",
       "         [[ 3.4928e-05, -1.0278e-03],\n",
       "          [-8.0657e-05, -1.1978e-03],\n",
       "          [-2.6114e-03,  1.7553e-03],\n",
       "          ...,\n",
       "          [ 3.4477e-04,  4.4228e-03],\n",
       "          [ 7.9968e-04,  4.6919e-03],\n",
       "          [ 1.2433e-03,  1.6642e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0626e-03,  3.8680e-03],\n",
       "          [ 4.0724e-03,  5.4639e-03],\n",
       "          [ 2.2293e-04, -2.6398e-05],\n",
       "          ...,\n",
       "          [ 6.2001e-05,  5.4086e-04],\n",
       "          [ 1.4294e-05, -1.6592e-04],\n",
       "          [-9.7119e-06,  8.5583e-05]],\n",
       "\n",
       "         [[ 4.1827e-03,  4.8286e-03],\n",
       "          [ 4.1184e-03,  5.5817e-03],\n",
       "          [ 4.0598e-03,  5.6117e-03],\n",
       "          ...,\n",
       "          [ 4.1304e-07, -1.4743e-05],\n",
       "          [ 2.5593e-06, -1.4184e-05],\n",
       "          [ 2.5214e-04,  7.1014e-05]],\n",
       "\n",
       "         [[ 4.1960e-03,  5.4716e-03],\n",
       "          [ 4.1037e-03,  5.6693e-03],\n",
       "          [ 4.1584e-03,  5.6859e-03],\n",
       "          ...,\n",
       "          [ 4.5405e-05, -9.8543e-05],\n",
       "          [ 1.4183e-04, -6.3163e-04],\n",
       "          [-1.3674e-05, -6.6289e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5216e-04,  4.7266e-04],\n",
       "          [-2.8055e-03, -3.1830e-04],\n",
       "          [-8.3737e-04, -1.1690e-04],\n",
       "          ...,\n",
       "          [-3.5376e-03,  7.2466e-04],\n",
       "          [-9.8582e-04, -1.5838e-03],\n",
       "          [-1.6164e-03, -2.9060e-03]],\n",
       "\n",
       "         [[ 1.5406e-04,  4.5808e-04],\n",
       "          [-5.1294e-04, -1.7349e-04],\n",
       "          [-1.0580e-03, -1.2662e-04],\n",
       "          ...,\n",
       "          [-2.2467e-03,  4.8586e-04],\n",
       "          [ 1.4965e-05,  1.0812e-03],\n",
       "          [ 1.2366e-03,  1.3895e-03]],\n",
       "\n",
       "         [[ 3.4998e-05, -1.0273e-03],\n",
       "          [-7.6127e-05, -8.4617e-04],\n",
       "          [-2.3941e-03,  1.7242e-03],\n",
       "          ...,\n",
       "          [ 6.3578e-04,  4.2396e-03],\n",
       "          [ 1.0779e-03,  4.3791e-03],\n",
       "          [ 1.2531e-03,  1.5648e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0704e-03,  3.9306e-03],\n",
       "          [ 4.0409e-03,  5.4846e-03],\n",
       "          [ 7.1518e-05, -6.9157e-06],\n",
       "          ...,\n",
       "          [ 4.3063e-05,  4.7746e-04],\n",
       "          [ 1.4291e-05, -1.6650e-04],\n",
       "          [ 3.2091e-05,  8.0864e-05]],\n",
       "\n",
       "         [[ 4.1209e-03,  4.8431e-03],\n",
       "          [ 4.1048e-03,  5.5934e-03],\n",
       "          [ 4.1037e-03,  5.6274e-03],\n",
       "          ...,\n",
       "          [-1.4668e-06, -1.7375e-05],\n",
       "          [ 2.4309e-06, -1.1756e-05],\n",
       "          [ 5.5703e-05, -3.1639e-05]],\n",
       "\n",
       "         [[ 4.1955e-03,  5.4750e-03],\n",
       "          [ 4.1150e-03,  5.6736e-03],\n",
       "          [ 4.1696e-03,  5.6786e-03],\n",
       "          ...,\n",
       "          [-1.4983e-05, -7.7953e-05],\n",
       "          [ 3.6138e-04, -6.2627e-04],\n",
       "          [-1.3711e-05, -6.6138e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4321e-04,  4.6407e-04],\n",
       "          [-2.7473e-03, -2.6437e-04],\n",
       "          [-8.7941e-04, -1.1894e-04],\n",
       "          ...,\n",
       "          [-3.5293e-03,  7.1776e-04],\n",
       "          [-3.0086e-04, -1.5820e-03],\n",
       "          [-1.5057e-03, -3.2689e-03]],\n",
       "\n",
       "         [[ 1.4915e-04,  4.4520e-04],\n",
       "          [-1.1486e-04, -6.3972e-05],\n",
       "          [-1.0985e-03, -1.2825e-04],\n",
       "          ...,\n",
       "          [-2.6419e-03,  3.1612e-04],\n",
       "          [-1.4072e-04,  9.8233e-04],\n",
       "          [ 1.2311e-03,  1.3855e-03]],\n",
       "\n",
       "         [[ 3.5043e-05, -1.0251e-03],\n",
       "          [-1.1159e-04, -4.6522e-04],\n",
       "          [-2.2366e-03,  1.7208e-03],\n",
       "          ...,\n",
       "          [ 9.7180e-04,  4.0636e-03],\n",
       "          [ 1.3148e-03,  4.0293e-03],\n",
       "          [ 1.2580e-03,  1.5074e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0490e-03,  3.9689e-03],\n",
       "          [ 4.0130e-03,  5.4947e-03],\n",
       "          [ 2.3126e-05, -3.0013e-06],\n",
       "          ...,\n",
       "          [ 1.9624e-05, -1.0519e-05],\n",
       "          [ 1.3949e-05, -1.6690e-04],\n",
       "          [ 4.3175e-05,  2.1216e-05]],\n",
       "\n",
       "         [[ 4.1507e-03,  4.8399e-03],\n",
       "          [ 4.0912e-03,  5.5945e-03],\n",
       "          [ 4.0884e-03,  5.6371e-03],\n",
       "          ...,\n",
       "          [-2.5835e-06, -7.0932e-06],\n",
       "          [ 2.3838e-06, -7.5866e-06],\n",
       "          [ 3.8267e-05, -4.0391e-05]],\n",
       "\n",
       "         [[ 4.1263e-03,  5.4748e-03],\n",
       "          [ 4.1264e-03,  5.6746e-03],\n",
       "          [ 4.1574e-03,  5.6809e-03],\n",
       "          ...,\n",
       "          [-3.1796e-05, -6.7047e-05],\n",
       "          [ 4.3441e-04, -5.8402e-04],\n",
       "          [-1.4132e-05, -6.6455e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4147e-04,  4.5952e-04],\n",
       "          [-2.7627e-03, -2.0085e-04],\n",
       "          [-9.2532e-04, -1.2171e-04],\n",
       "          ...,\n",
       "          [-3.5240e-03,  7.1684e-04],\n",
       "          [ 2.3333e-04, -1.7232e-03],\n",
       "          [-1.4411e-03, -3.6155e-03]],\n",
       "\n",
       "         [[ 1.4964e-04,  4.2182e-04],\n",
       "          [-1.6582e-05, -2.9914e-05],\n",
       "          [-1.1457e-03, -1.3104e-04],\n",
       "          ...,\n",
       "          [-2.9274e-03,  1.8747e-04],\n",
       "          [-2.6982e-04,  9.0384e-04],\n",
       "          [ 1.2266e-03,  1.3710e-03]],\n",
       "\n",
       "         [[ 3.5165e-05, -1.0186e-03],\n",
       "          [-2.4747e-04,  1.2506e-04],\n",
       "          [-2.1278e-03,  1.7198e-03],\n",
       "          ...,\n",
       "          [ 1.3384e-03,  3.8895e-03],\n",
       "          [ 1.5005e-03,  3.6858e-03],\n",
       "          [ 1.2624e-03,  1.4706e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9959e-03,  3.9855e-03],\n",
       "          [ 4.0391e-03,  5.5172e-03],\n",
       "          [ 1.2934e-05, -6.9049e-07],\n",
       "          ...,\n",
       "          [ 6.9045e-06, -5.4614e-04],\n",
       "          [ 1.4274e-05, -1.6592e-04],\n",
       "          [ 3.8002e-05, -2.4957e-05]],\n",
       "\n",
       "         [[ 4.1475e-03,  4.8219e-03],\n",
       "          [ 4.1343e-03,  5.5950e-03],\n",
       "          [ 4.0717e-03,  5.6506e-03],\n",
       "          ...,\n",
       "          [-2.0173e-06, -8.3717e-06],\n",
       "          [ 2.3628e-06, -9.0713e-06],\n",
       "          [ 3.5069e-05, -4.0564e-05]],\n",
       "\n",
       "         [[ 4.1732e-03,  5.4654e-03],\n",
       "          [ 4.1378e-03,  5.6692e-03],\n",
       "          [ 4.1568e-03,  5.6801e-03],\n",
       "          ...,\n",
       "          [-4.5972e-05, -5.9901e-05],\n",
       "          [ 3.5158e-04, -4.9035e-04],\n",
       "          [-1.4233e-05, -6.6465e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4789e-04,  4.6591e-04],\n",
       "          [-2.8057e-03, -1.4560e-04],\n",
       "          [-9.6731e-04, -1.2635e-04],\n",
       "          ...,\n",
       "          [-3.5180e-03,  7.1142e-04],\n",
       "          [ 3.8167e-04, -2.0519e-03],\n",
       "          [-1.4294e-03, -4.0817e-03]],\n",
       "\n",
       "         [[ 1.5194e-04,  4.0182e-04],\n",
       "          [ 8.4341e-06, -1.8495e-05],\n",
       "          [-1.1889e-03, -1.3427e-04],\n",
       "          ...,\n",
       "          [-3.1269e-03,  8.3907e-05],\n",
       "          [-3.6731e-04,  8.4322e-04],\n",
       "          [ 1.2205e-03,  1.3712e-03]],\n",
       "\n",
       "         [[ 3.5602e-05, -9.9739e-04],\n",
       "          [-6.7466e-04,  9.6739e-04],\n",
       "          [-2.0534e-03,  1.7337e-03],\n",
       "          ...,\n",
       "          [ 1.7123e-03,  3.7083e-03],\n",
       "          [ 1.6332e-03,  3.3550e-03],\n",
       "          [ 1.2622e-03,  1.4376e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9719e-03,  3.9787e-03],\n",
       "          [ 4.0472e-03,  5.5319e-03],\n",
       "          [ 2.8999e-05,  4.0782e-06],\n",
       "          ...,\n",
       "          [ 3.3923e-06, -6.4636e-04],\n",
       "          [ 1.4133e-05, -1.6593e-04],\n",
       "          [ 3.4314e-05, -3.8937e-05]],\n",
       "\n",
       "         [[ 4.1303e-03,  4.7921e-03],\n",
       "          [ 4.0970e-03,  5.5978e-03],\n",
       "          [ 4.0425e-03,  5.6559e-03],\n",
       "          ...,\n",
       "          [-2.0209e-07, -7.4233e-06],\n",
       "          [ 2.3764e-06, -9.1046e-06],\n",
       "          [ 3.5864e-05, -4.0296e-05]],\n",
       "\n",
       "         [[ 4.1630e-03,  5.4531e-03],\n",
       "          [ 4.1607e-03,  5.6760e-03],\n",
       "          [ 4.1675e-03,  5.6951e-03],\n",
       "          ...,\n",
       "          [-8.6145e-05, -3.3833e-05],\n",
       "          [ 2.0227e-04, -3.4420e-04],\n",
       "          [-1.3329e-05, -6.6639e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6616e-04,  4.7809e-04],\n",
       "          [-2.9032e-03, -1.0448e-04],\n",
       "          [-1.0012e-03, -1.3217e-04],\n",
       "          ...,\n",
       "          [-3.5065e-03,  7.1500e-04],\n",
       "          [ 8.9407e-05, -2.4332e-03],\n",
       "          [-1.4682e-03, -4.3552e-03]],\n",
       "\n",
       "         [[ 1.5481e-04,  4.0196e-04],\n",
       "          [ 8.7464e-06, -1.4117e-05],\n",
       "          [-1.2228e-03, -1.3940e-04],\n",
       "          ...,\n",
       "          [-3.2621e-03,  1.3189e-05],\n",
       "          [-4.3196e-04,  7.9411e-04],\n",
       "          [ 1.2182e-03,  1.3628e-03]],\n",
       "\n",
       "         [[ 3.7259e-05, -9.2236e-04],\n",
       "          [-1.6284e-03,  1.5569e-03],\n",
       "          [-2.0095e-03,  1.7506e-03],\n",
       "          ...,\n",
       "          [ 2.0725e-03,  3.5398e-03],\n",
       "          [ 1.7222e-03,  3.1107e-03],\n",
       "          [ 1.2590e-03,  1.4194e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9539e-03,  3.9571e-03],\n",
       "          [ 3.9946e-03,  5.5519e-03],\n",
       "          [ 9.0330e-05,  1.5687e-05],\n",
       "          ...,\n",
       "          [ 2.9382e-06, -6.4902e-04],\n",
       "          [ 1.3711e-05, -1.6089e-04],\n",
       "          [ 3.4787e-05, -4.0569e-05]],\n",
       "\n",
       "         [[ 4.1301e-03,  4.7358e-03],\n",
       "          [ 4.1267e-03,  5.6066e-03],\n",
       "          [ 4.0459e-03,  5.6729e-03],\n",
       "          ...,\n",
       "          [ 1.2018e-06, -9.9778e-06],\n",
       "          [ 2.3685e-06, -9.1282e-06],\n",
       "          [ 3.5594e-05, -4.1313e-05]],\n",
       "\n",
       "         [[ 4.1429e-03,  5.4362e-03],\n",
       "          [ 4.1371e-03,  5.6703e-03],\n",
       "          [ 4.1435e-03,  5.6858e-03],\n",
       "          ...,\n",
       "          [-2.6052e-04,  1.1431e-04],\n",
       "          [ 8.9393e-05, -2.0549e-04],\n",
       "          [-1.3659e-05, -6.6205e-04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].xy, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3767e-02, -3.4700e-02,  3.0571e-02, -8.2881e-01,  5.6464e-01,\n",
       "          -1.7210e-01, -1.4194e-01, -1.4499e-01, -1.9355e+00, -2.1615e+00],\n",
       "         [ 2.2124e-02,  1.0253e-01,  3.9760e-02,  2.6451e-01,  1.8114e-01,\n",
       "           1.3256e-01,  1.4042e-02,  2.8924e-01,  4.4653e-01,  4.5710e-01],\n",
       "         [ 5.7360e-02,  1.3924e-02, -4.5769e-01, -4.6845e-01, -6.8417e-02,\n",
       "          -6.9603e-02,  3.9270e-01,  2.5818e-01,  5.0050e-01,  4.7010e-01],\n",
       "         [ 5.7789e-02,  5.7622e-02, -4.6913e-01, -4.5203e-01,  2.3165e-01,\n",
       "           9.4123e-02,  4.6897e-01,  2.4495e-01,  2.3918e-01, -1.2186e+00],\n",
       "         [ 1.1949e-01, -2.1887e-02,  2.3971e-01,  2.7453e-01,  2.3514e-01,\n",
       "           3.9079e-02,  2.2132e-01,  1.5682e-01,  7.0854e-02, -1.1105e-01],\n",
       "         [-8.5912e-01, -3.1555e-01, -2.0230e-01, -6.2497e-02, -1.1175e+00,\n",
       "           5.5000e-02,  1.9478e-01,  1.6253e-01,  1.6205e-01, -2.6559e+00],\n",
       "         [-2.0999e+00, -1.9445e+00,  6.2242e-02,  1.3614e-01,  7.1574e-02,\n",
       "           3.8566e-01, -1.1116e-02, -1.1077e-02, -2.4399e+00, -3.9734e+00],\n",
       "         [-1.8988e+00, -1.9653e+00, -1.0689e-02,  9.2113e-03, -2.0226e-01,\n",
       "           1.6589e-01,  6.7485e-02, -1.7624e-02, -8.0236e-03,  4.8868e-03],\n",
       "         [-1.8924e+00, -1.9625e+00, -1.9620e+00, -4.3478e-01, -1.1748e-01,\n",
       "          -4.0347e-02,  1.6400e-02, -5.7188e-02, -5.9288e-02, -6.1336e-03],\n",
       "         [-1.9447e+00, -1.9722e+00, -1.9713e+00, -1.9297e+00, -1.1948e-01,\n",
       "          -6.0884e-02, -1.6613e-02,  3.7168e-02, -1.0877e-02, -1.0425e-02]],\n",
       "\n",
       "        [[ 2.2477e-02, -1.2284e-02,  2.6911e-02, -8.3516e-01,  5.6344e-01,\n",
       "           1.5121e-02, -1.4353e-01, -1.4247e-01, -1.8882e+00, -2.2247e+00],\n",
       "         [ 2.1213e-02,  5.7795e-02,  3.4890e-02,  2.3771e-01,  1.8992e-01,\n",
       "           8.7448e-02,  5.3979e-02,  3.0161e-01,  4.3886e-01,  4.5838e-01],\n",
       "         [ 5.7425e-02,  1.5930e-02, -4.5088e-01, -4.6035e-01, -6.8045e-02,\n",
       "          -6.9502e-02,  4.0875e-01,  2.2851e-01,  5.1246e-01,  4.6382e-01],\n",
       "         [ 5.7790e-02,  5.5468e-02, -4.6857e-01, -4.4890e-01,  2.3511e-01,\n",
       "           7.9580e-02,  4.6636e-01,  2.1416e-01,  2.0728e-01, -1.3299e+00],\n",
       "         [ 1.0115e-01, -2.2491e-02,  2.0535e-01,  2.1036e-01,  3.1670e-01,\n",
       "           4.6215e-02,  1.7041e-01,  1.5418e-01,  3.7645e-02, -1.1102e-01],\n",
       "         [-7.2154e-01, -2.8958e-01, -1.9025e-01,  2.1664e-02, -1.0867e+00,\n",
       "           5.9261e-02,  1.6595e-01,  1.6241e-01,  1.6178e-01, -2.6633e+00],\n",
       "         [-2.1221e+00, -1.9243e+00,  6.2555e-02,  8.8338e-02, -5.6901e-02,\n",
       "           4.4240e-01, -1.1040e-02, -1.1071e-02, -2.7761e+00, -3.9746e+00],\n",
       "         [-1.9097e+00, -1.9688e+00,  2.3078e-02,  1.1709e-02, -1.9450e-01,\n",
       "           1.6846e-01,  2.9901e-02, -1.1863e-02, -8.0191e-03,  6.4470e-03],\n",
       "         [-1.8945e+00, -1.9630e+00, -1.9631e+00, -4.3913e-01, -1.1844e-01,\n",
       "          -4.0894e-02,  2.1173e-02, -5.8276e-02, -5.9277e-02,  4.0060e-03],\n",
       "         [-1.9447e+00, -1.9723e+00, -1.9714e+00, -1.9230e+00, -1.1918e-01,\n",
       "          -9.3671e-02, -1.6650e-02,  3.7275e-02, -3.4258e-04, -1.0426e-02]],\n",
       "\n",
       "        [[ 2.2018e-02,  1.4977e-02,  2.2627e-02, -8.2256e-01,  5.6245e-01,\n",
       "           5.5740e-02, -1.5579e-01, -1.4149e-01, -1.8537e+00, -2.2966e+00],\n",
       "         [ 2.0587e-02,  4.0308e-02,  3.0522e-02,  1.9821e-01,  2.1653e-01,\n",
       "           7.8328e-02,  5.8714e-02,  3.0454e-01,  4.3107e-01,  4.5888e-01],\n",
       "         [ 5.7375e-02,  9.7013e-03, -4.4880e-01, -4.5429e-01, -6.7271e-02,\n",
       "          -6.9844e-02,  4.1473e-01,  1.9218e-01,  5.0656e-01,  4.5979e-01],\n",
       "         [ 5.7789e-02,  5.3196e-02, -4.6824e-01, -4.4641e-01,  2.4080e-01,\n",
       "           1.3389e-01,  4.5891e-01,  1.7440e-01,  1.6338e-01, -1.4658e+00],\n",
       "         [ 9.2953e-02, -1.9021e-02,  1.8465e-01,  1.8537e-01,  3.7869e-01,\n",
       "           5.0008e-02,  1.6142e-01,  1.4688e-01, -4.3919e-03, -1.1101e-01],\n",
       "         [-6.3586e-01, -2.6973e-01, -1.8787e-01,  4.0828e-02, -9.9231e-01,\n",
       "           6.3257e-02,  1.6109e-01,  1.6209e-01,  1.6101e-01, -2.6706e+00],\n",
       "         [-2.1489e+00, -1.9053e+00,  6.2671e-02,  7.2463e-02, -1.3145e-01,\n",
       "           4.9459e-01, -1.0791e-02, -1.1049e-02, -3.2476e+00, -3.9756e+00],\n",
       "         [-1.9212e+00, -1.9727e+00,  3.4423e-02,  1.7556e-02, -1.9385e-01,\n",
       "           1.7326e-01,  2.6093e-02,  5.4280e-03, -8.0189e-03,  6.3618e-03],\n",
       "         [-1.8952e+00, -1.9633e+00, -1.9641e+00, -4.4551e-01, -1.1877e-01,\n",
       "          -4.4855e-02,  2.9932e-02, -5.8799e-02, -5.9272e-02,  5.1623e-03],\n",
       "         [-1.9439e+00, -1.9721e+00, -1.9714e+00, -1.9063e+00, -1.1913e-01,\n",
       "          -1.1265e-01, -1.6826e-02,  3.7125e-02,  4.6123e-03, -1.0427e-02]],\n",
       "\n",
       "        [[ 2.2094e-02,  3.4677e-02,  1.8018e-02, -7.9737e-01,  5.6189e-01,\n",
       "           6.5125e-02, -1.7931e-01, -1.4112e-01, -1.8565e+00, -2.3736e+00],\n",
       "         [ 1.9772e-02,  3.5517e-02,  2.6269e-02,  1.5363e-01,  2.4320e-01,\n",
       "           7.7275e-02,  6.2469e-02,  3.0238e-01,  4.2314e-01,  4.5868e-01],\n",
       "         [ 5.7161e-02, -8.7548e-03, -4.4989e-01, -4.4744e-01, -6.4447e-02,\n",
       "          -7.0984e-02,  4.1113e-01,  1.5078e-01,  4.8515e-01,  4.5642e-01],\n",
       "         [ 5.7785e-02,  4.9185e-02, -4.6809e-01, -4.4410e-01,  2.5047e-01,\n",
       "           2.3935e-01,  4.4613e-01,  1.2578e-01,  1.0499e-01, -1.6091e+00],\n",
       "         [ 8.3551e-02, -1.0322e-02,  1.7304e-01,  1.7572e-01,  4.0284e-01,\n",
       "           4.9297e-02,  1.5963e-01,  1.2643e-01, -4.6536e-02, -1.1101e-01],\n",
       "         [-5.8567e-01, -2.5413e-01, -1.9459e-01,  1.6094e-02, -8.8472e-01,\n",
       "           6.4921e-02,  1.6010e-01,  1.6119e-01,  1.5884e-01, -2.6778e+00],\n",
       "         [-2.1825e+00, -1.8867e+00,  6.2621e-02,  6.6835e-02, -1.6677e-01,\n",
       "           5.2660e-01, -8.2517e-03, -1.0777e-02, -3.6372e+00, -3.9768e+00],\n",
       "         [-1.9342e+00, -1.9767e+00,  3.5571e-02,  1.7637e-02, -1.9414e-01,\n",
       "           1.7611e-01,  2.5373e-02,  2.0539e-02, -8.0201e-03,  5.7830e-03],\n",
       "         [-1.8947e+00, -1.9634e+00, -1.9649e+00, -4.5452e-01, -1.1889e-01,\n",
       "          -6.7622e-02,  8.0941e-03, -5.9051e-02, -5.9273e-02,  5.3677e-03],\n",
       "         [-1.9425e+00, -1.9719e+00, -1.9712e+00, -1.8804e+00, -1.1912e-01,\n",
       "          -1.1812e-01, -1.7275e-02,  3.6270e-02, -1.7742e-03, -1.0429e-02]],\n",
       "\n",
       "        [[ 2.2517e-02,  3.9381e-02,  1.3294e-02, -7.8371e-01,  5.6216e-01,\n",
       "           6.5379e-02, -2.0274e-01, -1.4110e-01, -1.9108e+00, -2.4524e+00],\n",
       "         [ 1.8583e-02,  3.3993e-02,  2.2070e-02,  1.1268e-01,  2.3587e-01,\n",
       "           7.6690e-02,  6.0218e-02,  2.9749e-01,  4.1508e-01,  4.5782e-01],\n",
       "         [ 5.6517e-02, -4.7203e-02, -4.5267e-01, -4.3640e-01, -5.0477e-02,\n",
       "          -7.4166e-02,  3.9596e-01,  1.0681e-01,  4.5284e-01,  4.5267e-01],\n",
       "         [ 5.7774e-02,  3.9113e-02, -4.6802e-01, -4.4160e-01,  2.6733e-01,\n",
       "           3.8657e-01,  4.2557e-01,  7.0661e-02,  3.0994e-02, -1.7388e+00],\n",
       "         [ 4.2342e-02,  6.1341e-03,  1.6659e-01,  1.7172e-01,  3.9701e-01,\n",
       "           4.1762e-02,  1.5915e-01,  6.5135e-02, -7.8234e-02, -1.1101e-01],\n",
       "         [-5.6121e-01, -2.4175e-01, -2.0543e-01, -2.3961e-02, -8.0551e-01,\n",
       "           6.0939e-02,  1.5985e-01,  1.5826e-01,  1.5178e-01, -2.6851e+00],\n",
       "         [-2.2255e+00, -1.8673e+00,  6.2335e-02,  6.4536e-02, -1.8276e-01,\n",
       "           5.2053e-01,  1.3649e-02, -5.7033e-03, -3.8118e+00, -3.9778e+00],\n",
       "         [-1.9500e+00, -1.9805e+00,  2.7485e-02,  8.1797e-03, -1.9410e-01,\n",
       "           1.7543e-01,  2.4785e-02,  2.3239e-02, -8.0267e-03,  5.5580e-03],\n",
       "         [-1.8932e+00, -1.9632e+00, -1.9657e+00, -4.6816e-01, -1.1891e-01,\n",
       "          -1.0333e-01, -3.3114e-02, -5.9160e-02, -5.9272e-02,  5.4024e-03],\n",
       "         [-1.9401e+00, -1.9715e+00, -1.9708e+00, -1.8553e+00, -1.1910e-01,\n",
       "          -1.1908e-01, -1.8051e-02,  3.2934e-02, -1.8111e-02, -1.0431e-02]],\n",
       "\n",
       "        [[ 2.3149e-02,  3.1940e-02,  8.6204e-03, -8.0243e-01,  5.6435e-01,\n",
       "           5.6907e-02, -2.1050e-01, -1.4140e-01, -2.0085e+00, -2.5270e+00],\n",
       "         [ 1.7513e-02,  3.3036e-02,  1.7976e-02,  8.0602e-02,  1.9914e-01,\n",
       "           7.4883e-02,  4.6200e-02,  2.9101e-01,  4.0681e-01,  4.5614e-01],\n",
       "         [ 5.4325e-02, -1.0761e-01, -4.5575e-01, -4.1752e-01,  3.6152e-02,\n",
       "          -7.9954e-02,  3.6312e-01,  6.2998e-02,  4.1365e-01,  4.4761e-01],\n",
       "         [ 5.7724e-02,  6.2546e-03, -4.6799e-01, -4.3856e-01,  2.9719e-01,\n",
       "           5.6108e-01,  3.9256e-01,  1.4381e-02, -5.6575e-02, -1.8383e+00],\n",
       "         [-1.0383e-01,  3.0373e-02,  1.6273e-01,  1.6976e-01,  3.8029e-01,\n",
       "           2.7872e-02,  1.5882e-01, -1.1108e-01, -9.5624e-02, -1.1102e-01],\n",
       "         [-5.5794e-01, -2.3211e-01, -2.1462e-01, -4.9147e-02, -7.6775e-01,\n",
       "           5.0925e-02,  1.5972e-01,  1.4683e-01,  1.2435e-01, -2.6922e+00],\n",
       "         [-2.2810e+00, -1.8522e+00,  6.1476e-02,  6.3225e-02, -1.9013e-01,\n",
       "           4.5431e-01,  2.1588e-02,  2.1395e-02, -3.8520e+00, -3.9789e+00],\n",
       "         [-1.9703e+00, -1.9846e+00,  9.5704e-04, -1.9492e-02, -1.9326e-01,\n",
       "           1.7034e-01,  2.4755e-02,  2.3376e-02, -8.1580e-03,  5.5211e-03],\n",
       "         [-1.8907e+00, -1.9628e+00, -1.9666e+00, -4.9073e-01, -1.1885e-01,\n",
       "          -1.1413e-01, -5.7243e-02, -5.9219e-02, -5.9273e-02,  5.3558e-03],\n",
       "         [-1.9369e+00, -1.9709e+00, -1.9703e+00, -1.8450e+00, -1.1905e-01,\n",
       "          -1.1919e-01, -1.9552e-02,  1.7952e-02, -3.5770e-02, -1.0433e-02]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].z, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-9.1348e-05, -3.8875e-04],\n",
       "          [ 2.6553e-03,  2.9941e-04],\n",
       "          [ 6.0583e-04,  6.1040e-05],\n",
       "          ...,\n",
       "          [ 3.2613e-03,  2.5556e-04],\n",
       "          [ 7.0767e-04, -1.0104e-03],\n",
       "          [ 9.8906e-04, -1.3887e-03]],\n",
       "\n",
       "         [[-9.4023e-05, -3.8872e-04],\n",
       "          [ 1.6346e-03,  3.7913e-04],\n",
       "          [ 7.8775e-04,  6.7353e-05],\n",
       "          ...,\n",
       "          [ 1.3053e-03,  2.9402e-04],\n",
       "          [ 5.7577e-05,  5.0583e-04],\n",
       "          [-6.6746e-04,  5.7088e-04]],\n",
       "\n",
       "         [[-7.5802e-06,  7.8429e-04],\n",
       "          [ 1.0955e-04,  9.3066e-04],\n",
       "          [ 1.0856e-03, -1.0134e-03],\n",
       "          ...,\n",
       "          [-2.1768e-04,  1.8563e-03],\n",
       "          [-4.7002e-04,  1.9644e-03],\n",
       "          [-6.7255e-04,  6.8122e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0289e-03, -2.5164e-03],\n",
       "          [ 2.1052e-03, -3.5506e-03],\n",
       "          [ 1.4289e-04,  4.1022e-05],\n",
       "          ...,\n",
       "          [ 2.4325e-05,  2.5899e-04],\n",
       "          [ 6.6162e-06, -1.1762e-04],\n",
       "          [-4.8937e-06,  5.9119e-05]],\n",
       "\n",
       "         [[ 2.1545e-03, -3.1062e-03],\n",
       "          [ 2.1470e-03, -3.6098e-03],\n",
       "          [ 2.1130e-03, -3.6307e-03],\n",
       "          ...,\n",
       "          [ 9.8969e-08, -1.1353e-05],\n",
       "          [ 1.5330e-06, -7.5589e-06],\n",
       "          [ 1.2408e-04, -7.1351e-05]],\n",
       "\n",
       "         [[ 2.1879e-03, -3.5185e-03],\n",
       "          [ 2.1457e-03, -3.6632e-03],\n",
       "          [ 2.1735e-03, -3.6728e-03],\n",
       "          ...,\n",
       "          [ 4.6742e-05, -8.2795e-05],\n",
       "          [ 1.3957e-04, -4.8780e-04],\n",
       "          [-1.2460e-05, -5.0058e-04]]],\n",
       "\n",
       "\n",
       "        [[[-7.8941e-05, -3.8157e-04],\n",
       "          [ 2.4626e-03,  2.7947e-04],\n",
       "          [ 6.4074e-04,  6.1193e-05],\n",
       "          ...,\n",
       "          [ 3.2448e-03,  2.4857e-04],\n",
       "          [ 1.6166e-04, -8.5295e-04],\n",
       "          [ 9.1437e-04, -1.4774e-03]],\n",
       "\n",
       "         [[-8.9532e-05, -3.7294e-04],\n",
       "          [ 4.2608e-04,  1.4086e-04],\n",
       "          [ 8.1606e-04,  6.8233e-05],\n",
       "          ...,\n",
       "          [ 1.6780e-03,  2.2235e-04],\n",
       "          [ 1.7914e-04,  4.5907e-04],\n",
       "          [-6.6381e-04,  5.6396e-04]],\n",
       "\n",
       "         [[-7.6184e-06,  7.8393e-04],\n",
       "          [ 1.1294e-04,  6.6324e-04],\n",
       "          [ 8.9307e-04, -9.9819e-04],\n",
       "          ...,\n",
       "          [-3.6602e-04,  1.7646e-03],\n",
       "          [-6.1273e-04,  1.8210e-03],\n",
       "          [-6.7835e-04,  6.3848e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0298e-03, -2.5538e-03],\n",
       "          [ 2.0877e-03, -3.5635e-03],\n",
       "          [ 6.1074e-05,  2.2580e-05],\n",
       "          ...,\n",
       "          [ 1.5035e-05,  2.2990e-04],\n",
       "          [ 6.6164e-06, -1.1802e-04],\n",
       "          [ 1.6609e-05,  5.6689e-05]],\n",
       "\n",
       "         [[ 2.1208e-03, -3.1139e-03],\n",
       "          [ 2.1396e-03, -3.6171e-03],\n",
       "          [ 2.1355e-03, -3.6405e-03],\n",
       "          ...,\n",
       "          [-1.7402e-06, -1.0464e-05],\n",
       "          [ 1.4713e-06, -6.1760e-06],\n",
       "          [ 2.7946e-05, -3.9533e-05]],\n",
       "\n",
       "         [[ 2.1873e-03, -3.5197e-03],\n",
       "          [ 2.1515e-03, -3.6658e-03],\n",
       "          [ 2.1793e-03, -3.6679e-03],\n",
       "          ...,\n",
       "          [-1.5982e-05, -6.1737e-05],\n",
       "          [ 3.4548e-04, -4.8330e-04],\n",
       "          [-1.2493e-05, -4.9943e-04]]],\n",
       "\n",
       "\n",
       "        [[[-7.2313e-05, -3.7509e-04],\n",
       "          [ 2.4281e-03,  2.2083e-04],\n",
       "          [ 6.9454e-04,  6.1261e-05],\n",
       "          ...,\n",
       "          [ 3.2385e-03,  2.4532e-04],\n",
       "          [-4.5937e-04, -8.1594e-04],\n",
       "          [ 8.5453e-04, -1.6170e-03]],\n",
       "\n",
       "         [[-8.6093e-05, -3.6333e-04],\n",
       "          [ 8.8644e-05,  4.8894e-05],\n",
       "          [ 8.6818e-04,  6.7548e-05],\n",
       "          ...,\n",
       "          [ 1.9529e-03,  1.6728e-04],\n",
       "          [ 2.8724e-04,  4.1975e-04],\n",
       "          [-6.5980e-04,  5.6214e-04]],\n",
       "\n",
       "         [[-7.5820e-06,  7.8227e-04],\n",
       "          [ 1.5586e-04,  3.7457e-04],\n",
       "          [ 7.4247e-04, -9.9486e-04],\n",
       "          ...,\n",
       "          [-5.3705e-04,  1.6747e-03],\n",
       "          [-7.3267e-04,  1.6637e-03],\n",
       "          [-6.8129e-04,  6.1364e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0140e-03, -2.5741e-03],\n",
       "          [ 2.0709e-03, -3.5692e-03],\n",
       "          [ 3.4615e-05,  1.6466e-05],\n",
       "          ...,\n",
       "          [ 5.0946e-06, -9.3860e-06],\n",
       "          [ 6.4582e-06, -1.1830e-04],\n",
       "          [ 2.2184e-05,  1.3102e-05]],\n",
       "\n",
       "         [[ 2.1344e-03, -3.1091e-03],\n",
       "          [ 2.1319e-03, -3.6174e-03],\n",
       "          [ 2.1268e-03, -3.6463e-03],\n",
       "          ...,\n",
       "          [-3.0327e-06, -4.1021e-06],\n",
       "          [ 1.4449e-06, -3.9769e-06],\n",
       "          [ 1.9529e-05, -3.4816e-05]],\n",
       "\n",
       "         [[ 2.1506e-03, -3.5180e-03],\n",
       "          [ 2.1573e-03, -3.6661e-03],\n",
       "          [ 2.1728e-03, -3.6689e-03],\n",
       "          ...,\n",
       "          [-3.3505e-05, -5.2387e-05],\n",
       "          [ 4.0373e-04, -4.5227e-04],\n",
       "          [-1.2876e-05, -5.0181e-04]]],\n",
       "\n",
       "\n",
       "        [[[-7.0955e-05, -3.7077e-04],\n",
       "          [ 2.4571e-03,  1.5269e-04],\n",
       "          [ 7.4897e-04,  6.1736e-05],\n",
       "          ...,\n",
       "          [ 3.2341e-03,  2.4468e-04],\n",
       "          [-9.3667e-04, -8.5007e-04],\n",
       "          [ 8.1953e-04, -1.7508e-03]],\n",
       "\n",
       "         [[-8.7574e-05, -3.4475e-04],\n",
       "          [ 7.4761e-06,  2.1281e-05],\n",
       "          [ 9.2271e-04,  6.7693e-05],\n",
       "          ...,\n",
       "          [ 2.1515e-03,  1.2432e-04],\n",
       "          [ 3.7718e-04,  3.8909e-04],\n",
       "          [-6.5657e-04,  5.5613e-04]],\n",
       "\n",
       "         [[-7.4481e-06,  7.7728e-04],\n",
       "          [ 2.9620e-04, -7.3163e-05],\n",
       "          [ 6.2625e-04, -9.8996e-04],\n",
       "          ...,\n",
       "          [-7.2321e-04,  1.5856e-03],\n",
       "          [-8.2551e-04,  1.5110e-03],\n",
       "          [-6.8382e-04,  5.9762e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9790e-03, -2.5782e-03],\n",
       "          [ 2.0818e-03, -3.5831e-03],\n",
       "          [ 2.8367e-05,  1.5579e-05],\n",
       "          ...,\n",
       "          [ 1.8403e-06, -2.7454e-04],\n",
       "          [ 6.6078e-06, -1.1761e-04],\n",
       "          [ 1.9519e-05, -2.0573e-05]],\n",
       "\n",
       "         [[ 2.1296e-03, -3.0938e-03],\n",
       "          [ 2.1537e-03, -3.6170e-03],\n",
       "          [ 2.1170e-03, -3.6543e-03],\n",
       "          ...,\n",
       "          [-2.6195e-06, -4.3826e-06],\n",
       "          [ 1.4344e-06, -4.7222e-06],\n",
       "          [ 1.7982e-05, -3.3062e-05]],\n",
       "\n",
       "         [[ 2.1744e-03, -3.5095e-03],\n",
       "          [ 2.1631e-03, -3.6622e-03],\n",
       "          [ 2.1722e-03, -3.6677e-03],\n",
       "          ...,\n",
       "          [-4.8990e-05, -4.7808e-05],\n",
       "          [ 3.0831e-04, -3.8544e-04],\n",
       "          [-1.2968e-05, -5.0187e-04]]],\n",
       "\n",
       "\n",
       "        [[[-7.5380e-05, -3.7452e-04],\n",
       "          [ 2.5063e-03,  9.4672e-05],\n",
       "          [ 7.9678e-04,  6.3308e-05],\n",
       "          ...,\n",
       "          [ 3.2284e-03,  2.4286e-04],\n",
       "          [-1.0628e-03, -9.9205e-04],\n",
       "          [ 8.1311e-04, -1.9549e-03]],\n",
       "\n",
       "         [[-9.1573e-05, -3.2851e-04],\n",
       "          [-1.2436e-05,  1.2284e-05],\n",
       "          [ 9.7054e-04,  6.8279e-05],\n",
       "          ...,\n",
       "          [ 2.2903e-03,  8.8853e-05],\n",
       "          [ 4.4468e-04,  3.6592e-04],\n",
       "          [-6.5261e-04,  5.5611e-04]],\n",
       "\n",
       "         [[-7.0784e-06,  7.6120e-04],\n",
       "          [ 6.9991e-04, -7.1662e-04],\n",
       "          [ 5.4383e-04, -9.9224e-04],\n",
       "          ...,\n",
       "          [-9.1326e-04,  1.4944e-03],\n",
       "          [-8.9094e-04,  1.3663e-03],\n",
       "          [-6.8379e-04,  5.8338e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9559e-03, -2.5642e-03],\n",
       "          [ 2.0830e-03, -3.5920e-03],\n",
       "          [ 3.5279e-05,  1.8928e-05],\n",
       "          ...,\n",
       "          [ 1.0449e-06, -3.2441e-04],\n",
       "          [ 6.5332e-06, -1.1764e-04],\n",
       "          [ 1.7650e-05, -3.0749e-05]],\n",
       "\n",
       "         [[ 2.1166e-03, -3.0690e-03],\n",
       "          [ 2.1330e-03, -3.6180e-03],\n",
       "          [ 2.1002e-03, -3.6567e-03],\n",
       "          ...,\n",
       "          [-9.0906e-07, -3.9075e-06],\n",
       "          [ 1.4478e-06, -4.7368e-06],\n",
       "          [ 1.8409e-05, -3.2520e-05]],\n",
       "\n",
       "         [[ 2.1680e-03, -3.4980e-03],\n",
       "          [ 2.1749e-03, -3.6659e-03],\n",
       "          [ 2.1774e-03, -3.6765e-03],\n",
       "          ...,\n",
       "          [-9.3523e-05, -3.2498e-05],\n",
       "          [ 1.5240e-04, -2.7694e-04],\n",
       "          [-1.2144e-05, -5.0316e-04]]],\n",
       "\n",
       "\n",
       "        [[[-8.7262e-05, -3.8184e-04],\n",
       "          [ 2.5993e-03,  5.4037e-05],\n",
       "          [ 8.3391e-04,  6.5644e-05],\n",
       "          ...,\n",
       "          [ 3.2169e-03,  2.4445e-04],\n",
       "          [-7.8668e-04, -1.1741e-03],\n",
       "          [ 8.3398e-04, -2.0721e-03]],\n",
       "\n",
       "         [[-9.4605e-05, -3.2764e-04],\n",
       "          [-1.1833e-05,  8.7787e-06],\n",
       "          [ 1.0067e-03,  7.0111e-05],\n",
       "          ...,\n",
       "          [ 2.3846e-03,  6.4651e-05],\n",
       "          [ 4.8944e-04,  3.4763e-04],\n",
       "          [-6.5093e-04,  5.5256e-04]],\n",
       "\n",
       "         [[-5.9124e-06,  7.0417e-04],\n",
       "          [ 1.5535e-03, -1.1767e-03],\n",
       "          [ 4.9499e-04, -9.9677e-04],\n",
       "          ...,\n",
       "          [-1.0973e-03,  1.4112e-03],\n",
       "          [-9.3387e-04,  1.2595e-03],\n",
       "          [-6.8200e-04,  5.7520e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9335e-03, -2.5364e-03],\n",
       "          [ 2.0515e-03, -3.6046e-03],\n",
       "          [ 6.3243e-05,  3.0372e-05],\n",
       "          ...,\n",
       "          [ 9.0912e-07, -3.2575e-04],\n",
       "          [ 6.1493e-06, -1.1464e-04],\n",
       "          [ 1.7901e-05, -3.1911e-05]],\n",
       "\n",
       "         [[ 2.1106e-03, -3.0249e-03],\n",
       "          [ 2.1471e-03, -3.6225e-03],\n",
       "          [ 2.1001e-03, -3.6661e-03],\n",
       "          ...,\n",
       "          [ 4.3364e-07, -5.3284e-06],\n",
       "          [ 1.4464e-06, -4.7567e-06],\n",
       "          [ 1.8257e-05, -3.3622e-05]],\n",
       "\n",
       "         [[ 2.1560e-03, -3.4825e-03],\n",
       "          [ 2.1622e-03, -3.6612e-03],\n",
       "          [ 2.1644e-03, -3.6692e-03],\n",
       "          ...,\n",
       "          [-2.8461e-04,  6.2879e-05],\n",
       "          [ 4.5858e-05, -1.6723e-04],\n",
       "          [-1.2443e-05, -4.9985e-04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(pred, volume.get_detectors()[0].panels[0].xy_span, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3256e+01, -8.1994e+00],\n",
       "          [ 6.4156e+02, -4.4952e+02],\n",
       "          [ 2.1540e+03, -6.6231e+03],\n",
       "          ...,\n",
       "          [ 1.4974e+03,  1.7462e+02],\n",
       "          [-1.0064e+01,  1.4480e+01],\n",
       "          [-2.5797e+00,  1.2969e+00]],\n",
       "\n",
       "         [[-4.5361e+01, -7.0577e+01],\n",
       "          [ 5.7069e+03, -4.1217e+03],\n",
       "          [ 1.1751e+04, -1.4882e+04],\n",
       "          ...,\n",
       "          [ 8.2668e+02, -1.1485e+01],\n",
       "          [-1.1945e+03, -9.8843e+01],\n",
       "          [-5.4327e+02,  2.2612e+02]],\n",
       "\n",
       "         [[-3.4595e+03, -2.1071e+04],\n",
       "          [-1.1314e+02, -1.5155e+01],\n",
       "          [-5.0500e+01, -1.4086e+02],\n",
       "          ...,\n",
       "          [-1.5531e+03,  7.6615e+02],\n",
       "          [-2.3810e+02, -2.2313e+01],\n",
       "          [-6.5837e+01, -8.8360e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8265e+00,  6.7330e+00],\n",
       "          [ 5.6487e+01, -6.3804e+00],\n",
       "          [ 3.7766e+02, -1.5772e+03],\n",
       "          ...,\n",
       "          [ 3.6220e+03,  4.0498e+04],\n",
       "          [ 5.0224e+05,  1.2664e+06],\n",
       "          [-1.6982e+03, -5.0803e+02]],\n",
       "\n",
       "         [[ 7.6026e-01,  4.0496e+00],\n",
       "          [ 1.3828e+01,  1.6667e+01],\n",
       "          [ 2.1635e+01,  1.0091e-01],\n",
       "          ...,\n",
       "          [-6.3088e+02,  3.2592e+03],\n",
       "          [-9.1352e+01,  4.7688e+03],\n",
       "          [-1.0064e+01, -1.0259e+00]],\n",
       "\n",
       "         [[ 1.5819e-02,  5.4173e-01],\n",
       "          [ 6.6640e-01,  3.4921e+00],\n",
       "          [ 1.1652e+00,  2.7436e+00],\n",
       "          ...,\n",
       "          [-1.0988e+05,  1.3326e+05],\n",
       "          [ 1.4718e+04,  5.0730e+04],\n",
       "          [-4.5116e+01, -2.2674e+02]]],\n",
       "\n",
       "\n",
       "        [[[-1.8013e+01, -1.3488e+01],\n",
       "          [ 2.5755e+02, -8.0170e+02],\n",
       "          [-1.1418e+04, -1.3024e+04],\n",
       "          ...,\n",
       "          [-3.8294e+02,  1.4166e+03],\n",
       "          [-1.2841e+01,  1.6066e+01],\n",
       "          [-2.9877e+00,  1.6208e+00]],\n",
       "\n",
       "         [[-6.2183e+01, -1.0311e+02],\n",
       "          [ 8.0013e+02, -1.6188e+04],\n",
       "          [-6.8542e+03, -2.8918e+04],\n",
       "          ...,\n",
       "          [-1.2140e+00,  1.4512e+02],\n",
       "          [-2.0316e+03,  3.9202e+02],\n",
       "          [-7.8702e+02,  6.5621e+02]],\n",
       "\n",
       "         [[-5.8534e+03, -4.3348e+04],\n",
       "          [-1.8094e+02, -4.4058e+02],\n",
       "          [-9.3703e+01, -1.7580e+02],\n",
       "          ...,\n",
       "          [-1.6477e+03,  1.0355e+03],\n",
       "          [-2.9616e+02, -3.7872e+01],\n",
       "          [-9.4622e+01, -9.4506e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9995e+00,  6.0887e+00],\n",
       "          [ 5.8177e+01, -1.3993e+01],\n",
       "          [ 5.6560e+02, -5.6252e+03],\n",
       "          ...,\n",
       "          [ 4.2245e+04,  3.6887e+05],\n",
       "          [ 2.5001e+06,  4.7246e+06],\n",
       "          [ 3.3112e+03,  9.1716e+03]],\n",
       "\n",
       "         [[ 7.9784e-01,  3.8749e+00],\n",
       "          [ 1.4258e+01,  1.4509e+01],\n",
       "          [ 2.2301e+01, -2.9692e+00],\n",
       "          ...,\n",
       "          [-4.5605e+02,  7.1664e+03],\n",
       "          [ 1.5566e+03,  1.0503e+04],\n",
       "          [-6.5831e+01,  2.3307e+00]],\n",
       "\n",
       "         [[ 1.7926e-02,  5.2960e-01],\n",
       "          [ 6.9163e-01,  3.3370e+00],\n",
       "          [ 1.2154e+00,  2.5185e+00],\n",
       "          ...,\n",
       "          [-1.9830e+05,  6.2930e+05],\n",
       "          [ 9.7260e+03,  9.1305e+04],\n",
       "          [ 5.8655e+01, -6.9699e+02]]],\n",
       "\n",
       "\n",
       "        [[[-2.1373e+01, -1.6771e+01],\n",
       "          [-1.0259e+03, -1.2703e+03],\n",
       "          [-3.7409e+04, -2.0224e+04],\n",
       "          ...,\n",
       "          [-5.4004e+03,  3.5509e+03],\n",
       "          [-1.5994e+01,  1.7410e+01],\n",
       "          [-3.3240e+00,  1.9640e+00]],\n",
       "\n",
       "         [[-7.4218e+01, -1.2269e+02],\n",
       "          [-8.7902e+04, -5.6123e+04],\n",
       "          [-4.7808e+04, -4.4608e+04],\n",
       "          ...,\n",
       "          [-1.3679e+03,  3.5056e+02],\n",
       "          [-3.0231e+03,  1.1449e+03],\n",
       "          [-1.0211e+03,  1.2500e+03]],\n",
       "\n",
       "         [[-6.4899e+03, -5.4296e+04],\n",
       "          [-1.9059e+02, -8.5123e+02],\n",
       "          [-1.4858e+02, -2.0646e+02],\n",
       "          ...,\n",
       "          [-1.6331e+03,  1.2233e+03],\n",
       "          [-3.4348e+02, -3.9427e+01],\n",
       "          [-1.2191e+02, -8.3462e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0224e+00,  5.2707e+00],\n",
       "          [ 5.7748e+01, -2.0551e+01],\n",
       "          [ 3.3721e+02, -1.1766e+04],\n",
       "          ...,\n",
       "          [ 1.1147e+05,  1.2766e+06],\n",
       "          [ 3.4699e+06,  4.1559e+06],\n",
       "          [ 7.7983e+04,  1.0490e+05]],\n",
       "\n",
       "         [[ 8.1050e-01,  3.5755e+00],\n",
       "          [ 1.4232e+01,  1.2069e+01],\n",
       "          [ 2.2152e+01, -5.6426e+00],\n",
       "          ...,\n",
       "          [ 4.4215e+02,  1.2366e+04],\n",
       "          [ 5.2913e+03,  1.8056e+04],\n",
       "          [-2.3632e+02,  4.7940e+01]],\n",
       "\n",
       "         [[ 2.0304e-02,  5.0016e-01],\n",
       "          [ 7.0068e-01,  3.0762e+00],\n",
       "          [ 1.2187e+00,  2.2222e+00],\n",
       "          ...,\n",
       "          [ 2.7477e+05,  1.2615e+06],\n",
       "          [ 1.2138e+03,  1.2800e+05],\n",
       "          [ 5.0171e+01, -1.2853e+03]]],\n",
       "\n",
       "\n",
       "        [[[-2.2143e+01, -1.6360e+01],\n",
       "          [-2.8913e+03, -1.7526e+03],\n",
       "          [-6.5961e+04, -2.4827e+04],\n",
       "          ...,\n",
       "          [-1.1903e+04,  5.5357e+03],\n",
       "          [-1.8418e+01,  1.8216e+01],\n",
       "          [-3.5296e+00,  2.2416e+00]],\n",
       "\n",
       "         [[-7.7353e+01, -1.2032e+02],\n",
       "          [-3.5349e+05, -1.3545e+05],\n",
       "          [-9.5776e+04, -5.4581e+04],\n",
       "          ...,\n",
       "          [-3.0023e+03,  5.2702e+02],\n",
       "          [-3.9357e+03,  2.0110e+03],\n",
       "          [-1.1857e+03,  1.8876e+03]],\n",
       "\n",
       "         [[-4.7347e+03, -4.2959e+04],\n",
       "          [-1.1642e+02, -8.4919e+02],\n",
       "          [-2.0967e+02, -2.2777e+02],\n",
       "          ...,\n",
       "          [-1.5092e+03,  1.2958e+03],\n",
       "          [-3.6859e+02, -2.4055e+01],\n",
       "          [-1.4080e+02, -5.3950e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8943e+00,  4.3535e+00],\n",
       "          [ 5.5182e+01, -2.5304e+01],\n",
       "          [-4.0253e+02, -1.5817e+04],\n",
       "          ...,\n",
       "          [ 1.8551e+05,  1.8399e+06],\n",
       "          [ 1.2874e+06,  8.6312e+04],\n",
       "          [ 2.9683e+05,  3.5349e+05]],\n",
       "\n",
       "         [[ 7.8838e-01,  3.1948e+00],\n",
       "          [ 1.3685e+01,  9.5115e+00],\n",
       "          [ 2.1119e+01, -7.7170e+00],\n",
       "          ...,\n",
       "          [ 2.0271e+03,  1.6665e+04],\n",
       "          [ 1.0128e+04,  2.3935e+04],\n",
       "          [-4.9363e+02,  1.7091e+02]],\n",
       "\n",
       "         [[ 2.0885e-02,  4.5678e-01],\n",
       "          [ 6.8082e-01,  2.7451e+00],\n",
       "          [ 1.1704e+00,  1.8949e+00],\n",
       "          ...,\n",
       "          [ 1.0740e+06,  9.7274e+05],\n",
       "          [ 1.8111e+04,  1.1218e+05],\n",
       "          [-1.1845e+02, -1.6654e+03]]],\n",
       "\n",
       "\n",
       "        [[[-2.0026e+01, -1.2380e+01],\n",
       "          [-4.2491e+03, -1.9966e+03],\n",
       "          [-8.0379e+04, -2.4081e+04],\n",
       "          ...,\n",
       "          [-1.5921e+04,  6.0548e+03],\n",
       "          [-1.8878e+01,  1.8069e+01],\n",
       "          [-3.5629e+00,  2.3535e+00]],\n",
       "\n",
       "         [[-7.0231e+01, -9.7635e+01],\n",
       "          [-6.4945e+05, -2.1279e+05],\n",
       "          [-1.2256e+05, -5.2986e+04],\n",
       "          ...,\n",
       "          [-4.4060e+03,  6.2715e+02],\n",
       "          [-4.4865e+03,  2.7318e+03],\n",
       "          [-1.2322e+03,  2.3831e+03]],\n",
       "\n",
       "         [[-2.2776e+03, -2.1844e+04],\n",
       "          [-1.8151e+01, -5.2569e+02],\n",
       "          [-2.6819e+02, -2.3609e+02],\n",
       "          ...,\n",
       "          [-1.2967e+03,  1.2444e+03],\n",
       "          [-3.6326e+02,  1.5217e+00],\n",
       "          [-1.4565e+02, -1.6868e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6022e+00,  3.4380e+00],\n",
       "          [ 5.0674e+01, -2.7991e+01],\n",
       "          [-1.1047e+03, -1.4162e+04],\n",
       "          ...,\n",
       "          [ 1.9625e+05,  1.0220e+06],\n",
       "          [ 9.9368e+04, -3.5248e+05],\n",
       "          [ 4.4575e+05,  5.1463e+05]],\n",
       "\n",
       "         [[ 7.2837e-01,  2.7592e+00],\n",
       "          [ 1.2552e+01,  7.1569e+00],\n",
       "          [ 1.9397e+01, -9.0038e+00],\n",
       "          ...,\n",
       "          [ 3.3720e+03,  1.7575e+04],\n",
       "          [ 1.3707e+04,  2.4419e+04],\n",
       "          [-6.4183e+02,  2.4829e+02]],\n",
       "\n",
       "         [[ 1.9266e-02,  4.0301e-01],\n",
       "          [ 6.3477e-01,  2.3665e+00],\n",
       "          [ 1.0790e+00,  1.5526e+00],\n",
       "          ...,\n",
       "          [ 9.5305e+05,  1.7455e+05],\n",
       "          [ 3.8287e+04,  5.8029e+04],\n",
       "          [-3.3672e+02, -1.5903e+03]]],\n",
       "\n",
       "\n",
       "        [[[-1.5797e+01, -6.7692e+00],\n",
       "          [-4.1225e+03, -1.7665e+03],\n",
       "          [-7.2252e+04, -1.8423e+04],\n",
       "          ...,\n",
       "          [-1.4918e+04,  4.8024e+03],\n",
       "          [-1.7123e+01,  1.6773e+01],\n",
       "          [-3.4133e+00,  2.1246e+00]],\n",
       "\n",
       "         [[-5.5488e+01, -6.4058e+01],\n",
       "          [-6.3592e+05, -2.1424e+05],\n",
       "          [-1.1255e+05, -4.0712e+04],\n",
       "          ...,\n",
       "          [-5.0957e+03,  6.0846e+02],\n",
       "          [-4.4830e+03,  3.0700e+03],\n",
       "          [-1.1450e+03,  2.5732e+03]],\n",
       "\n",
       "         [[-7.2432e+02, -7.2090e+03],\n",
       "          [ 3.3951e+01, -2.2493e+02],\n",
       "          [-3.1459e+02, -2.3051e+02],\n",
       "          ...,\n",
       "          [-1.0330e+03,  1.0864e+03],\n",
       "          [-3.2637e+02,  3.2902e+01],\n",
       "          [-1.3495e+02,  1.6772e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.2660e+00,  2.5767e+00],\n",
       "          [ 4.4844e+01, -2.8551e+01],\n",
       "          [-1.0984e+03, -8.6054e+03],\n",
       "          ...,\n",
       "          [ 1.0924e+05,  1.6180e+04],\n",
       "          [-1.7495e+03, -3.6431e+04],\n",
       "          [ 2.8442e+05,  3.5568e+05]],\n",
       "\n",
       "         [[ 6.5278e-01,  2.3031e+00],\n",
       "          [ 1.1060e+01,  5.0412e+00],\n",
       "          [ 1.7133e+01, -9.4647e+00],\n",
       "          ...,\n",
       "          [ 3.6450e+03,  1.4347e+04],\n",
       "          [ 1.3709e+04,  1.8837e+04],\n",
       "          [-5.5323e+02,  1.4742e+02]],\n",
       "\n",
       "         [[ 1.8340e-02,  3.4388e-01],\n",
       "          [ 5.6084e-01,  1.9741e+00],\n",
       "          [ 9.5453e-01,  1.2323e+00],\n",
       "          ...,\n",
       "          [ 3.3605e+05, -6.8459e+04],\n",
       "          [ 3.4884e+04,  2.0766e+04],\n",
       "          [-3.9315e+02, -1.1201e+03]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].xy, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0486e+03,  1.3906e+04, -1.9446e+05,  5.8336e+03,  5.4195e+02,\n",
       "          -1.1806e+02,  5.3263e+04,  1.3171e+05,  1.8636e+02,  5.7778e+01],\n",
       "         [-8.4126e+03, -7.7938e+05, -2.4222e+06,  1.1695e+04, -9.9906e+04,\n",
       "          -4.0504e+06, -2.5195e+05, -1.7867e+05, -2.3436e+05, -1.7479e+04],\n",
       "         [ 1.5524e+05, -1.4720e+04, -2.0701e+03, -1.5281e+03, -1.8903e+06,\n",
       "           7.4261e+06, -7.7657e+04, -5.2895e+04, -5.8358e+04, -2.2921e+04],\n",
       "         [-3.2929e+06, -3.1781e+05,  5.4836e+04, -1.0454e+03, -7.3192e+04,\n",
       "          -1.0762e+05, -5.0329e+05,  9.6502e+04,  3.6801e+04,  8.8489e+01],\n",
       "         [-6.1418e+03,  2.2665e+05, -2.5158e+05, -1.0521e+06, -5.4342e+04,\n",
       "           3.1015e+06, -9.1083e+05,  6.0238e+04, -5.6681e+03,  1.4439e+05],\n",
       "         [ 6.0554e+03,  3.5239e+05,  8.6244e+05, -1.4555e+05,  1.7436e+05,\n",
       "           2.6003e+05, -1.3779e+06,  1.2651e+05, -6.6516e+04, -3.4779e+01],\n",
       "         [ 4.2048e+02,  1.8744e+03, -5.2432e+06, -5.4514e+07,  1.6362e+06,\n",
       "          -5.4717e+03,  6.1941e+06,  1.1521e+08, -2.1545e+02, -6.7660e+01],\n",
       "         [ 2.5618e+02,  2.5192e+02,  6.8499e+05, -1.0023e+05, -4.8915e+03,\n",
       "          -1.1702e+03, -3.6586e+05,  3.1857e+06,  2.7146e+07, -7.6799e+04],\n",
       "         [ 1.2771e+01, -1.3437e+02,  8.2616e+00, -1.3072e+03, -6.3041e+03,\n",
       "           3.3730e+06, -5.2373e+05, -7.3945e+04, -1.0753e+05, -9.0561e+01],\n",
       "         [-2.5129e+00, -2.5729e+01, -1.9488e+01,  3.4070e+00,  2.3022e+03,\n",
       "           9.0012e+04,  2.0934e+06, -5.9503e+06, -5.3216e+05, -3.6169e+03]],\n",
       "\n",
       "        [[-1.0254e+03,  5.7647e+02,  1.6825e+05,  9.0715e+03,  6.7888e+02,\n",
       "           1.3310e+04,  9.3324e+04,  1.6164e+05,  2.3024e+02,  1.6363e+02],\n",
       "         [-9.6226e+03, -3.2487e+06, -3.5391e+06,  1.8847e+04, -1.2159e+05,\n",
       "          -1.9807e+07, -7.6456e+05, -2.3043e+05, -2.6033e+05,  2.2053e+04],\n",
       "         [ 4.4208e+05, -1.1681e+04, -4.8492e+03, -1.6485e+03, -3.6014e+06,\n",
       "           2.6274e+06,  1.5449e+04, -2.8152e+04, -7.8704e+04, -2.8555e+04],\n",
       "         [-1.8777e+06, -3.6791e+05,  6.0551e+04, -1.6813e+03,  1.7032e+03,\n",
       "          -1.0855e+05, -5.6555e+05,  1.3206e+05,  3.8167e+04,  8.8615e+01],\n",
       "         [-7.8611e+03,  1.0882e+05, -3.4900e+05, -1.9741e+06, -1.7646e+05,\n",
       "           3.8208e+06, -3.1113e+06,  5.9449e+04, -1.0109e+04,  1.1494e+05],\n",
       "         [ 8.0103e+03,  4.5023e+05,  9.1210e+05, -4.4636e+05,  3.0475e+05,\n",
       "          -4.6965e+05, -5.4188e+06,  2.9684e+05, -3.2544e+04, -3.7273e+01],\n",
       "         [ 4.3165e+02,  2.2419e+03,  1.1743e+06, -8.9380e+07,  3.2309e+06,\n",
       "          -8.8536e+03, -2.2863e+07,  1.4904e+08, -2.2920e+02, -7.4308e+01],\n",
       "         [ 2.6567e+02,  3.2290e+02,  2.0911e+06,  1.1779e+06, -4.3908e+04,\n",
       "           2.8796e+04, -1.2839e+06,  7.6628e+06,  6.4135e+07, -5.4374e+05],\n",
       "         [ 1.5328e+01, -1.1469e+02,  3.5742e+01, -1.0168e+03, -5.9528e+04,\n",
       "           1.2156e+06, -9.1638e+04, -1.3491e+05, -1.8339e+05, -7.1626e+02],\n",
       "         [-2.3604e+00, -2.4257e+01, -1.7398e+01,  3.7960e+00,  5.3465e+03,\n",
       "           2.2442e+05,  2.0126e+05, -1.8251e+07, -1.5620e+06, -2.4770e+03]],\n",
       "\n",
       "        [[-7.8369e+02, -6.4185e+04,  1.0363e+06,  1.2838e+04,  7.4137e+02,\n",
       "           8.6078e+04,  1.3673e+05,  1.0016e+05,  2.8818e+02,  2.9732e+02],\n",
       "         [-9.4616e+03, -8.3277e+06, -3.8909e+06,  2.5627e+04, -1.0524e+05,\n",
       "          -4.8191e+07,  1.0078e+06, -2.5524e+05, -2.2891e+05,  9.3456e+04],\n",
       "         [ 6.5515e+05, -3.1879e+03, -8.6314e+03, -1.7719e+03, -3.7334e+06,\n",
       "          -2.5549e+06,  1.7248e+05, -9.5409e+03, -9.4753e+04, -3.0676e+04],\n",
       "         [ 1.2434e+06, -2.5780e+05,  6.1407e+04, -2.4731e+03,  7.2749e+04,\n",
       "          -1.0376e+05, -4.7743e+05,  1.4543e+05,  3.4727e+04,  8.1074e+01],\n",
       "         [-6.1227e+03, -7.3708e+04, -2.5476e+05, -2.9750e+06, -3.6464e+05,\n",
       "           3.6282e+06, -6.5329e+06,  4.4411e+04, -1.5195e+04,  4.4009e+04],\n",
       "         [ 9.2938e+03,  4.9471e+05,  7.3955e+05, -7.9096e+05,  4.6422e+05,\n",
       "          -1.7348e+06, -1.4544e+07,  3.0305e+05, -7.6136e+03, -3.9415e+01],\n",
       "         [ 4.3507e+02,  2.5282e+03,  2.2171e+07, -9.0408e+07,  4.4175e+06,\n",
       "          -1.1941e+04, -6.3907e+07, -9.7620e+07, -2.4069e+02, -8.0375e+01],\n",
       "         [ 2.7285e+02,  3.9722e+02,  4.1890e+06,  4.0711e+06, -1.5060e+05,\n",
       "           5.5519e+04, -3.7069e+06,  8.2856e+05, -1.1602e+07, -1.3883e+06],\n",
       "         [ 1.8360e+01, -8.9032e+01,  6.5041e+01, -7.0079e+02, -2.1694e+05,\n",
       "           9.6999e+05,  1.0073e+06, -1.9197e+05, -2.3341e+05, -2.9833e+03],\n",
       "         [-2.1002e+00, -2.1881e+01, -1.4631e+01,  4.0227e+00,  8.7235e+03,\n",
       "           4.2021e+05, -1.7711e+06, -1.6539e+07, -2.5332e+06,  7.8564e+02]],\n",
       "\n",
       "        [[-3.9797e+02, -1.7580e+05,  2.1982e+06,  1.5559e+04,  7.2461e+02,\n",
       "           2.4370e+05,  1.6755e+05, -5.6304e+04,  3.5834e+02,  4.2730e+02],\n",
       "         [-7.9312e+03, -1.1583e+07, -3.0101e+06,  2.9941e+04, -6.6759e+04,\n",
       "          -4.8011e+07,  9.7752e+06, -2.3951e+05, -1.3210e+05,  1.8823e+05],\n",
       "         [ 5.8162e+05,  3.6008e+03, -1.3221e+04, -1.9014e+03, -2.2862e+06,\n",
       "          -3.4157e+06,  3.3264e+05, -2.3079e+03, -1.0100e+05, -2.7814e+04],\n",
       "         [ 2.9531e+06, -9.8103e+04,  5.6294e+04, -3.3626e+03,  1.2002e+05,\n",
       "          -9.6094e+04, -2.5967e+05,  1.3371e+05,  2.7534e+04,  6.7866e+01],\n",
       "         [-2.6277e+03, -1.7273e+05,  2.2832e+05, -3.5121e+06, -5.5849e+05,\n",
       "           2.8903e+06, -6.6206e+06,  2.5661e+04, -1.8565e+04, -4.1483e+04],\n",
       "         [ 9.4263e+03,  4.6377e+05,  3.7495e+05, -1.0176e+06,  5.6287e+05,\n",
       "          -2.8245e+06, -2.6176e+07,  2.0164e+05,  2.2364e+03, -4.1128e+01],\n",
       "         [ 4.2892e+02,  2.6157e+03,  4.7433e+07, -4.4436e+07,  3.6141e+06,\n",
       "          -1.2581e+04, -2.7729e+07, -8.8506e+07, -2.5254e+02, -8.5638e+01],\n",
       "         [ 2.7690e+02,  4.6278e+02,  5.6687e+06,  7.0159e+06, -3.2827e+05,\n",
       "           6.4863e+04, -4.7711e+05, -5.1277e+06, -6.1394e+07, -1.3696e+06],\n",
       "         [ 2.1575e+01, -6.0013e+01,  9.3023e+01, -4.1594e+02, -4.9140e+05,\n",
       "           1.0412e+06,  1.8889e+06, -2.0950e+05, -2.0606e+05, -6.5285e+03],\n",
       "         [-1.7575e+00, -1.8868e+01, -1.1468e+01,  4.0277e+00,  9.5284e+03,\n",
       "           5.8121e+05, -2.1764e+06,  1.1799e+07, -1.7451e+06,  4.2469e+03]],\n",
       "\n",
       "        [[-1.0115e+01, -2.5160e+05,  3.0733e+06,  1.5654e+04,  6.4395e+02,\n",
       "           3.4496e+05,  1.5298e+05, -2.1731e+05,  4.2750e+02,  5.1249e+02],\n",
       "         [-5.5877e+03, -5.5161e+06, -1.2779e+06,  2.9898e+04, -3.5139e+04,\n",
       "           1.1075e+06,  1.9315e+07, -1.8458e+05,  9.9342e+03,  2.8361e+05],\n",
       "         [ 3.2402e+05,  5.6883e+03, -1.8179e+04, -2.0249e+03, -8.5386e+05,\n",
       "          -1.7634e+06,  4.1686e+05, -5.9378e+03, -9.4708e+04, -2.0313e+04],\n",
       "         [ 2.2771e+06, -1.1291e+04,  4.5199e+04, -4.2536e+03,  1.3695e+05,\n",
       "          -8.3930e+04, -1.9279e+04,  1.0289e+05,  1.8719e+04,  5.2166e+01],\n",
       "         [-2.2888e+02, -1.2774e+05,  1.1292e+06, -3.0736e+06, -6.6018e+05,\n",
       "           2.4659e+06,  3.0639e+06,  1.1909e+04, -1.8506e+04, -1.0527e+05],\n",
       "         [ 8.3395e+03,  3.6636e+05, -6.5514e+04, -1.0559e+06,  5.1169e+05,\n",
       "          -2.8423e+06, -3.0512e+07,  9.5409e+04,  2.9410e+03, -4.2344e+01],\n",
       "         [ 4.1252e+02,  2.4403e+03,  5.5371e+07,  9.5292e+06,  4.8930e+05,\n",
       "          -9.5499e+03, -2.5876e+06, -1.0641e+07, -2.6448e+02, -8.9895e+01],\n",
       "         [ 2.7713e+02,  5.0952e+02,  5.2605e+06,  7.4938e+06, -4.9969e+05,\n",
       "           5.5745e+04,  7.4204e+06, -8.9345e+04, -1.8137e+07, -1.1410e+05],\n",
       "         [ 2.4642e+01, -3.0622e+01,  1.1686e+02, -1.9091e+02, -7.6097e+05,\n",
       "          -1.2749e+06,  1.8947e+06, -1.6938e+05, -9.4562e+04, -7.4432e+03],\n",
       "         [-1.3669e+00, -1.5496e+01, -8.2226e+00,  3.9286e+00,  6.0291e+03,\n",
       "           5.8603e+05, -1.3413e+06,  2.3192e+07, -1.5121e+05,  5.6302e+03]],\n",
       "\n",
       "        [[ 2.5394e+02, -2.1999e+05,  3.1643e+06,  1.2908e+04,  5.2519e+02,\n",
       "           2.5360e+05,  8.9460e+04, -2.7912e+05,  4.5852e+02,  5.2063e+02],\n",
       "         [-3.2339e+03,  6.3859e+06,  3.2069e+05,  2.5393e+04, -1.8540e+04,\n",
       "           3.3306e+07,  1.6794e+07, -1.0778e+05,  1.5455e+05,  3.5104e+05],\n",
       "         [ 1.1558e+05,  5.0655e+03, -2.2880e+04, -2.1174e+03, -1.9572e+05,\n",
       "          -5.3417e+05,  3.9041e+05, -1.5067e+04, -7.7586e+04, -1.0401e+04],\n",
       "         [ 9.6640e+05,  5.3720e+03,  2.9378e+04, -5.0279e+03,  1.2978e+05,\n",
       "          -6.4041e+04,  1.3502e+05,  6.4545e+04,  1.0502e+04,  3.7050e+01],\n",
       "         [ 4.8134e+02, -1.4468e+04,  2.1587e+06, -1.6668e+06, -6.0509e+05,\n",
       "           2.5025e+06,  1.9510e+07,  4.8388e+03, -1.5234e+04, -1.2618e+05],\n",
       "         [ 6.4258e+03,  2.3845e+05, -4.3258e+05, -9.5579e+05,  3.2813e+05,\n",
       "          -1.7538e+06, -2.1055e+07,  3.3104e+04,  1.3887e+03, -4.3016e+01],\n",
       "         [ 3.8658e+02,  2.0683e+03,  4.0939e+07,  3.0260e+07, -2.9486e+06,\n",
       "          -3.9514e+03,  1.2884e+05, -2.2338e+05, -2.7476e+02, -9.2983e+01],\n",
       "         [ 2.7302e+02,  5.3489e+02,  3.3766e+06,  5.2788e+06, -5.4986e+05,\n",
       "           3.7962e+04,  8.1636e+06,  3.2883e+06, -1.2643e+06,  9.5505e+05],\n",
       "         [ 2.7237e+01, -3.3939e+00,  1.3444e+02, -2.8152e+01, -8.3520e+05,\n",
       "          -4.1465e+06,  1.2299e+06, -9.2452e+04,  4.0972e+04, -4.3467e+03],\n",
       "         [-9.6440e-01, -1.2073e+01, -5.1701e+00,  3.9448e+00,  5.5070e+02,\n",
       "           4.2518e+05, -4.8365e+05,  1.0471e+07,  5.1849e+05,  4.6133e+03]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].z, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.7766e+00,  6.7788e+00],\n",
       "          [-6.5652e+02,  3.1518e+02],\n",
       "          [-2.7413e+03,  3.6846e+03],\n",
       "          ...,\n",
       "          [-1.3771e+03,  6.1010e+01],\n",
       "          [ 5.9682e+00,  7.6746e+00],\n",
       "          [ 1.4302e+00,  6.6453e-01]],\n",
       "\n",
       "         [[ 2.6758e+01,  5.8439e+01],\n",
       "          [-5.4867e+03,  3.1141e+03],\n",
       "          [-8.4036e+03,  8.2805e+03],\n",
       "          ...,\n",
       "          [-6.3122e+02, -6.3198e+01],\n",
       "          [ 6.6793e+02, -4.9277e+01],\n",
       "          [ 2.9499e+02,  9.1804e+01]],\n",
       "\n",
       "         [[ 7.7727e+02,  1.6078e+04],\n",
       "          [ 3.9358e+01,  1.4793e+01],\n",
       "          [ 1.8616e+01,  7.9816e+01],\n",
       "          ...,\n",
       "          [ 7.0366e+02,  3.2508e+02],\n",
       "          [ 1.1972e+02, -4.1484e+00],\n",
       "          [ 3.5738e+01, -3.5577e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9560e+00, -4.5507e+00],\n",
       "          [ 2.9449e+01,  3.5947e+00],\n",
       "          [ 9.5752e+01,  4.0652e+02],\n",
       "          ...,\n",
       "          [ 1.3233e+03,  2.2783e+04],\n",
       "          [ 2.3255e+05,  8.9764e+05],\n",
       "          [-8.7833e+02, -2.6135e+02]],\n",
       "\n",
       "         [[ 3.9355e-01, -2.6319e+00],\n",
       "          [ 7.2254e+00, -1.0818e+01],\n",
       "          [ 1.1303e+01, -1.3602e-01],\n",
       "          ...,\n",
       "          [-3.8696e+02,  1.6757e+03],\n",
       "          [-5.6186e+01,  2.4558e+03],\n",
       "          [-5.1828e+00, -8.1076e-01]],\n",
       "\n",
       "         [[ 8.2040e-03, -3.5030e-01],\n",
       "          [ 3.4854e-01, -2.2587e+00],\n",
       "          [ 6.0939e-01, -1.7745e+00],\n",
       "          ...,\n",
       "          [-1.0968e+05,  9.5751e+04],\n",
       "          [ 1.2304e+04,  3.7091e+04],\n",
       "          [-4.1111e+01, -1.7120e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0558e+01,  1.1152e+01],\n",
       "          [-3.2867e+02,  5.1924e+02],\n",
       "          [ 6.1304e+03,  7.2078e+03],\n",
       "          ...,\n",
       "          [ 3.4983e+02,  4.8235e+02],\n",
       "          [ 8.0691e+00,  8.4531e+00],\n",
       "          [ 1.6549e+00,  7.9475e-01]],\n",
       "\n",
       "         [[ 3.6684e+01,  8.5378e+01],\n",
       "          [-1.0825e+03,  1.2036e+04],\n",
       "          [ 5.3021e+03,  1.6009e+04],\n",
       "          ...,\n",
       "          [-8.0960e+01, -2.7134e+01],\n",
       "          [ 1.1795e+03,  1.4670e+02],\n",
       "          [ 4.2811e+02,  2.6590e+02]],\n",
       "\n",
       "         [[ 1.3149e+03,  3.3076e+04],\n",
       "          [ 5.4156e+01,  3.4105e+02],\n",
       "          [ 2.8386e+01,  1.0010e+02],\n",
       "          ...,\n",
       "          [ 7.5406e+02,  4.3108e+02],\n",
       "          [ 1.5204e+02, -1.0713e+01],\n",
       "          [ 5.1359e+01, -3.8053e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0439e+00, -4.1402e+00],\n",
       "          [ 3.0329e+01,  8.4960e+00],\n",
       "          [ 1.2944e+02,  1.3742e+03],\n",
       "          ...,\n",
       "          [ 1.5857e+04,  1.9052e+05],\n",
       "          [ 1.1576e+06,  3.3488e+06],\n",
       "          [ 1.6844e+03,  8.0743e+03]],\n",
       "\n",
       "         [[ 4.1297e-01, -2.5192e+00],\n",
       "          [ 7.4500e+00, -9.4227e+00],\n",
       "          [ 1.1650e+01,  1.8477e+00],\n",
       "          ...,\n",
       "          [-2.7725e+02,  3.6868e+03],\n",
       "          [ 9.5732e+02,  5.4089e+03],\n",
       "          [-3.3886e+01,  1.8460e+00]],\n",
       "\n",
       "         [[ 9.3025e-03, -3.4244e-01],\n",
       "          [ 3.6174e-01, -2.1584e+00],\n",
       "          [ 6.3564e-01, -1.6289e+00],\n",
       "          ...,\n",
       "          [-1.9839e+05,  4.5401e+05],\n",
       "          [ 4.4497e+03,  6.5798e+04],\n",
       "          [ 5.3476e+01, -5.2627e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2530e+01,  1.3860e+01],\n",
       "          [ 8.2877e+02,  7.7001e+02],\n",
       "          [ 2.4156e+04,  1.1130e+04],\n",
       "          ...,\n",
       "          [ 4.9584e+03,  1.2062e+03],\n",
       "          [ 1.0605e+01,  9.0516e+00],\n",
       "          [ 1.8397e+00,  9.1770e-01]],\n",
       "\n",
       "         [[ 4.3812e+01,  1.0160e+02],\n",
       "          [ 8.0148e+04,  4.1689e+04],\n",
       "          [ 3.5642e+04,  2.4571e+04],\n",
       "          ...,\n",
       "          [ 8.4750e+02,  3.6176e+01],\n",
       "          [ 1.8024e+03,  4.5119e+02],\n",
       "          [ 5.5645e+02,  5.0624e+02]],\n",
       "\n",
       "         [[ 1.4580e+03,  4.1429e+04],\n",
       "          [ 4.3898e+01,  6.5530e+02],\n",
       "          [ 4.0851e+01,  1.1776e+02],\n",
       "          ...,\n",
       "          [ 7.5474e+02,  5.0105e+02],\n",
       "          [ 1.7928e+02, -1.2169e+01],\n",
       "          [ 6.6167e+01, -3.3583e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0538e+00, -3.6147e+00],\n",
       "          [ 3.0103e+01,  1.2726e+01],\n",
       "          [ 8.9226e+01,  2.8385e+03],\n",
       "          ...,\n",
       "          [ 3.8059e+04,  6.4336e+05],\n",
       "          [ 1.6067e+06,  2.9458e+06],\n",
       "          [ 4.0133e+04,  8.4157e+04]],\n",
       "\n",
       "         [[ 4.1942e-01, -2.3255e+00],\n",
       "          [ 7.4360e+00, -7.8451e+00],\n",
       "          [ 1.1572e+01,  3.5759e+00],\n",
       "          ...,\n",
       "          [ 2.8040e+02,  6.3625e+03],\n",
       "          [ 3.2543e+03,  9.2982e+03],\n",
       "          [-1.2163e+02,  3.7723e+01]],\n",
       "\n",
       "         [[ 1.0544e-02, -3.2339e-01],\n",
       "          [ 3.6647e-01, -1.9897e+00],\n",
       "          [ 6.3737e-01, -1.4372e+00],\n",
       "          ...,\n",
       "          [ 2.7322e+05,  9.1060e+05],\n",
       "          [-7.6290e+03,  9.0981e+04],\n",
       "          [ 4.5747e+01, -9.7046e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3000e+01,  1.3508e+01],\n",
       "          [ 2.5307e+03,  1.0242e+03],\n",
       "          [ 4.4669e+04,  1.3581e+04],\n",
       "          ...,\n",
       "          [ 1.0931e+04,  1.8794e+03],\n",
       "          [ 1.2615e+01,  9.3449e+00],\n",
       "          [ 1.9525e+00,  1.0031e+00]],\n",
       "\n",
       "         [[ 4.5751e+01,  9.9651e+01],\n",
       "          [ 3.2355e+05,  1.0074e+05],\n",
       "          [ 7.1429e+04,  2.9911e+04],\n",
       "          ...,\n",
       "          [ 1.9714e+03,  1.0299e+02],\n",
       "          [ 2.3917e+03,  8.0498e+02],\n",
       "          [ 6.4727e+02,  7.6437e+02]],\n",
       "\n",
       "         [[ 1.0641e+03,  3.2779e+04],\n",
       "          [ 1.9794e+00,  6.5338e+02],\n",
       "          [ 5.4573e+01,  1.2978e+02],\n",
       "          ...,\n",
       "          [ 7.0531e+02,  5.2293e+02],\n",
       "          [ 1.9476e+02, -7.1252e+00],\n",
       "          [ 7.6414e+01, -2.1652e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9854e+00, -3.0207e+00],\n",
       "          [ 2.8757e+01,  1.5797e+01],\n",
       "          [-4.1461e+01,  3.8035e+03],\n",
       "          ...,\n",
       "          [ 5.8404e+04,  9.2359e+05],\n",
       "          [ 5.9608e+05,  6.1176e+04],\n",
       "          [ 1.5279e+05,  2.7890e+05]],\n",
       "\n",
       "         [[ 4.0770e-01, -2.0790e+00],\n",
       "          [ 7.1492e+00, -6.1901e+00],\n",
       "          [ 1.1030e+01,  4.9183e+00],\n",
       "          ...,\n",
       "          [ 1.2573e+03,  8.5761e+03],\n",
       "          [ 6.2292e+03,  1.2326e+04],\n",
       "          [-2.5405e+02,  1.3441e+02]],\n",
       "\n",
       "         [[ 1.0845e-02, -2.9531e-01],\n",
       "          [ 3.5606e-01, -1.7755e+00],\n",
       "          [ 6.1210e-01, -1.2255e+00],\n",
       "          ...,\n",
       "          [ 1.0703e+06,  7.0060e+05],\n",
       "          [ 6.2592e+03,  7.8113e+04],\n",
       "          [-1.0794e+02, -1.2574e+03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1782e+01,  1.0207e+01],\n",
       "          [ 3.7827e+03,  1.1505e+03],\n",
       "          [ 5.5661e+04,  1.3087e+04],\n",
       "          ...,\n",
       "          [ 1.4621e+04,  2.0553e+03],\n",
       "          [ 1.3001e+01,  9.1740e+00],\n",
       "          [ 1.9707e+00,  1.0141e+00]],\n",
       "\n",
       "         [[ 4.1649e+01,  8.0881e+01],\n",
       "          [ 5.9485e+05,  1.5839e+05],\n",
       "          [ 9.1651e+04,  2.8882e+04],\n",
       "          ...,\n",
       "          [ 2.9473e+03,  1.5663e+02],\n",
       "          [ 2.7637e+03,  1.1029e+03],\n",
       "          [ 6.7369e+02,  9.6493e+02]],\n",
       "\n",
       "         [[ 5.1251e+02,  1.6668e+04],\n",
       "          [-4.3690e+01,  4.0506e+02],\n",
       "          [ 6.6879e+01,  1.3414e+02],\n",
       "          ...,\n",
       "          [ 6.1448e+02,  4.9561e+02],\n",
       "          [ 1.9358e+02,  2.0662e+00],\n",
       "          [ 7.9044e+01, -6.6657e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8317e+00, -2.4241e+00],\n",
       "          [ 2.6396e+01,  1.7547e+01],\n",
       "          [-1.6652e+02,  3.4087e+03],\n",
       "          ...,\n",
       "          [ 6.0912e+04,  5.1288e+05],\n",
       "          [ 4.6007e+04, -2.4984e+05],\n",
       "          [ 2.2942e+05,  4.0471e+05]],\n",
       "\n",
       "         [[ 3.7621e-01, -1.7968e+00],\n",
       "          [ 6.5565e+00, -4.6659e+00],\n",
       "          [ 1.0128e+01,  5.7527e+00],\n",
       "          ...,\n",
       "          [ 2.0791e+03,  9.0470e+03],\n",
       "          [ 8.4301e+03,  1.2575e+04],\n",
       "          [-3.3033e+02,  1.9525e+02]],\n",
       "\n",
       "         [[ 9.9961e-03, -2.6052e-01],\n",
       "          [ 3.3196e-01, -1.5306e+00],\n",
       "          [ 5.6424e-01, -1.0040e+00],\n",
       "          ...,\n",
       "          [ 9.4852e+05,  1.2261e+05],\n",
       "          [ 2.5360e+04,  3.8536e+04],\n",
       "          [-3.0688e+02, -1.2007e+03]]],\n",
       "\n",
       "\n",
       "        [[[ 9.3123e+00,  5.5635e+00],\n",
       "          [ 3.6878e+03,  1.0059e+03],\n",
       "          [ 5.0653e+04,  9.9394e+03],\n",
       "          ...,\n",
       "          [ 1.3700e+04,  1.6304e+03],\n",
       "          [ 1.1544e+01,  8.4668e+00],\n",
       "          [ 1.8884e+00,  8.7571e-01]],\n",
       "\n",
       "         [[ 3.2941e+01,  5.3071e+01],\n",
       "          [ 5.8252e+05,  1.5951e+05],\n",
       "          [ 8.4420e+04,  2.2065e+04],\n",
       "          ...,\n",
       "          [ 3.4388e+03,  1.7527e+02],\n",
       "          [ 2.7881e+03,  1.2466e+03],\n",
       "          [ 6.2683e+02,  1.0419e+03]],\n",
       "\n",
       "         [[ 1.6361e+02,  5.5007e+03],\n",
       "          [-5.9165e+01,  1.7362e+02],\n",
       "          [ 7.5239e+01,  1.3055e+02],\n",
       "          ...,\n",
       "          [ 4.9795e+02,  4.2782e+02],\n",
       "          [ 1.7492e+02,  1.3861e+01],\n",
       "          [ 7.3237e+01,  6.9203e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6556e+00, -1.8595e+00],\n",
       "          [ 2.3341e+01,  1.7929e+01],\n",
       "          [-1.6852e+02,  2.0836e+03],\n",
       "          ...,\n",
       "          [ 3.3884e+04,  8.1198e+03],\n",
       "          [-8.1268e+02, -2.5825e+04],\n",
       "          [ 1.4638e+05,  2.7958e+05]],\n",
       "\n",
       "         [[ 3.3664e-01, -1.5010e+00],\n",
       "          [ 5.7756e+00, -3.2955e+00],\n",
       "          [ 8.9434e+00,  6.0543e+00],\n",
       "          ...,\n",
       "          [ 2.2416e+03,  7.3869e+03],\n",
       "          [ 8.4312e+03,  9.7006e+03],\n",
       "          [-2.8473e+02,  1.1596e+02]],\n",
       "\n",
       "         [[ 9.5114e-03, -2.2226e-01],\n",
       "          [ 2.9328e-01, -1.2767e+00],\n",
       "          [ 4.9911e-01, -7.9678e-01],\n",
       "          ...,\n",
       "          [ 3.3217e+05, -5.2477e+04],\n",
       "          [ 2.3441e+04,  1.2558e+04],\n",
       "          [-3.5832e+02, -8.4566e+02]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(weight, volume.get_detectors()[0].panels[0].xy_span, create_graph=True)#.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb = PanelScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0inf = PanelX0Inferer(sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, weight = x0inf.pred_x0(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = DetectorLoss(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(pred, weight, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   5306.6948, -147312.7812]) tensor(-2265922.5000) tensor([   812.7222, 186090.4375])\n",
      "tensor([-8164.4385, 30907.7422]) tensor(-433788.) tensor([-7812.4854, 10428.1523])\n",
      "tensor([  7157.6875, -82562.2344]) tensor(-175594.2500) tensor([ 3928.4033, 99080.5859])\n",
      "tensor([  23220.0371, -412142.0625]) tensor(1279701.5000) tensor([ 14488.2695, 472666.6250])\n",
      "tensor([ 380140.3438, -172452.1562]) tensor(10892807.) tensor([261809.7656, 114713.6328])\n",
      "tensor([-21339.4902, -12355.7148]) tensor(2525371.2500) tensor([-17239.6523,  -2093.1003])\n",
      "tensor([83534.3125, -2845.6880]) tensor(-4402399.) tensor([52152.6797,   105.1506])\n",
      "tensor([220451.6875, -28788.3223]) tensor(-7419419.) tensor([137201.5000,  18495.7969])\n"
     ]
    }
   ],
   "source": [
    "for d in volume.get_detectors():\n",
    "    for p in d.panels:\n",
    "        print(p.xy.grad, p.z.grad, p.xy_span.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VolumeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from __future__ import annotations\n",
    "from fastcore.all import Path\n",
    "from typing import Callable, Iterator, Optional, List, Any, Tuple, Union\n",
    "from fastprogress.fastprogress import ConsoleProgressBar, NBProgressBar, ProgressBar\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from tomopt.optimisation.callbacks.cyclic_callbacks import CyclicCallback\n",
    "from tomopt.optimisation.callbacks.eval_metric import EvalMetric\n",
    "from tomopt.optimisation.wrapper.volume_wrapper import FitParams\n",
    "\n",
    "PartialOpt = Callable[[Iterator[nn.Parameter]], torch.optim.Optimizer]\n",
    "\n",
    "class AbsVolumeWrapper(metaclass=ABCMeta):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "        partial_scatter_inferer: Callable[[MuonBatch, Volume], ScatterBatch] = ScatterBatch,\n",
    "        partial_x0_inferer: Callable[[ScatterBatch, bool], X0Inferer] = X0Inferer\n",
    "    ):\n",
    "        self.volume, self.loss_func, self.default_pred, self.mu_generator = volume, loss_func, default_pred, mu_generator\n",
    "        self.partial_scatter_inferer, self.partial_x0_inferer = partial_scatter_inferer, partial_x0_inferer\n",
    "        self._build_opt(**partial_opts)\n",
    "        self.parameters = self.volume.parameters\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _build_opt(\n",
    "        self, **kwargs\n",
    "    ) -> None:\n",
    "        r'''\n",
    "        self.opts = {'res_opt': res_opt((l.resolution for l in self.volume.get_detectors())),\n",
    "                     'eff_opt': eff_opt((l.efficiency for l in self.volume.get_detectors()))}\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def get_detectors(self) -> List[DetectorLayer]:\n",
    "        return self.volume.get_detectors()\n",
    "\n",
    "    def save(self, name: str) -> None:\n",
    "        torch.save({\"volume\": self.volume.state_dict(), **{k:v.state_dict() for k,v in self.opts.items()}}, str(name))\n",
    "\n",
    "    def load(self, name: str) -> None:\n",
    "        state = torch.load(name, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.volume.load_state_dict(state[\"volume\"])\n",
    "        for k,v in state.items():\n",
    "            if '_opt' in k: self.opts[k].load_state_dict(v)\n",
    "\n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "        partial_scatter_inferer: Callable[[MuonBatch, Volume], ScatterBatch] = ScatterBatch,\n",
    "        partial_x0_inferer: Callable[[ScatterBatch, bool], X0Inferer] = X0Inferer\n",
    "    ) -> VolumeWrapper:\n",
    "        vw = cls(volume=volume, partial_opts=partial_opts, loss_func=loss_func, default_pred=default_pred, mu_generator=mu_generator, partial_scatter_inferer=partial_scatter_inferer, partial_x0_inferer=partial_x0_inferer)\n",
    "        vw.load(name)\n",
    "        return vw\n",
    "\n",
    "    def get_param_count(self, trainable: bool = True) -> int:\n",
    "        r\"\"\"\n",
    "        Return number of parameters in detector.\n",
    "\n",
    "        Arguments:\n",
    "            trainable: if true (default) only count trainable parameters\n",
    "\n",
    "        Returns:\n",
    "            Number of (trainable) parameters in detector\n",
    "        \"\"\"\n",
    "\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad or not trainable)\n",
    "\n",
    "    def _scan_volume(self) -> None:\n",
    "        # Scan volume with muon batches\n",
    "        self.fit_params.wpreds, self.fit_params.weights = [], []\n",
    "        if self.fit_params.state != \"test\":\n",
    "            muon_bar = progress_bar(range(self.fit_params.n_mu_per_volume // self.fit_params.mu_bs), display=False, leave=False)\n",
    "        else:\n",
    "            muon_bar = progress_bar(range(self.fit_params.n_mu_per_volume // self.fit_params.mu_bs), parent=self.fit_params.passive_bar)\n",
    "        for _ in muon_bar:\n",
    "            self.fit_params.mu = MuonBatch(self.mu_generator(self.fit_params.mu_bs), init_z=self.volume.h)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_mu_batch_begin()\n",
    "            self.volume(self.fit_params.mu)\n",
    "            self.fit_params.sb = self.partial_scatter_inferer(self.fit_params.mu, self.volume)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_scatter_end()\n",
    "            inferer = self.partial_x0_inferer(self.fit_params.sb, self.default_pred)\n",
    "            pred, wgt = inferer.pred_x0(inc_default=False)\n",
    "            self.fit_params.wpreds.append(pred * wgt)\n",
    "            self.fit_params.weights.append(wgt)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_mu_batch_end()\n",
    "\n",
    "        # Predict volume based on all muon batches\n",
    "        for c in self.fit_params.cbs:\n",
    "            c.on_x0_pred_begin()\n",
    "        wgt = torch.stack(self.fit_params.weights, dim=0).sum(0)\n",
    "        pred = torch.stack(self.fit_params.wpreds, dim=0).sum(0) / wgt\n",
    "        if self.fit_params.use_default_pred:\n",
    "            pred, wgt = inferer.add_default_pred(pred, wgt)\n",
    "        self.fit_params.weight = wgt\n",
    "        self.fit_params.pred = pred\n",
    "\n",
    "        for c in self.fit_params.cbs:\n",
    "            c.on_x0_pred_end()\n",
    "\n",
    "        # Compute loss for volume\n",
    "        if self.fit_params.state != \"test\" and self.loss_func is not None:\n",
    "            loss = self.loss_func(pred_x0=self.fit_params.pred, pred_weight=self.fit_params.weight, volume=self.volume)\n",
    "            if self.fit_params.loss_val is None:\n",
    "                self.fit_params.loss_val = loss\n",
    "            else:\n",
    "                self.fit_params.loss_val = self.fit_params.loss_val + loss\n",
    "\n",
    "    def _scan_volumes(self, passives: PassiveYielder) -> None:\n",
    "        if self.fit_params.state == \"test\":\n",
    "            self.fit_params.passive_bar = master_bar(passives)\n",
    "        for i, passive in enumerate(self.fit_params.passive_bar if self.fit_params.state == \"test\" else passives):\n",
    "            self.fit_params.volume_id = i\n",
    "            if self.fit_params.state != \"test\" and i % self.fit_params.passive_bs == 0:  # Volume batch start\n",
    "                self.fit_params.loss_val = None\n",
    "                for c in self.fit_params.cbs:\n",
    "                    c.on_volume_batch_begin()\n",
    "\n",
    "            self.volume.load_rad_length(passive)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_volume_begin()\n",
    "            self._scan_volume()\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_volume_end()\n",
    "\n",
    "            if self.fit_params.state != \"test\" and (i + 1) % self.fit_params.passive_bs == 0:  # Volume batch end\n",
    "                if self.fit_params.loss_val is not None:\n",
    "                    self.fit_params.mean_loss = self.fit_params.loss_val / self.fit_params.passive_bs\n",
    "                for c in self.fit_params.cbs:\n",
    "                    c.on_volume_batch_end()\n",
    "\n",
    "                if self.fit_params.state == \"train\":\n",
    "                    # Compute update step\n",
    "                    for o in self.opts.values():\n",
    "                        o.zero_grad()\n",
    "                    for c in self.fit_params.cbs:\n",
    "                        c.on_backwards_begin()\n",
    "                    self.fit_params.mean_loss.backward()\n",
    "                    for c in self.fit_params.cbs:\n",
    "                        c.on_backwards_end()        \n",
    "                    for o in self.opts.values():\n",
    "                        o.step()\n",
    "                        \n",
    "#                     for d in self.volume.get_detectors():\n",
    "#                         for p in d.panels:\n",
    "#                             print('xy', p.xy.data, p.xy.grad)\n",
    "#                             print('z', p.z.data, p.z.grad)\n",
    "#                     for d in self.volume.get_detectors():\n",
    "#                         for p in d.panels:\n",
    "#                             print('xy_span', p.xy_span.data, p.xy_span.grad)\n",
    "\n",
    "                if len(passives) - (i + 1) < self.fit_params.passive_bs:\n",
    "                    break\n",
    "\n",
    "    def _fit_epoch(self) -> None:\n",
    "        def run_epoch(passives: PassiveYielder) -> None:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_epoch_begin()\n",
    "            self._scan_volumes(passives)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_epoch_end()\n",
    "\n",
    "        self.fit_params.epoch += 1\n",
    "        # Training\n",
    "        self.volume.train()\n",
    "        self.fit_params.state = \"train\"\n",
    "        run_epoch(self.fit_params.trn_passives)\n",
    "\n",
    "        # Validation\n",
    "        if self.fit_params.val_passives is not None:\n",
    "            self.volume.eval()\n",
    "            self.fit_params.state = \"valid\"\n",
    "            run_epoch(self.fit_params.val_passives)\n",
    "\n",
    "    @staticmethod\n",
    "    def _sort_cbs(cbs: List[Callback]) -> Tuple[List[CyclicCallback], Optional[MetricLogger], Optional[List[EvalMetric]]]:\n",
    "        cyclic_cbs, metric_log, metric_cbs = [], None, []\n",
    "        for c in cbs:\n",
    "            if isinstance(c, CyclicCallback):\n",
    "                cyclic_cbs.append(c)  # CBs that might prevent a wrapper from stopping training due to a hyper-param cycle\n",
    "            if isinstance(c, MetricLogger):\n",
    "                metric_log = c  # CB that logs losses and eval_metrics\n",
    "            if isinstance(c, EvalMetric):\n",
    "                metric_cbs.append(c)  # CB that computes additional performance metrics\n",
    "        return cyclic_cbs, metric_log, metric_cbs\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        n_epochs: int,\n",
    "        passive_bs: int,\n",
    "        n_mu_per_volume: int,\n",
    "        mu_bs: int,\n",
    "        trn_passives: PassiveYielder,\n",
    "        val_passives: Optional[PassiveYielder],\n",
    "        cbs: Optional[List[Callback]] = None,\n",
    "        cb_savepath: Path = Path(\"train_weights\"),\n",
    "    ) -> List[Callback]:\n",
    "\n",
    "        if cbs is None:\n",
    "            cbs = []\n",
    "        cyclic_cbs, metric_log, metric_cbs = self._sort_cbs(cbs)\n",
    "\n",
    "        self.fit_params = FitParams(\n",
    "            cbs=cbs,\n",
    "            cyclic_cbs=cyclic_cbs,\n",
    "            metric_log=metric_log,\n",
    "            metric_cbs=metric_cbs,\n",
    "            stop=False,\n",
    "            n_epochs=n_epochs,\n",
    "            mu_bs=mu_bs,\n",
    "            n_mu_per_volume=n_mu_per_volume,\n",
    "            cb_savepath=Path(cb_savepath),\n",
    "            trn_passives=trn_passives,\n",
    "            val_passives=val_passives,\n",
    "            passive_bs=passive_bs,\n",
    "        )\n",
    "        self.fit_params.cb_savepath.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.set_wrapper(self)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_train_begin()\n",
    "            self.fit_params.epoch_bar = progress_bar(range(self.fit_params.n_epochs))\n",
    "            for e in self.fit_params.epoch_bar:\n",
    "                self._fit_epoch()\n",
    "                if self.fit_params.stop:\n",
    "                    break\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_train_end()\n",
    "        finally:\n",
    "            self.fit_params = None\n",
    "            torch.cuda.empty_cache()\n",
    "        return cbs\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        passives: PassiveYielder,\n",
    "        n_mu_per_volume: int,\n",
    "        mu_bs: int,\n",
    "        use_default_pred: bool = False,\n",
    "        pred_cb: PredHandler = PredHandler(),\n",
    "        cbs: Optional[List[Callback]] = None,\n",
    "        cb_savepath: Path = Path(\"train_weights\"),\n",
    "    ) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        if cbs is None:\n",
    "            cbs = []\n",
    "        cbs.append(pred_cb)\n",
    "        passives.shuffle = False\n",
    "\n",
    "        self.fit_params = FitParams(\n",
    "            n_mu_per_volume=n_mu_per_volume,\n",
    "            mu_bs=mu_bs,\n",
    "            cbs=cbs,\n",
    "            tst_passives=passives,\n",
    "            state=\"test\",\n",
    "            cb_savepath=cb_savepath,\n",
    "            use_default_pred=use_default_pred,\n",
    "        )\n",
    "        try:\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.set_wrapper(self)\n",
    "            self.volume.eval()\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_pred_begin()\n",
    "            self._scan_volumes(self.fit_params.tst_passives)\n",
    "            for c in self.fit_params.cbs:\n",
    "                c.on_pred_end()\n",
    "        finally:\n",
    "            self.fit_params = None\n",
    "            cbs.pop()  # Remove pred_cb to avoid mutating cbs\n",
    "            torch.cuda.empty_cache()\n",
    "        return pred_cb.get_preds()\n",
    "\n",
    "    def get_opt_lr(self, opt:str) -> float:\n",
    "        return self.opts[opt].param_groups[0][\"lr\"]\n",
    "\n",
    "    def set_opt_lr(self, lr: float, opt:str) -> None:\n",
    "        self.opts[opt].param_groups[0][\"lr\"] = lr\n",
    "\n",
    "    def get_opt_mom(self, opt:str) -> float:\n",
    "        if \"betas\" in self.opts[opt].param_groups[0]:\n",
    "            return self.opts[opt].param_groups[0][\"betas\"][0]\n",
    "        else:\n",
    "            return self.opts[opt].param_groups[0][\"momentum\"]\n",
    "\n",
    "    def set_opt_mom(self, mom: float, opt:str) -> None:\n",
    "        if \"betas\" in self.opts[opt].param_groups[0]:\n",
    "            self.opts[opt].param_groups[0][\"betas\"] = (mom, self.opts[opt].param_groups[0][\"betas\"][1])\n",
    "        else:\n",
    "            self.opts[opt].param_groups[0][\"momentum\"] = mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeWrapper(AbsVolumeWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        res_opt: PartialOpt,\n",
    "        eff_opt: PartialOpt,\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ):\n",
    "        super().__init__(volume=volume, partial_opts={'res_opt':res_opt, 'eff_opt':eff_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                         mu_generator=mu_generator, partial_scatter_inferer=ScatterBatch, partial_x0_inferer=X0Inferer)\n",
    "\n",
    "    def _build_opt(\n",
    "        self, res_opt: PartialOpt, eff_opt: PartialOpt\n",
    "    ) -> None:\n",
    "        self.opts = {'res_opt': res_opt((l.resolution for l in self.volume.get_detectors())),\n",
    "                     'eff_opt': eff_opt((l.efficiency for l in self.volume.get_detectors()))}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ) -> VolumeWrapper:\n",
    "        return super().from_save(name, partial_opts={'res_opt':res_opt, 'eff_opt':eff_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                                 mu_generator=mu_generator, partial_scatter_inferer=ScatterBatch, partial_x0_inferer=X0Inferer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PanelVolumeWrapper(AbsVolumeWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: Volume,\n",
    "        *,\n",
    "        xy_pos_opt: PartialOpt,\n",
    "        z_pos_opt: PartialOpt,\n",
    "        xy_span_opt: PartialOpt,\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ):\n",
    "        super().__init__(volume=volume, partial_opts={'xy_pos_opt':xy_pos_opt, 'z_pos_opt':z_pos_opt, 'xy_span_opt':xy_span_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                         mu_generator=mu_generator, partial_scatter_inferer=PanelScatterBatch, partial_x0_inferer=PanelX0Inferer)\n",
    "\n",
    "    def _build_opt(\n",
    "        self, xy_pos_opt: PartialOpt, z_pos_opt: PartialOpt, xy_span_opt: PartialOpt\n",
    "    ) -> None:\n",
    "        self.opts = {'xy_pos_opt': xy_pos_opt((p.xy for l in self.volume.get_detectors() for p in l.panels)),\n",
    "                     'z_pos_opt': z_pos_opt((p.z for l in self.volume.get_detectors() for p in l.panels)),\n",
    "                     'xy_span_opt': xy_span_opt((p.xy_span for l in self.volume.get_detectors() for p in l.panels))}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_save(\n",
    "        cls,\n",
    "        name: str,\n",
    "        *,\n",
    "        partial_opts: Dict[str, PartialOpt],\n",
    "        loss_func: Optional[DetectorLoss],\n",
    "        default_pred: Optional[float] = X0[\"beryllium\"],\n",
    "        mu_generator: Callable[[int], Tensor] = generate_batch,\n",
    "    ) -> VolumeWrapper:\n",
    "        return super().from_save(name, partial_opts={'xyz_opt':xyz_opt, 'xy_span_opt':xy_span_opt}, loss_func=loss_func, default_pred=default_pred,\n",
    "                                 mu_generator=mu_generator, partial_scatter_inferer=PanelScatterBatch, partial_x0_inferer=PanelX0Inferer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelDetectorLoss(nn.Module):\n",
    "    def __init__(self, cost_coef: Optional[float] = None):\n",
    "        super().__init__()\n",
    "        self.cost_coef = cost_coef\n",
    "        self.sub_losses: Dict[str, Tensor] = {}  # Store subcomponents in dict for telemetry\n",
    "\n",
    "    def _compute_cost_coef(self, cost: Tensor, inference: Tensor) -> None:\n",
    "        self.cost_coef = inference.detach() / cost.detach()\n",
    "\n",
    "    def forward(self, pred_x0: Tensor, pred_weight: Tensor, volume: Volume) -> Tensor:\n",
    "        true_x0 = volume.get_rad_cube()\n",
    "        inference = torch.mean(pred_x0 - true_x0).pow(2)\n",
    "        self.sub_losses[\"error\"] = inference\n",
    "        cost = volume.get_cost()\n",
    "        if self.cost_coef is None:\n",
    "            self._compute_cost_coef(cost, inference)\n",
    "        self.sub_losses[\"cost\"] = self.cost_coef * cost\n",
    "        return self.sub_losses[\"error\"] + self.sub_losses[\"cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython.display import display\n",
    "\n",
    "class MetricLogger(Callback):\n",
    "    r\"\"\"\n",
    "    Provides live feedback during training showing a variety of metrics to help highlight problems or test hyper-parameters without completing a full training.\n",
    "    If `show_plots` is false, will instead print training and validation losses at the end of each epoch.\n",
    "    The full history is available as a dictionary by calling `MetricLogger.get_loss_history`.\n",
    "    \"\"\"\n",
    "\n",
    "    tk_sz = 16\n",
    "    tk_col = \"black\"\n",
    "    lbl_sz = 24\n",
    "    lbl_col = \"black\"\n",
    "    leg_sz = 16\n",
    "    cat_palette = \"tab10\"\n",
    "    style = {\"style\": \"whitegrid\", \"rc\": {\"patch.edgecolor\": \"none\"}}\n",
    "    h_mid = 8\n",
    "    w_mid = h_mid * 16 / 9\n",
    "\n",
    "    def __init__(self, show_plots: bool = IN_NOTEBOOK):\n",
    "        self.show_plots = show_plots\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        self.loss_vals: Dict[str, List[float]] = {\"Training\": [], \"Validation\": []}\n",
    "        self.sub_losses: Dict[str, List[float]] = defaultdict(list)\n",
    "        self.best_loss: float = math.inf\n",
    "        self.val_epoch_results: Optional[Tuple[float, Optional[float]]] = None\n",
    "        self.metric_cbs: List[EvalMetric] = []\n",
    "        self.n_trn_batches = len(self.wrapper.fit_params.trn_passives) // self.wrapper.fit_params.passive_bs\n",
    "\n",
    "        self.metric_vals: List[List[float]] = [[] for _ in self.wrapper.fit_params.metric_cbs]\n",
    "        self.main_metric_idx: Optional[int] = None\n",
    "        self.lock_to_metric: bool = False\n",
    "        if len(self.wrapper.fit_params.metric_cbs) > 0:\n",
    "            self.main_metric_idx = 0\n",
    "            for i, c in enumerate(self.wrapper.fit_params.metric_cbs):\n",
    "                if c.main_metric:\n",
    "                    self.main_metric_idx = i\n",
    "                    self.lock_to_metric = True\n",
    "                    break\n",
    "        self._prep_plots()\n",
    "        self.display = display(self.fig, display_id=True)\n",
    "        \n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        return self.fig.add_gridspec(3 + (self.main_metric_idx is None), 1)\n",
    "\n",
    "    def _prep_plots(self) -> None:\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.fig = plt.figure(figsize=(self.w_mid, self.w_mid), constrained_layout=True)\n",
    "                self.grid_spec = self._build_grid_spec()\n",
    "                self.loss_ax = self.fig.add_subplot(self.grid_spec[:3, :])\n",
    "                self.sub_loss_ax = self.fig.add_subplot(self.grid_spec[3:4, :])\n",
    "                if self.main_metric_idx is not None:\n",
    "                    self.metric_ax = self.fig.add_subplot(self.grid_spec[4:5, :])\n",
    "                for ax in [self.loss_ax, self.sub_loss_ax]:\n",
    "                    ax.tick_params(axis=\"x\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    ax.tick_params(axis=\"y\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                self.sub_loss_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                self.loss_ax.set_ylabel(\"Loss\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                self.sub_loss_ax.set_ylabel(\"Loss Composition\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                if self.main_metric_idx is not None:\n",
    "                    self.metric_ax.tick_params(axis=\"x\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    self.metric_ax.tick_params(axis=\"y\", labelsize=0.8 * self.tk_sz, labelcolor=self.tk_col)\n",
    "                    self.metric_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                    self.metric_ax.set_ylabel(self.wrapper.fit_params.metric_cbs[self.main_metric_idx].name, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "    def on_train_begin(self) -> None:\n",
    "        r\"\"\"\n",
    "        Prepare for new training\n",
    "        \"\"\"\n",
    "\n",
    "        super().on_train_begin()\n",
    "        self._reset()\n",
    "\n",
    "    def on_epoch_begin(self) -> None:\n",
    "        r\"\"\"\n",
    "        Prepare to track new loss\n",
    "        \"\"\"\n",
    "\n",
    "        self.tmp_loss, self.batch_cnt, self.volume_cnt = 0, 0, 0\n",
    "        self.tmp_sub_losses: Dict[str, float] = defaultdict(float)\n",
    "\n",
    "    def on_volume_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"valid\" and self.wrapper.loss_func is not None and hasattr(self.wrapper.loss_func, \"sub_losses\"):\n",
    "            for k, v in self.wrapper.loss_func.sub_losses.items():\n",
    "                self.tmp_sub_losses[k] += v.data.item()\n",
    "            self.volume_cnt += 1\n",
    "\n",
    "    def on_backwards_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"train\":\n",
    "            self.loss_vals[\"Training\"].append(self.wrapper.fit_params.mean_loss.data.item())\n",
    "\n",
    "    def on_volume_batch_end(self) -> None:\n",
    "        if self.wrapper.fit_params.state == \"valid\":\n",
    "            self.tmp_loss += self.wrapper.fit_params.mean_loss.data.item()\n",
    "            self.batch_cnt += 1\n",
    "\n",
    "    def on_epoch_end(self) -> None:\n",
    "        r\"\"\"\n",
    "        If validation epoch finished, record validation losses, compute info and update plots\n",
    "        \"\"\"\n",
    "\n",
    "        if self.wrapper.fit_params.state == \"valid\":\n",
    "            self.loss_vals[\"Validation\"].append(self.tmp_loss / self.batch_cnt)\n",
    "            for k, v in self.tmp_sub_losses.items():\n",
    "                self.sub_losses[k].append(v / (self.loss_vals[\"Validation\"][-1] * self.volume_cnt))  # Fractional components\n",
    "\n",
    "            for i, c in enumerate(self.wrapper.fit_params.metric_cbs):\n",
    "                self.metric_vals[i].append(c.get_metric())\n",
    "            if self.loss_vals[\"Validation\"][-1] <= self.best_loss:\n",
    "                self.best_loss = self.loss_vals[\"Validation\"][-1]\n",
    "\n",
    "            if self.show_plots:\n",
    "                self.update_plot()\n",
    "                self.display.update(self.fig)\n",
    "            else:\n",
    "                self.print_losses()\n",
    "\n",
    "            m = None\n",
    "            if self.lock_to_metric:\n",
    "                m = self.metric_vals[self.main_metric_idx][-1]\n",
    "                if not self.wrapper.fit_params.metric_cbs[self.main_metric_idx].lower_metric_better:\n",
    "                    m *= -1\n",
    "            self.val_epoch_results = self.loss_vals[\"Validation\"][-1], m\n",
    "\n",
    "    def print_losses(self) -> None:\n",
    "        r\"\"\"\n",
    "        Print training and validation losses for the last epoch\n",
    "        \"\"\"\n",
    "\n",
    "        p = f'Epoch {len(self.loss_vals[\"Validation\"])}: '\n",
    "        p += f'Training = {np.mean(self.loss_vals[\"Training\"][-self.n_trn_batches:]):.2E} | '\n",
    "        p += f'Validation = {self.loss_vals[\"Validation\"][-1]:.2E}'\n",
    "        for m, v in zip(self.wrapper.fit_params.metric_cbs, self.metric_vals):\n",
    "            p += f\" {m.name} = {v[-1]:.2E}\"\n",
    "        print(p)\n",
    "\n",
    "    def update_plot(self) -> None:\n",
    "        r\"\"\"\n",
    "        Updates the plot(s).\n",
    "        \"\"\"\n",
    "\n",
    "        # Loss\n",
    "        self.loss_ax.clear()\n",
    "        self.sub_loss_ax.clear()\n",
    "        with sns.axes_style(**self.style), sns.color_palette(self.cat_palette):\n",
    "            self.loss_ax.plot(\n",
    "                (1 / self.n_trn_batches)\n",
    "                + np.linspace(0, len(self.loss_vals[\"Validation\"]), self.n_trn_batches * len(self.loss_vals[\"Validation\"]), endpoint=False),\n",
    "                self.loss_vals[\"Training\"],\n",
    "                label=\"Training\",\n",
    "            )\n",
    "            x = range(1, len(self.loss_vals[\"Validation\"]) + 1)\n",
    "            self.loss_ax.plot(x, self.loss_vals[\"Validation\"], label=\"Validation\")\n",
    "            keys = sorted([k for k in self.sub_losses])\n",
    "            self.sub_loss_ax.stackplot(x, *[self.sub_losses[k] for k in keys], labels=keys)\n",
    "            self.loss_ax.plot([1 / self.n_trn_batches, x[-1]], [self.best_loss, self.best_loss], label=f\"Best = {self.best_loss:.3E}\", linestyle=\"--\")\n",
    "            self.loss_ax.legend(loc=\"upper right\", fontsize=0.8 * self.leg_sz)\n",
    "            self.sub_loss_ax.legend(loc=\"upper left\", fontsize=0.8 * self.leg_sz)\n",
    "            for ax in [self.loss_ax, self.sub_loss_ax]:\n",
    "                ax.grid(True, which=\"both\")\n",
    "                ax.set_xlim(1 / self.n_trn_batches, x[-1])\n",
    "            self.sub_loss_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "            self.loss_ax.set_ylabel(\"Loss\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "            self.sub_loss_ax.set_ylabel(\"Loss Composition\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "        if len(self.loss_vals[\"Validation\"]) > 1:\n",
    "            # Metrics\n",
    "            if self.main_metric_idx is not None:\n",
    "                self.metric_ax.clear()\n",
    "                with sns.axes_style(**self.style), sns.color_palette(self.cat_palette) as palette:\n",
    "                    x = range(self.n_trn_batches, self.n_trn_batches * len(self.loss_vals[\"Validation\"]) + 1, self.n_trn_batches)\n",
    "                    y = self.metric_vals[self.main_metric_idx]\n",
    "                    self.metric_ax.plot(x, y, color=palette[1])\n",
    "                    best = np.nanmin(y) if self.wrapper.fit_params.metric_cbs[self.main_metric_idx].lower_metric_better else np.nanmax(y)\n",
    "                    self.metric_ax.plot([1, x[-1]], [best, best], label=f\"Best = {best:.3E}\", linestyle=\"--\", color=palette[2])\n",
    "                    self.metric_ax.legend(loc=\"upper left\", fontsize=0.8 * self.leg_sz)\n",
    "                    self.metric_ax.grid(True, which=\"both\")\n",
    "                    self.metric_ax.set_xlim(1 / self.n_trn_batches, x[-1])\n",
    "                    self.metric_ax.set_xlabel(\"Epoch\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "                    self.metric_ax.set_ylabel(self.wrapper.fit_params.metric_cbs[self.main_metric_idx].name, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "    def on_train_end(self) -> None:\n",
    "        plt.clf()  # prevent plot be shown twice\n",
    "        self.metric_cbs = self.wrapper.fit_params.metric_cbs  # Copy referenece since fit_params gets set to None at end of training\n",
    "\n",
    "    def get_loss_history(self) -> Tuple[Dict[str, List[float]], Dict[str, List[float]]]:\n",
    "        r\"\"\"\n",
    "        Get the current history of losses and metrics\n",
    "\n",
    "        Returns:\n",
    "            history: tuple of ordered dictionaries: first with losses, second with validation metrics\n",
    "        \"\"\"\n",
    "\n",
    "        history: Tuple[Dict[str, List[float]], Dict[str, List[float]]] = ({}, {})\n",
    "        history[0][\"Training\"] = self.loss_vals[\"Training\"]\n",
    "        history[0][\"Validation\"] = self.loss_vals[\"Validation\"]\n",
    "        for v, c in zip(self.metric_vals, self.metric_cbs):\n",
    "            history[1][c.name] = v\n",
    "        return history\n",
    "\n",
    "    def get_results(self, loaded_best: bool) -> Dict[str, float]:\n",
    "        if loaded_best:\n",
    "            if self.lock_to_metric:\n",
    "                idx = (\n",
    "                    np.nanargmin(self.metric_vals[self.main_metric_idx])\n",
    "                    if self.metric_cbs[self.main_metric_idx].lower_metric_better\n",
    "                    else np.nanargmax(self.metric_vals[self.main_metric_idx])\n",
    "                )\n",
    "            else:\n",
    "                idx = np.nanargmin(self.loss_vals[\"Validation\"])\n",
    "        else:\n",
    "            idx = -1\n",
    "\n",
    "        results = {}\n",
    "        results[\"loss\"] = self.loss_vals[\"Validation\"][idx]\n",
    "        if len(self.metric_cbs) > 0:\n",
    "            for c, v in zip(self.metric_cbs, np.array(self.metric_vals)[:, idx]):\n",
    "                results[c.name] = v\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerMetricLogger(MetricLogger):\n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        self.n_dets = len(self.wrapper.get_detectors())\n",
    "        return self.fig.add_gridspec(5 + (self.main_metric_idx is None), self.n_dets)\n",
    "    \n",
    "    def _set_axes_labels(self) -> None:\n",
    "        for i in range(self.n_dets):\n",
    "            self.eff_axes[i].set_xlabel(f\"Det. {i}\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        self.res_axes[0].set_ylabel(\"Resolution\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        self.eff_axes[0].set_ylabel(\"Efficiency\", fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "    \n",
    "    def _prep_plots(self) -> None:\n",
    "        super()._prep_plots()\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.res_axes = [self.fig.add_subplot(self.grid_spec[-2:-1, i : i + 1]) for i in range(self.n_dets)]\n",
    "                self.eff_axes = [self.fig.add_subplot(self.grid_spec[-1:, i : i + 1]) for i in range(self.n_dets)]\n",
    "                self.res_cbar_ax = self.fig.add_axes([1.0, 0.04, 0.03, 0.31])\n",
    "                self.eff_cbar_ax = self.fig.add_axes([1.1, 0.04, 0.03, 0.31])\n",
    "                \n",
    "                \n",
    "    def update_plot(self) -> None:\n",
    "        super().update_plot()\n",
    "        with sns.axes_style(**self.style):\n",
    "            dets = self.wrapper.get_detectors()\n",
    "            res = np.array([l.resolution.data.cpu().numpy() for l in dets])\n",
    "            eff = np.array([l.efficiency.data.cpu().numpy() for l in dets])\n",
    "            res_min, res_max = res.min(), res.max()\n",
    "            eff_min, eff_max = eff.min(), eff.max()\n",
    "\n",
    "            for i, l in enumerate(dets):\n",
    "                self.res_axes[i].clear()\n",
    "                self.eff_axes[i].clear()\n",
    "                sns.heatmap(\n",
    "                    res[i],\n",
    "                    ax=self.res_axes[i],\n",
    "                    cmap=\"viridis\",\n",
    "                    square=True,\n",
    "                    cbar=(i == 0),\n",
    "                    vmin=res_min,\n",
    "                    vmax=res_max,\n",
    "                    cbar_ax=self.res_cbar_ax if i == 0 else None,\n",
    "                )\n",
    "                sns.heatmap(\n",
    "                    eff[i],\n",
    "                    ax=self.eff_axes[i],\n",
    "                    cmap=\"plasma\",\n",
    "                    square=True,\n",
    "                    cbar=(i == 0),\n",
    "                    vmin=eff_min,\n",
    "                    vmax=eff_max,\n",
    "                    cbar_ax=self.eff_cbar_ax if i == 0 else None,\n",
    "                )\n",
    "            self._set_axes_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.z-dl.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "class PanelMetricLogger(MetricLogger):\n",
    "    def _build_grid_spec(self) -> mpl.gridspec.GridSpec:\n",
    "        self.n_dets = len(self.wrapper.get_detectors())\n",
    "        return self.fig.add_gridspec(5 + (self.main_metric_idx is None), 3)\n",
    "    \n",
    "    def _set_axes_labels(self) -> None:\n",
    "        for ax, x in zip(self.below_det,['x','y','x']):\n",
    "            ax.set_xlabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "        for i, (ax, x) in enumerate(zip(self.above_det,['z','z','y'])):\n",
    "            if i == 0:\n",
    "                x = 'Above, ' + x\n",
    "            ax.set_ylabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col) \n",
    "        for i, (ax, x) in enumerate(zip(self.below_det,['z','z','y'])):\n",
    "            if i == 0:\n",
    "                x = 'Below, ' + x\n",
    "            ax.set_ylabel(x, fontsize=0.8 * self.lbl_sz, color=self.lbl_col)\n",
    "\n",
    "        for ax, det in zip((self.above_det,self.below_det), self.wrapper.get_detectors()):\n",
    "            lw,z = det.lw.detach().cpu(), det.z.detach().cpu()\n",
    "            ax[0].set_xlim(0, lw[0])\n",
    "            ax[1].set_xlim(0, lw[1])\n",
    "            ax[2].set_xlim(0,lw[0])\n",
    "            ax[0].set_ylim(z-det.size,z)\n",
    "            ax[1].set_ylim(z-det.size,z)\n",
    "            ax[2].set_ylim(0,lw[1])\n",
    "            ax[2].set_aspect('equal', 'box')\n",
    "    \n",
    "    def _prep_plots(self) -> None:\n",
    "        super()._prep_plots()\n",
    "        if self.show_plots:\n",
    "            with sns.axes_style(**self.style):\n",
    "                self.above_det = [self.fig.add_subplot(self.grid_spec[-2:-1, i : i + 1]) for i in range(3)]\n",
    "                self.below_det = [self.fig.add_subplot(self.grid_spec[-1:, i : i + 1]) for i in range(3)]\n",
    "                \n",
    "                    \n",
    "                self._set_axes_labels()\n",
    "                \n",
    "                \n",
    "    def update_plot(self) -> None:\n",
    "        super().update_plot()\n",
    "        with sns.axes_style(**self.style), sns.color_palette(self.cat_palette) as palette:\n",
    "            for axes, det in zip([self.above_det, self.below_det],self.wrapper.get_detectors()):\n",
    "                loc, span = [], []\n",
    "                for p in det.panels:\n",
    "                    loc.append(np.concatenate((p.xy.detach().cpu().numpy(),p.z.detach().cpu().numpy()[None])))\n",
    "                    span.append(p.xy_span.detach().cpu().numpy())\n",
    "                loc, span = np.array(loc), np.array(span)\n",
    "                    \n",
    "                for ax in axes: ax.clear()\n",
    "                for p in range(len(loc)):\n",
    "                    axes[0].add_line(mlines.Line2D((loc[p,0]-(span[p,0]/2),loc[p,0]+(span[p,0]/2)), (loc[p,2],loc[p,2]), color=palette[p]))  # xz\n",
    "                    axes[1].add_line(mlines.Line2D((loc[p,1]-(span[p,1]/2),loc[p,1]+(span[p,1]/2)), (loc[p,2],loc[p,2]), color=palette[p]))  # yz\n",
    "                    axes[2].add_patch(patches.Rectangle((loc[p,0]-(span[p,0]/2), loc[p,1]-(span[p,1]/2)), span[p,0], span[p,1],linewidth=1, edgecolor=palette[p], facecolor='none'))  # xy\n",
    "                                \n",
    "            self._set_axes_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = PanelVolumeWrapper(volume=volume, xy_pos_opt=partial(torch.optim.SGD, lr=2e-2), z_pos_opt=partial(torch.optim.SGD, lr=2e-4), xy_span_opt=partial(torch.optim.SGD, lr=2e-2),\n",
    "                        loss_func=PanelDetectorLoss(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = PanelMetricLogger(show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation.callbacks.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1024x1024 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/25 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2]] is at version 20; expected version 18 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-404-757d5290b7c9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epochs, passive_bs, n_mu_per_volume, mu_bs, trn_passives, val_passives, cbs, cb_savepath)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-404-757d5290b7c9>\u001b[0m in \u001b[0;36m_fit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_passives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-404-757d5290b7c9>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(passives)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_volumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-404-757d5290b7c9>\u001b[0m in \u001b[0;36m_scan_volumes\u001b[0;34m(self, passives)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backwards_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backwards_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tomopt/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tomopt/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2]] is at version 20; expected version 18 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1024x1024 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "_ = wrapper.fit(25, n_mu_per_volume=1000, mu_bs=100, passive_bs=1, trn_passives=trn_passives, val_passives=trn_passives, cbs=[ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Volume(\n",
       "  (layers): ModuleList(\n",
       "    (0): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.3401, 0.5221]), 0.9996697902679443, and xy span tensor([0.3768, 0.4970])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.4982, 0.5026]), 0.9631624817848206, and xy span tensor([0.4987, 0.4996])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.4763, 0.4975]), 0.8864086270332336, and xy span tensor([0.4822, 0.5003])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.1885, 0.5154]), 0.8337922096252441, and xy span tensor([0.2654, 0.4974])\n",
       "      )\n",
       "    )\n",
       "    (1): PassiveLayer()\n",
       "    (2): PassiveLayer()\n",
       "    (3): PassiveLayer()\n",
       "    (4): PassiveLayer()\n",
       "    (5): PassiveLayer()\n",
       "    (6): PassiveLayer()\n",
       "    (7): DetectorLayer(\n",
       "      (panels): ModuleList(\n",
       "        (0): <class '__main__.DetectorPanel'> located at tensor([0.4991, 0.5270]), 0.19998009502887726, and xy span tensor([0.4993, 0.4929])\n",
       "        (1): <class '__main__.DetectorPanel'> located at tensor([0.5215, 0.5007]), 0.1715656816959381, and xy span tensor([0.5138, 0.5000])\n",
       "        (2): <class '__main__.DetectorPanel'> located at tensor([0.4898, 0.5022]), 0.08246137946844101, and xy span tensor([0.4935, 0.4994])\n",
       "        (3): <class '__main__.DetectorPanel'> located at tensor([0.4317, 0.5086]), 5.496815902006347e-06, and xy span tensor([0.4564, 0.4977])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
