{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.muon import *\n",
    "from tomopt.inference import *\n",
    "from tomopt.volume import *\n",
    "from tomopt.core import *\n",
    "from tomopt.optimisation import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arb_rad_length(*,z:float, lw:Tensor, size:float) -> float:\n",
    "    rad_length = torch.ones(list((lw/size).long()))*X0['beryllium']\n",
    "    if z >= 0.4 and z <= 0.5: rad_length[5:,5:] = X0['lead']\n",
    "    return rad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_cost(x:Tensor) -> Tensor:\n",
    "    return torch.expm1(3*F.relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_cost(x:Tensor) -> Tensor:\n",
    "    return F.relu(x/100)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers():\n",
    "    layers = []\n",
    "    lwh = Tensor([1,1,1])\n",
    "    size = 0.1\n",
    "    init_eff = 0.5\n",
    "    init_res = 1000\n",
    "    pos = 'above'\n",
    "    for z,d in zip(np.arange(lwh[2],0,-size), [1,1,0,0,0,0,0,0,1,1]):\n",
    "        if d:\n",
    "            layers.append(DetectorLayer(pos=pos, init_eff=init_eff, init_res=z*init_res,\n",
    "                                        lw=lwh[:2], z=z, size=size, eff_cost_func=eff_cost, res_cost_func=res_cost))\n",
    "        else:\n",
    "            pos = 'below'\n",
    "            layers.append(PassiveLayer(rad_length_func=arb_rad_length, lw=lwh[:2], z=z, size=size))\n",
    "\n",
    "    return nn.ModuleList(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "muons = MuonBatch(generate_batch(100), init_z=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume(muons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (DetectorLayer(), 0)\n",
      "1 (DetectorLayer(), 1)\n",
      "2 (DetectorLayer(), 2)\n",
      "3 (DetectorLayer(), 3)\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(zip(volume.get_detectors(), range(5))): print(i,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(9,-1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.utils import jacobian\n",
    "\n",
    "class GenScatterBatch(ScatterBatch):    \n",
    "    @staticmethod\n",
    "    def get_muon_trajectory(hits: List[Tensor], uncs: List[Tensor]) -> Tensor:\n",
    "        r\"\"\"\n",
    "        hits = [muons,detector,(x,y,z)]\n",
    "        uncs = [muons,detector,(unc,unc,0)]\n",
    "\n",
    "        Assume same unceratinty for x and y\n",
    "        \"\"\"\n",
    "        \n",
    "        hits, uncs = torch.stack(hits, dim=1), torch.stack(uncs, dim=1)\n",
    "\n",
    "        inv_unc2 = uncs[:, :, 0:1] ** -2\n",
    "        sum_inv_unc2 = inv_unc2.sum(dim=1)\n",
    "        mean_xyz = torch.sum(hits * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_xyz_z = torch.sum(hits * hits[:, :, 2:3] * inv_unc2, dim=1) / sum_inv_unc2\n",
    "        mean_xy = mean_xyz[:, :2]\n",
    "        mean_z = mean_xyz[:, 2:3]\n",
    "        mean_xy_z = mean_xyz_z[:, :2]\n",
    "        mean_z2 = mean_xyz_z[:, 2:3]\n",
    "\n",
    "        xy_star = (mean_xy - ((mean_z * mean_xy_z) / mean_z2)) / (1 - (mean_z.square() / mean_z2))\n",
    "        angles = (mean_xy_z - (xy_star * mean_z)) / mean_z2\n",
    "\n",
    "        def _calc_xyz(z: Tensor) -> Tensor:\n",
    "            return torch.cat([xy_star + (angles * z), z], dim=-1)\n",
    "        \n",
    "        return _calc_xyz(hits[:, 1, 2:3]) - _calc_xyz(hits[:, 0, 2:3])\n",
    "        \n",
    "    def compute_scatters(self) -> None:\n",
    "        r\"\"\"\n",
    "        Currently only handles 2 detectors above and below passive volume\n",
    "        \"\"\"\n",
    "        \n",
    "        # reco x, reco y, gen z, must be a list to allow computation of uncertainty\n",
    "        self.above_hits = [torch.cat([self.hits[\"above\"][\"xy\"][:,i], self.hits[\"above\"][\"z\"][:,i]], dim=-1) for i in range(self.hits[\"above\"][\"xy\"].shape[1])]  \n",
    "        self.below_hits = [torch.cat([self.hits[\"below\"][\"xy\"][:,i], self.hits[\"below\"][\"z\"][:,i]], dim=-1) for i in range(self.hits[\"below\"][\"xy\"].shape[1])]\n",
    "        self.n_hits_above = len(self.above_hits)\n",
    "        \n",
    "        def _get_hit_uncs(dets:List[DetectorLayer], hits:List[Tensor]) -> List[Tensor]:\n",
    "            res = []\n",
    "            for i, (l, h) in enumerate(zip(dets,hits)):\n",
    "                x = l.abs2idx(h)\n",
    "                r = 1 / l.resolution[x[:, 0], x[:, 1]]\n",
    "                res.append(torch.stack([r, r, torch.zeros_like(r)], dim=-1))\n",
    "            return res\n",
    "        \n",
    "        self.above_hit_uncs = _get_hit_uncs(self.volume.get_detectors()[:self.n_hits_above], self.above_hits)\n",
    "        self.below_hit_uncs = _get_hit_uncs(self.volume.get_detectors()[self.n_hits_above:], self.below_hits)\n",
    "        \n",
    "        v1 = self.get_muon_trajectory(self.above_hits, uncs=self.above_hit_uncs)\n",
    "        v2 = self.get_muon_trajectory(self.below_hits, uncs=self.below_hit_uncs)\n",
    "        \n",
    "        # scatter locations\n",
    "        v3 = torch.cross(v1, v2, dim=1)  # connecting vector perpendicular to both lines\n",
    "        rhs = self.below_hits[0] - self.above_hits[0]\n",
    "        lhs = torch.stack([v1, -v2, v3], dim=1).transpose(2, 1)\n",
    "        coefs = torch.linalg.solve(lhs, rhs)  # solve p1+t1*v1 + t3*v3 = p2+t2*v2 => p2-p1 = t1*v1 - t2*v2 + t3*v3\n",
    "\n",
    "        q1 = self.above_hits[0] + (coefs[:, 0:1] * v1)  # closest point on v1\n",
    "        self._loc = q1 + (coefs[:, 2:3] * v3 / 2)  # Move halfway along v3 from q1\n",
    "        self._loc_unc: Optional[Tensor] = None\n",
    "\n",
    "        # Theta deviations\n",
    "        self._theta_in = torch.arctan(v1[:, :2] / v1[:, 2:3])\n",
    "        self._theta_out = torch.arctan(v2[:, :2] / v2[:, 2:3])\n",
    "        self._dtheta = torch.abs(self._theta_in - self._theta_out)\n",
    "        self._theta_in_unc: Optional[Tensor] = None\n",
    "        self._theta_out_unc: Optional[Tensor] = None\n",
    "        self._dtheta_unc: Optional[Tensor] = None\n",
    "\n",
    "        # xy deviations\n",
    "        self._dxy = coefs[:, 2:3] * v3[:, :2]\n",
    "        self._dxy_unc: Optional[Tensor] = None\n",
    "            \n",
    "    def _compute_unc(self, var: Tensor, hits: List[Tensor], hit_uncs: List[Tensor]) -> Tensor:\n",
    "        unc2_sum = None\n",
    "        for i, (xi, unci) in enumerate(zip(hits, hit_uncs)):\n",
    "            for j, (xj, uncj) in enumerate(zip(hits, hit_uncs)):\n",
    "                if j < i:\n",
    "                    continue\n",
    "                dv_dx_2 = jacobian(var, xi).sum((2)) * jacobian(var, xj).sum((2)) if i != j else jacobian(var, xi).sum((2)) ** 2  # Muons, var_xyz, hit_xyz\n",
    "                \n",
    "                unc_2 = (dv_dx_2 * unci[:, None] * uncj[:, None]).sum(2)  # Muons, (x,y,z)\n",
    "                if unc2_sum is None:\n",
    "                    unc2_sum = unc_2\n",
    "                else:\n",
    "                    unc2_sum = unc2_sum + unc_2\n",
    "        return torch.sqrt(unc2_sum)\n",
    "\n",
    "    @property\n",
    "    def location(self) -> Tensor:\n",
    "        return self._loc\n",
    "\n",
    "    @property\n",
    "    def location_unc(self) -> Tensor:\n",
    "        if self._loc_unc is None:\n",
    "            self._loc_unc = self._compute_unc(\n",
    "                var=self._loc,\n",
    "                hits=self.above_hits+self.below_hits,\n",
    "                hit_uncs=self.above_hit_uncs+self.below_hit_uncs,\n",
    "            )\n",
    "        return self._loc_unc\n",
    "\n",
    "    @property\n",
    "    def dtheta(self) -> Tensor:\n",
    "        return self._dtheta\n",
    "\n",
    "    @property\n",
    "    def dtheta_unc(self) -> Tensor:\n",
    "        if self._dtheta_unc is None:\n",
    "            self._dtheta_unc = self._compute_unc(\n",
    "                var=self._dtheta,\n",
    "                hits=self.above_hits+self.below_hits,\n",
    "                hit_uncs=self.above_hit_uncs+self.below_hit_uncs,\n",
    "            )\n",
    "        return self._dtheta_unc\n",
    "\n",
    "    @property\n",
    "    def dxy(self) -> Tensor:\n",
    "        return self._dxy\n",
    "\n",
    "    @property\n",
    "    def dxy_unc(self) -> Tensor:\n",
    "        if self._dxy_unc is None:\n",
    "            self._dxy_unc = self._compute_unc(\n",
    "                var=self._dxy,\n",
    "                hits=self.above_hits+self.below_hits,\n",
    "                hit_uncs=self.above_hit_uncs+self.below_hit_uncs,\n",
    "            )\n",
    "        return self._dxy_unc\n",
    "\n",
    "    @property\n",
    "    def theta_in(self) -> Tensor:\n",
    "        return self._theta_in\n",
    "\n",
    "    @property\n",
    "    def theta_in_unc(self) -> Tensor:\n",
    "        if self._theta_in_unc is None:\n",
    "            self._theta_in_unc = self._compute_unc(var=self._theta_in, hits=self.above_hits, hit_uncs=self.above_hit_uncs)\n",
    "        return self._theta_in_unc\n",
    "\n",
    "    @property\n",
    "    def theta_out(self) -> Tensor:\n",
    "        return self._theta_out\n",
    "\n",
    "    @property\n",
    "    def theta_out_unc(self) -> Tensor:\n",
    "        if self._theta_out_unc is None:\n",
    "            self._theta_out_unc = self._compute_unc(var=self._theta_out, hits=self.below_hits, hit_uncs=self.below_hit_uncs)\n",
    "        return self._theta_out_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsb = GenScatterBatch(muons, volume)\n",
    "sb = ScatterBatch(muons, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9271,  0.8857,  0.1793],\n",
       "         [ 0.2274,  0.5313,  0.1083],\n",
       "         [ 0.7479,  0.2227,  0.0494],\n",
       "         [ 0.9296,  0.3082,  0.3317],\n",
       "         [ 0.9193,  0.6987,  0.0650],\n",
       "         [ 0.6436,  0.3648, -0.1672],\n",
       "         [ 0.9118,  0.3332,  0.0391],\n",
       "         [ 0.5644,  0.0162, -0.0211],\n",
       "         [ 0.2386,  0.0617,  0.0289],\n",
       "         [ 0.5692,  0.4057,  0.1498]], grad_fn=<SliceBackward>),\n",
       " tensor([[ 0.9271,  0.8857,  0.1793],\n",
       "         [ 0.2274,  0.5313,  0.1083],\n",
       "         [ 0.7479,  0.2227,  0.0494],\n",
       "         [ 0.9296,  0.3082,  0.3317],\n",
       "         [ 0.9193,  0.6987,  0.0650],\n",
       "         [ 0.6436,  0.3648, -0.1672],\n",
       "         [ 0.9118,  0.3332,  0.0391],\n",
       "         [ 0.5644,  0.0162, -0.0211],\n",
       "         [ 0.2386,  0.0617,  0.0289],\n",
       "         [ 0.5692,  0.4057,  0.1498]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.location[:10], sb.location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0095, 0.0086, 0.0761],\n",
       "         [0.0058, 0.0058, 0.0351],\n",
       "         [0.0081, 0.0083, 0.0778],\n",
       "         [0.0134, 0.0083, 0.1844],\n",
       "         [0.0098, 0.0075, 0.0512],\n",
       "         [0.0580, 0.0420, 0.3434],\n",
       "         [0.0072, 0.0261, 0.1366],\n",
       "         [0.0122, 0.0088, 0.1608],\n",
       "         [0.0186, 0.0083, 0.0733],\n",
       "         [0.0054, 0.0050, 0.0405]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0095, 0.0086, 0.0761],\n",
       "         [0.0058, 0.0058, 0.0351],\n",
       "         [0.0081, 0.0083, 0.0778],\n",
       "         [0.0134, 0.0083, 0.1844],\n",
       "         [0.0098, 0.0075, 0.0512],\n",
       "         [0.0580, 0.0420, 0.3434],\n",
       "         [0.0072, 0.0261, 0.1366],\n",
       "         [0.0122, 0.0088, 0.1608],\n",
       "         [0.0186, 0.0083, 0.0733],\n",
       "         [0.0054, 0.0050, 0.0405]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.location_unc[:10], sb.location_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0103, 0.0106],\n",
       "         [0.0104, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0103, 0.0105],\n",
       "         [0.0106, 0.0105],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0103, 0.0106],\n",
       "         [0.0105, 0.0106]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0103, 0.0106],\n",
       "         [0.0104, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0103, 0.0105],\n",
       "         [0.0106, 0.0105],\n",
       "         [0.0106, 0.0106],\n",
       "         [0.0103, 0.0106],\n",
       "         [0.0105, 0.0106]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.theta_in_unc[:10], sb.theta_in_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0862, 0.0857],\n",
       "         [0.0845, 0.0862],\n",
       "         [0.0866, 0.0848],\n",
       "         [0.0848, 0.0865],\n",
       "         [0.0814, 0.0859],\n",
       "         [0.0854, 0.0839],\n",
       "         [0.0865, 0.0810],\n",
       "         [0.0848, 0.0866],\n",
       "         [0.0807, 0.0842],\n",
       "         [0.0849, 0.0866]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0862, 0.0857],\n",
       "         [0.0845, 0.0862],\n",
       "         [0.0866, 0.0848],\n",
       "         [0.0848, 0.0865],\n",
       "         [0.0814, 0.0859],\n",
       "         [0.0854, 0.0839],\n",
       "         [0.0865, 0.0810],\n",
       "         [0.0848, 0.0866],\n",
       "         [0.0807, 0.0842],\n",
       "         [0.0849, 0.0866]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.theta_out_unc[:10], sb.theta_out_unc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0865, 0.0860],\n",
       "         [0.0848, 0.0866],\n",
       "         [0.0869, 0.0852],\n",
       "         [0.0851, 0.0868],\n",
       "         [0.0817, 0.0863],\n",
       "         [0.0857, 0.0843],\n",
       "         [0.0868, 0.0813],\n",
       "         [0.0852, 0.0869],\n",
       "         [0.0810, 0.0846],\n",
       "         [0.0852, 0.0869]], grad_fn=<SliceBackward>),\n",
       " tensor([[0.0865, 0.0860],\n",
       "         [0.0848, 0.0866],\n",
       "         [0.0869, 0.0852],\n",
       "         [0.0851, 0.0868],\n",
       "         [0.0817, 0.0863],\n",
       "         [0.0857, 0.0843],\n",
       "         [0.0868, 0.0813],\n",
       "         [0.0852, 0.0869],\n",
       "         [0.0810, 0.0846],\n",
       "         [0.0852, 0.0869]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.dtheta_unc[:10], sb.dtheta_unc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VolumeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume(get_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = VolumeWrapper(volume=volume, res_opt=partial(torch.optim.SGD, lr=2e10), eff_opt=partial(torch.optim.SGD, lr=2e5),\n",
    "                        loss_func=DetectorLoss(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MetricLogger(show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_passives = PassiveYielder([arb_rad_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomopt.optimisation.callbacks.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamCap(Callback):\n",
    "    def on_volume_batch_begin(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            for d in self.wrapper.volume.get_detectors():\n",
    "                torch.clamp_(d.resolution, min=1, max=1e7)\n",
    "                torch.clamp_(d.efficiency, min=1e-7, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = wrapper.fit(25, n_mu_per_volume=1000, mu_bs=100, passive_bs=1, trn_passives=trn_passives, val_passives=trn_passives, cbs=[NoMoreNaNs(),ParamCap(),ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in volume.get_detectors():\n",
    "    print(1, d.resolution, d.efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tomopt]",
   "language": "python",
   "name": "conda-env-tomopt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
